head	1.1;
branch	1.1.1;
access;
symbols
	tg-mergetmp-mirosx-1:1.1.1.7
	tg-mergefixes-1-branch:1.1.1.7.0.8
	tg-mergefixes-1-base:1.1.1.7
	MIROS_X:1.1.1.7.0.6
	MIROS_X_BASE:1.1.1.7
	tg-mergetmp-3:1.1.1.7
	MIRBSD_XP_MIRPPC:1.1.1.7.0.4
	MIRBSD_XP_SPARC_BASE:1.1.1.7
	MIRBSD_XP_SPARC:1.1.1.7.0.2
	MIRBSD_7quater:1.1.1.4
	cvs-200405160640:1.1.1.7
	cvs-200401271800:1.1.1.7
	cvs-200401261630:1.1.1.7
	cvs-200401021645:1.1.1.6
	MIRBSD_7_ALPHA:1.1.1.4.0.6
	MIRBSD_7:1.1.1.4.0.4
	cvs-200312222040:1.1.1.5
	MIRBSD_7ter:1.1.1.4
	MIRBSD_7_DEV:1.1.1.4.0.2
	cvs-200310020700:1.1.1.4
	cvs-200309271030:1.1.1.3
	cvs-200309261655:1.1.1.3
	cvs-200309251530:1.1.1.3
	cvs-200308302005:1.1.1.3
	cvs-200308171200:1.1.1.3
	ctm-3496:1.1.1.3
	ctm-3449:1.1.1.3
	ctm-3437:1.1.1.3
	cvs-200307191805:1.1.1.3
	ctm-3425:1.1.1.3
	cvs-200307091500:1.1.1.3
	cvs-200307072125:1.1.1.3
	ctm-3389:1.1.1.3
	cvs-200307021520:1.1.1.3
	cvs-200306291430:1.1.1.3
	ctm-3341:1.1.1.3
	MIRBSD_5:1.1.1.3
	cvs-200306082100:1.1.1.3
	ctm-3316:1.1.1.3
	ctm-3272:1.1.1.3
	cvs-200305131745:1.1.1.3
	ctm-3264:1.1.1.3
	cvs-200305071630:1.1.1.3
	ctm-3255:1.1.1.3
	ctm-3229:1.1.1.2
	MIRBSD_4:1.1.1.2
	ctm-3203:1.1.1.2
	cvs-20030410-1130:1.1.1.2
	ctm-3155:1.1.1.2
	ctm-3132:1.1.1.1
	openbsd:1.1.1;
locks; strict;
comment	@ * @;


1.1
date	2003.03.22.17.50.54;	author tg;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2003.03.22.17.50.54;	author tg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2003.03.29.19.46.12;	author tg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2003.05.05.18.55.29;	author tg;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2003.10.02.07.40.46;	author tg;	state Exp;
branches;
next	1.1.1.5;

1.1.1.5
date	2003.12.22.21.01.39;	author tg;	state Exp;
branches;
next	1.1.1.6;

1.1.1.6
date	2004.01.02.17.51.31;	author tg;	state Exp;
branches;
next	1.1.1.7;

1.1.1.7
date	2004.01.26.18.47.18;	author tg;	state Stab;
branches;
next	;


desc
@@


1.1
log
@Initial revision
@
text
@/*
 * Bus independent OpenBSD shim for the aic7xxx based adaptec SCSI controllers
 *
 * Copyright (c) 1994-2001 Justin T. Gibbs.
 * Copyright (c) 2001-2002 Steve Murphree, Jr.
 * All rights reserved.
 *
 * Redistribution and use in source and binary forms, with or without
 * modification, are permitted provided that the following conditions
 * are met:
 * 1. Redistributions of source code must retain the above copyright
 *    notice, this list of conditions, and the following disclaimer,
 *    without modification.
 * 2. The name of the author may not be used to endorse or promote products
 *    derived from this software without specific prior written permission.
 *
 * Alternatively, this software may be distributed under the terms of the
 * GNU Public License ("GPL").
 *
 * THIS SOFTWARE IS PROVIDED BY THE AUTHOR AND CONTRIBUTORS ``AS IS'' AND
 * ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
 * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
 * ARE DISCLAIMED. IN NO EVENT SHALL THE AUTHOR OR CONTRIBUTORS BE LIABLE FOR
 * ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
 * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS
 * OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)
 * HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
 * LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
 * OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
 * SUCH DAMAGE.
 *
 * $Id: aic7xxx_openbsd.c,v 1.10 2003/01/05 22:41:35 deraadt Exp $
 *
 * $FreeBSD: src/sys/dev/aic7xxx/aic7xxx_freebsd.c,v 1.26 2001/07/18 21:39:47 gibbs Exp $
 * $OpenBSD: aic7xxx_openbsd.c,v 1.10 2003/01/05 22:41:35 deraadt Exp $
 */

#include <dev/ic/aic7xxx_openbsd.h>
#include <dev/ic/aic7xxx_inline.h>

struct cfdriver ahc_cd = {
	NULL, "ahc", DV_DULL
};

int32_t		ahc_action(struct scsi_xfer *xs);
static void	ahc_minphys(struct buf *bp);

static struct scsi_adapter ahc_switch =
{
	ahc_action,
	ahc_minphys,
	0,
	0,
};

/* the below structure is so we have a default dev struct for our link struct */
static struct scsi_device ahc_dev =
{
	NULL, /* Use default error handler */
	NULL, /* have a queue, served by this */
	NULL, /* have no async handler */
	NULL, /* Use default 'done' routine */
};

#ifndef AHC_TMODE_ENABLE
#define AHC_TMODE_ENABLE 0
#endif

#define ccb_scb_ptr spriv_ptr0

#ifdef AHC_DEBUG
int     ahc_debug = AHC_DEBUG;
#endif

#if UNUSED
static void     ahc_dump_targcmd(struct target_cmd *cmd);
#endif
void		ahc_build_free_scb_list(struct ahc_softc *ahc);
int		ahc_execute_scb(void *arg, bus_dma_segment_t *dm_segs,
				int nsegments);
int		ahc_poll(struct ahc_softc *ahc, int wait);
void		ahc_timeout(void *);
int		ahc_setup_data(struct ahc_softc *ahc,
				    struct scsi_xfer *xs,
			       struct scb *scb);
void		ahc_set_recoveryscb(struct ahc_softc *ahc,
				    struct scb *scb);
int		ahc_init_scbdata(struct ahc_softc *ahc);
void		ahc_fini_scbdata(struct ahc_softc *ahc);
int		ahc_istagged_device(struct ahc_softc *ahc,
					 struct scsi_xfer *xs,
				    int nocmdcheck);
void		ahc_check_tags(struct ahc_softc *ahc,
			       struct scsi_xfer *xs);

/*
 * Routines to manage busy targets.  The old driver didn't need to 
 * pause the sequencer because no device registers were accessed.  Now
 * busy targets are controlled via the device registers and thus, we
 * have to pause the sequencer for chips that don't have the
 * auto-pause feature.  XXX smurph
 */
u_int ahc_pause_index_busy_tcl(struct ahc_softc *ahc, u_int tcl);
void  ahc_pause_unbusy_tcl(struct ahc_softc *ahc, u_int tcl);
void  ahc_pause_busy_tcl(struct ahc_softc *ahc, u_int tcl, u_int busyid);

u_int
ahc_pause_index_busy_tcl(ahc, tcl)
	struct ahc_softc *ahc;
	u_int tcl;
{
	u_int retval; 
	if (ahc->features & AHC_AUTOPAUSE) {
		retval = ahc_index_busy_tcl(ahc, tcl);
	} else {
		ahc_pause(ahc);
		retval = ahc_index_busy_tcl(ahc, tcl);
		ahc_unpause(ahc);
	}
	return retval;
}

void
ahc_pause_unbusy_tcl(ahc, tcl)
	struct ahc_softc *ahc;
	u_int tcl;
{
	if (ahc->features & AHC_AUTOPAUSE) {
		ahc_unbusy_tcl(ahc, tcl);
	} else {
		ahc_pause(ahc);
		ahc_unbusy_tcl(ahc, tcl);
		ahc_unpause(ahc);
	}
}
					     
void
ahc_pause_busy_tcl(ahc, tcl, busyid)
	struct ahc_softc *ahc;
	u_int tcl;
	u_int busyid;
{
	if (ahc->features & AHC_AUTOPAUSE) {
		ahc_busy_tcl(ahc, tcl, busyid);
	} else {
		ahc_pause(ahc);
		ahc_busy_tcl(ahc, tcl, busyid);
		ahc_unpause(ahc);
	}
}

/* Special routine to force negotiation for OpenBSD */
void 
ahc_force_neg(ahc)
	struct ahc_softc *ahc;
{
	int num_targets = AHC_NUM_TARGETS;
	int i;
	
	if ((ahc->features & (AHC_WIDE|AHC_TWIN)) == 0)
		num_targets = 8;

	for (i = 0; i < num_targets; i++) {
		struct ahc_initiator_tinfo *tinfo;
		struct ahc_tmode_tstate *tstate;
		u_int our_id;
		u_int target_id;
		char channel;

		channel = 'A';
		our_id = ahc->our_id;
		target_id = i;
		if (i > 7 && (ahc->features & AHC_TWIN) != 0) {
			channel = 'B';
			our_id = ahc->our_id_b;
			target_id = i % 8;
		}
		tinfo = ahc_fetch_transinfo(ahc, channel, our_id,
					    target_id, &tstate);
		tinfo->goal = tinfo->user; /* force negotiation */
		tstate->discenable = ahc->user_discenable;
	}
}

int
ahc_createdmamem(ahc, dmat, size, mapp, vaddr, baddr, seg, nseg, what)
	struct ahc_softc *ahc;
	bus_dma_tag_t dmat;
	int size;
	bus_dmamap_t *mapp;
	caddr_t *vaddr;
	bus_addr_t *baddr;
	bus_dma_segment_t *seg;
	int *nseg;
	const char *what;
{
	int error, level = 0;
	int dma_flags = BUS_DMA_NOWAIT;

	dmat = ahc->parent_dmat;
	
	if ((ahc->chip & AHC_VL) !=0)
		dma_flags |= ISABUS_DMA_32BIT;
	
	if ((error = bus_dmamem_alloc(dmat, size, NBPG, 0,
			seg, 1, nseg, BUS_DMA_NOWAIT)) != 0) {
		printf("%s: failed to %s DMA map for %s, error = %d\n",
			"allocate", ahc_name(ahc), what, error);
		goto out;
	}
	level++;

	if ((error = bus_dmamem_map(dmat, seg, *nseg, size, vaddr,
			BUS_DMA_NOWAIT|BUS_DMA_COHERENT)) != 0) {
		printf("%s: failed to %s DMA map for %s, error = %d\n",
			"map", ahc_name(ahc), what, error);
		goto out;
	}
	level++;

	if ((error = bus_dmamap_create(dmat, size, 1, size, 0,
			dma_flags, mapp)) != 0) {
		printf("%s: failed to %s DMA map for %s, error = %d\n",
			"create", ahc_name(ahc), what, error);
		goto out;
	}
	level++;

	if ((error = bus_dmamap_load(dmat, *mapp, *vaddr, size, NULL,
			BUS_DMA_NOWAIT)) != 0) {
		printf("%s: failed to %s DMA map for %s, error = %d\n",
			"load", ahc_name(ahc), what, error);
		goto out;
	}

	*baddr = (*mapp)->dm_segs[0].ds_addr;
	return 0;
out:
	switch (level) {
	case 3:
		bus_dmamap_destroy(dmat, *mapp);
		/* FALLTHROUGH */
	case 2:
		bus_dmamem_unmap(dmat, *vaddr, size);
		/* FALLTHROUGH */
	case 1:
		bus_dmamem_free(dmat, seg, *nseg);
		break;
	default:
		break;
	}

	return error;
}

void
ahc_freedmamem(tag, size, map, vaddr, seg, nseg)
	bus_dma_tag_t tag;
	int size;
	bus_dmamap_t map;
	caddr_t vaddr;
	bus_dma_segment_t *seg;
	int nseg;
{
	bus_dmamap_unload(tag, map);
	bus_dmamap_destroy(tag, map);
	bus_dmamem_unmap(tag, vaddr, size);
	bus_dmamem_free(tag, seg, nseg);
}

void
ahc_alloc_scbs(ahc)
	struct ahc_softc *ahc;
{
	struct scb_data *scb_data;
	struct scb *next_scb;
	struct sg_map_node *sg_map;
	bus_addr_t physaddr;
	struct ahc_dma_seg *segs;
	int newcount;
	int i;
	int dma_flags = 0;

	scb_data = ahc->scb_data;
	if (scb_data->numscbs >= AHC_SCB_MAX)
		/* Can't allocate any more */
		return;

	next_scb = &scb_data->scbarray[scb_data->numscbs];

	sg_map = malloc(sizeof(*sg_map), M_DEVBUF, M_NOWAIT);

	if (sg_map == NULL)
		return;
	
	if (ahc_createdmamem(ahc, scb_data->sg_dmat, PAGE_SIZE, 
			     &sg_map->sg_dmamap, (caddr_t *)&sg_map->sg_vaddr,
			     &sg_map->sg_physaddr, &sg_map->sg_dmasegs, 
			     &sg_map->sg_nseg, "SG space") < 0) {
		free(sg_map, M_DEVBUF);
		return;
	}

	SLIST_INSERT_HEAD(&scb_data->sg_maps, sg_map, links);

	segs = sg_map->sg_vaddr;
	physaddr = sg_map->sg_physaddr;

	newcount = (PAGE_SIZE / (AHC_NSEG * sizeof(struct ahc_dma_seg)));
	for (i = 0; scb_data->numscbs < AHC_SCB_MAX && i < newcount; i++) {
		struct scb_platform_data *pdata;
		int error;
		
		pdata = (struct scb_platform_data *)malloc(sizeof(*pdata),
							   M_DEVBUF, M_NOWAIT);
		if (pdata == NULL)
			break;
		bzero(pdata, sizeof(*pdata));
		next_scb->platform_data = pdata;
		next_scb->sg_map = sg_map;
		next_scb->sg_list = segs;
		/*
		 * The sequencer always starts with the second entry.
		 * The first entry is embedded in the scb.
		 */
		next_scb->sg_list_phys = physaddr + sizeof(struct ahc_dma_seg);
		next_scb->ahc_softc = ahc;
		next_scb->flags = SCB_FREE;
		
		/* set up AHA-284x correctly. */
		dma_flags = ((ahc->chip & AHC_VL) !=0) ? 
			BUS_DMA_NOWAIT|ISABUS_DMA_32BIT :
			BUS_DMA_NOWAIT|BUS_DMA_ALLOCNOW;
		
		ahc->buffer_dmat = ahc->parent_dmat;
		error = bus_dmamap_create(ahc->buffer_dmat,
					  AHC_MAXTRANSFER_SIZE, AHC_NSEG,
					  MAXBSIZE, 0, dma_flags, 
					  &next_scb->dmamap);
		if (error !=0) 
			break;
		
		next_scb->hscb = &scb_data->hscbs[scb_data->numscbs];
		next_scb->hscb->tag = ahc->scb_data->numscbs;
		SLIST_INSERT_HEAD(&ahc->scb_data->free_scbs,
				  next_scb, links.sle);
		segs += AHC_NSEG;
		physaddr += (AHC_NSEG * sizeof(struct ahc_dma_seg));
		next_scb++;
		ahc->scb_data->numscbs++;
	}
}

int
ahc_init_scbdata(ahc)
	struct ahc_softc *ahc;
{
	struct scb_data *scb_data;

	scb_data = ahc->scb_data;
	scb_data->init_level = 0;
	SLIST_INIT(&scb_data->free_scbs);
	SLIST_INIT(&scb_data->sg_maps);

	/* Allocate SCB resources */
	scb_data->scbarray =
	    (struct scb *)malloc(sizeof(struct scb) * AHC_SCB_MAX,
				 M_DEVBUF, M_NOWAIT);
	if (scb_data->scbarray == NULL)
		return (ENOMEM);
	memset(scb_data->scbarray, 0, sizeof(struct scb) * AHC_SCB_MAX);

	/* set dma tags */
	scb_data->hscb_dmat = ahc->parent_dmat;
	scb_data->sense_dmat = ahc->parent_dmat;
	scb_data->sg_dmat = ahc->parent_dmat;
	
	/* Determine the number of hardware SCBs and initialize them */
	scb_data->maxhscbs = ahc_probe_scbs(ahc);
	if ((ahc->flags & AHC_PAGESCBS) != 0) {
		/* SCB 0 heads the free list */
		ahc_outb(ahc, FREE_SCBH, 0);
	} else {
		ahc_outb(ahc, FREE_SCBH, SCB_LIST_NULL);
	}

	if (ahc->scb_data->maxhscbs == 0) {
		printf("%s: No SCB space found\n", ahc_name(ahc));
		return (ENXIO);
	}

	ahc_build_free_scb_list(ahc);

	/*
	 * Create our DMA mappings.  These tags define the kinds of device
	 * accessible memory allocations and memory mappings we will
	 * need to perform during normal operation.
	 *
	 * Unless we need to further restrict the allocation, we rely
	 * on the restrictions of the parent dmat, hence the common
	 * use of MAXADDR and MAXSIZE.
	 */
	if (ahc_createdmamem(ahc, scb_data->hscb_dmat,
	    AHC_SCB_MAX * sizeof(struct hardware_scb), 
	    &scb_data->hscb_dmamap, (caddr_t *)&scb_data->hscbs, 
	    &scb_data->hscb_busaddr, &scb_data->hscb_seg,
	    &scb_data->hscb_nseg, "hardware SCB structures") < 0)
		goto error_exit;
	
	scb_data->init_level++;

	/* DMA for our sense buffers */
	if (ahc_createdmamem(ahc, scb_data->sense_dmat,
	    AHC_SCB_MAX * sizeof(struct scsi_sense_data),
	    &scb_data->sense_dmamap, (caddr_t *)&scb_data->sense,
	    &scb_data->sense_busaddr, &scb_data->sense_seg,
	    &scb_data->sense_nseg, "sense buffers") < 0)
		goto error_exit;

	scb_data->init_level++;
	
	/* Perform initial CCB allocation */
	memset(scb_data->hscbs, 0, AHC_SCB_MAX * sizeof(struct hardware_scb));
	ahc_alloc_scbs(ahc);

	if (scb_data->numscbs == 0) {
		printf("%s: Unable to allocate initial scbs\n",
		       ahc_name(ahc));
		goto error_exit;
	}
	scb_data->init_level++;

	/*
	 * Tell the sequencer which SCB will be the next one it receives.
	 */
	ahc->next_queued_scb = ahc_get_scb(ahc);
	ahc_outb(ahc, NEXT_QUEUED_SCB, ahc->next_queued_scb->hscb->tag);

	/*
	 * Note that we were successful
	 */
	return (0); 

error_exit:

	return (ENOMEM);
}

void
ahc_fini_scbdata(ahc)
	struct ahc_softc *ahc;
{
	struct scb_data *scb_data;

	scb_data = ahc->scb_data;

	switch (scb_data->init_level) {
	default:
	case 3:
	{
		struct sg_map_node *sg_map;

		while ((sg_map = SLIST_FIRST(&scb_data->sg_maps))!= NULL) {
			SLIST_REMOVE_HEAD(&scb_data->sg_maps, links);
			ahc_freedmamem(ahc->parent_dmat, PAGE_SIZE,
				       sg_map->sg_dmamap,
				       (caddr_t)sg_map->sg_vaddr,
				       &sg_map->sg_dmasegs, sg_map->sg_nseg);
			free(sg_map, M_DEVBUF);
		}
	}
	/*FALLTHROUGH*/
	case 2:
		ahc_freedmamem(ahc->parent_dmat,
			       AHC_SCB_MAX * sizeof(struct scsi_sense_data),
			       scb_data->sense_dmamap, (caddr_t)scb_data->sense,
			       &scb_data->sense_seg, scb_data->sense_nseg);
	/*FALLTHROUGH*/
	case 1:
		ahc_freedmamem(ahc->parent_dmat,
			       AHC_SCB_MAX * sizeof(struct hardware_scb), 
			       scb_data->hscb_dmamap, (caddr_t)scb_data->hscbs,
			       &scb_data->hscb_seg, scb_data->hscb_nseg);
	/*FALLTHROUGH*/
	}
	if (scb_data->scbarray != NULL)
		free(scb_data->scbarray, M_DEVBUF);
}

void
ahc_free(ahc)
	struct ahc_softc *ahc;
{
	ahc_fini_scbdata(ahc);
	if (ahc->init_level != 0)
		ahc_freedmamem(ahc->parent_dmat, ahc->shared_data_size,
		    ahc->shared_data_dmamap, ahc->qoutfifo,
		    &ahc->shared_data_seg, ahc->shared_data_nseg);

	if (ahc->scb_data != NULL)
		free(ahc->scb_data, M_DEVBUF);
	return;
}

/*
 * Attach all the sub-devices we can find
 */
int
ahc_attach(ahc)
	struct ahc_softc *ahc;
{
	char   ahc_info[256];
	int s;
	ahc_lock(ahc, &s);
	
	ahc_controller_info(ahc, ahc_info);
	printf("%s: %s\n", ahc_name(ahc), ahc_info);
	/*
	 * Initialize the software queue.
	 */
	LIST_INIT(&ahc->platform_data->sc_xxxq);

#ifdef AHC_BROKEN_CACHE
	if (cpu_class == CPUCLASS_386)	/* doesn't have "wbinvd" instruction */
		ahc_broken_cache = 0;
#endif
	/*
	 * fill in the prototype scsi_links.
	 */
	ahc->platform_data->sc_link.adapter_target = ahc->our_id;
	if (ahc->features & AHC_WIDE)
		ahc->platform_data->sc_link.adapter_buswidth = 16;
	ahc->platform_data->sc_link.adapter_softc = ahc;
	ahc->platform_data->sc_link.adapter = &ahc_switch;
	ahc->platform_data->sc_link.openings = 2;
	ahc->platform_data->sc_link.device = &ahc_dev;
	ahc->platform_data->sc_link.flags = SCSIDEBUG_LEVEL;
	
	if (ahc->features & AHC_TWIN) {
		/* Configure the second scsi bus */
		ahc->platform_data->sc_link_b = ahc->platform_data->sc_link;
		ahc->platform_data->sc_link_b.adapter_target = ahc->our_id_b;
		if (ahc->features & AHC_WIDE)
			ahc->platform_data->sc_link.adapter_buswidth = 16;
		ahc->platform_data->sc_link_b.adapter_softc = ahc;
		ahc->platform_data->sc_link_b.adapter = &ahc_switch;
		ahc->platform_data->sc_link_b.openings = 2;
		ahc->platform_data->sc_link_b.device = &ahc_dev;
		ahc->platform_data->sc_link_b.flags = SCSIDEBUG_LEVEL;
	}

	/*
	 * ask the adapter what subunits are present
	 */
	if (ahc->platform_data->channel_b_primary == FALSE) {
		/* make SCSI_IS_SCSIBUS_B() == false, while probing channel A */
		ahc->platform_data->sc_link_b.scsibus = 0xff;
		config_found((void *)ahc, &ahc->platform_data->sc_link, scsiprint);
		if (ahc->features & AHC_TWIN)
			config_found((void *)ahc, &ahc->platform_data->sc_link_b, scsiprint);
	} else {
		/*
		 * if implementation of SCSI_IS_SCSIBUS_B() is changed to use
		 * ahc->sc_link.scsibus, then "ahc->sc_link.scsibus = 0xff;"
		 * is needed, here.
		 */
		if (ahc->features & AHC_TWIN)
			config_found((void *)ahc, &ahc->platform_data->sc_link_b, scsiprint);
		config_found((void *)ahc, &ahc->platform_data->sc_link, scsiprint);
	}
	ahc_unlock(ahc, &s);
	return 1;
}

/*
 * Catch an interrupt from the adapter
 */
int
ahc_platform_intr(arg)
	void *arg;
{
	struct	ahc_softc *ahc;
	u_int	intstat = 0;
	u_int	errstat = 0;

	/*
	 * Any interrupts to process?
	 */
	ahc = (struct ahc_softc *)arg; 
	
	intstat = ahc_inb(ahc, INTSTAT);
	
	/* Only check PCI error on PCI cards */
        if ((ahc->chip & AHC_PCI) != 0) {
		errstat = ahc_inb(ahc, ERROR);
		if ((intstat & INT_PEND) == 0 && (errstat & PCIERRSTAT)) {
			if (ahc->unsolicited_ints > 500) {
				ahc->unsolicited_ints = 0;
				ahc->bus_intr(ahc);
			}
			ahc->unsolicited_ints++;
			/* claim the interrupt */
			return 1;
		}
	}
	
	if ((intstat & INT_PEND) == 0){
		/* This interrupt is not for us */
		return 0;
	}
	
	ahc_intr(ahc);
	return 1; 
}

/*
 * We have an scb which has been processed by the
 * adaptor, now we look to see how the operation
 * went.
 */
void
ahc_done(ahc, scb)
	struct ahc_softc *ahc;
	struct scb *scb;
{
	struct scsi_xfer *xs = scb->io_ctx;
	struct scsi_link *sc_link = xs->sc_link;
	int requeue = 0;
	int target;
	int lun;

	SC_DEBUG(xs->sc_link, SDEV_DB2, ("ahc_done\n"));
	
#ifdef maybe_not_such_a_good_idea
	/* Don't smash a disconnected SCB */
	if ((scb->hscb->control & DISCONNECTED) != 0){
		printf("disconnected sbc (tag %d) in ahc_done(ahc)!!!\n");
		if ((xs = ahc->platform_data->sc_xxxq.lh_first) != NULL)
			(void) ahc_action(xs);
		return;
	}
#endif	
	
	LIST_REMOVE(scb, pending_links);
	if ((scb->flags & SCB_UNTAGGEDQ) != 0) {
		struct scb_tailq *untagged_q;
		int target_offset;

		target_offset = SCB_GET_TARGET_OFFSET(ahc, scb);
		untagged_q = &ahc->untagged_queues[target_offset];
		TAILQ_REMOVE(untagged_q, scb, links.tqe);
		scb->flags &= ~SCB_UNTAGGEDQ;
		ahc_run_untagged_queue(ahc, untagged_q);
	}
	
	timeout_del(&xs->stimeout);

#ifdef AHC_DEBUG
	if ((ahc_debug & AHC_SHOWCMDS)) {
		ahc_print_path(ahc, scb);
		printf("ahc_done: opcode 0x%x tag %x flags %x status %d error %d\n", 
		       xs->cmdstore.opcode, scb->hscb->tag, 
		       scb->flags, xs->status, xs->error);
	}
#endif
	
	target = sc_link->target;
	lun = sc_link->lun;

	if (xs->datalen) {
		int op;
	
		if ((xs->flags & SCSI_DATA_IN) != 0)
			op = BUS_DMASYNC_POSTREAD;
		else
			op = BUS_DMASYNC_POSTWRITE;
		ahc->buffer_dmat = ahc->parent_dmat;
		bus_dmamap_sync(ahc->buffer_dmat, scb->dmamap,
		    0, scb->dmamap->dm_mapsize, op);
		
		bus_dmamap_unload(ahc->buffer_dmat, scb->dmamap);
	}

	/*
	 * Unbusy this target/channel/lun.
	 * XXX if we are holding two commands per lun, 
	 *     send the next command.
	 */
	if (!(scb->hscb->control & TAG_ENB)){
		ahc_pause_unbusy_tcl(ahc, XS_TCL(xs));
	}

	/*
	 * If the recovery SCB completes, we have to be
	 * out of our timeout.
	 */
	if ((scb->flags & SCB_RECOVERY_SCB) != 0) {
		struct	scb *list_scb;

		/*
		 * We were able to complete the command successfully,
		 * so reinstate the timeouts for all other pending
		 * commands.
		 */
		LIST_FOREACH(list_scb, &ahc->pending_scbs, pending_links) {
			struct scsi_xfer *txs = list_scb->io_ctx;
			if (!(txs->flags & SCSI_POLL))
				timeout_add(&list_scb->io_ctx->stimeout,
				    (list_scb->io_ctx->timeout * hz)/1000);
		}

		if (xs->error != XS_NOERROR)
			ahc_set_transaction_status(scb, CAM_CMD_TIMEOUT);
		ahc_print_path(ahc, scb);
		printf("no longer in timeout, status = %x\n", xs->status);
	}

	if (xs->error != XS_NOERROR) {
		/* Don't clobber any existing error state */
	} else if ((scb->flags & SCB_SENSE) != 0) {
		/*
		 * We performed autosense retrieval.
		 *
		 * Zero the sense data before having
		 * the drive fill it.  The SCSI spec mandates
		 * that any untransfered data should be
		 * assumed to be zero.  Complete the 'bounce'
		 * of sense information through buffers accessible
		 * via bus-space by copying it into the clients
		 * csio.
		 */
		memset(&xs->sense, 0, sizeof(struct scsi_sense_data));
		memcpy(&xs->sense, ahc_get_sense_buf(ahc, scb),
		       ahc_le32toh((scb->sg_list->len & AHC_SG_LEN_MASK)));
		xs->error = XS_SENSE;
	}
	
	if (scb->platform_data->flags & SCB_FREEZE_QUEUE) {
		/* keep negs from happening */
		if (ahc->platform_data->devqueue_blocked[target] > 0) {
			ahc->platform_data->devqueue_blocked[target]--;
		}
		scb->platform_data->flags &= ~SCB_FREEZE_QUEUE;
	}
	
	requeue = scb->platform_data->flags & SCB_REQUEUE;
	ahc_free_scb(ahc, scb);

	if (requeue) {
		/*
		 * Re-insert at the front of the private queue to
		 * preserve order.
		 */
		int s;
		ahc_lock(ahc, &s);
		ahc_list_insert_head(ahc, xs);
		ahc_unlock(ahc, &s);
	} else {
		if ((xs->sc_link->lun == 0) &&
		    (xs->flags & SCSI_POLL) &&
		    (xs->error == XS_NOERROR))
		ahc_check_tags(ahc, xs);
		xs->flags |= ITSDONE;
		scsi_done(xs);
	}

	/*
	 * If there are entries in the software queue, try to
	 * run the first one.  We should be more or less guaranteed
	 * to succeed, since we just freed an SCB.
	 *
	 * NOTE: ahc_action() relies on our calling it with
	 * the first entry in the queue.
	 */
	if ((xs = ahc->platform_data->sc_xxxq.lh_first) != NULL)
		(void) ahc_action(xs);
}

static void
ahc_minphys(bp)
	struct buf *bp;
{
	/*
	 * Even though the card can transfer up to 16megs per command
	 * we are limited by the number of segments in the dma segment
	 * list that we can hold.  The worst case is that all pages are
	 * discontinuous physically, hense the "page per segment" limit
	 * enforced here.
	 */
	if (bp->b_bcount > ((AHC_NSEG - 1) * PAGE_SIZE)) {
		bp->b_bcount = ((AHC_NSEG - 1) * PAGE_SIZE);
	}
	minphys(bp);
}

int32_t
ahc_action(xs)
	struct scsi_xfer *xs;
{
	struct scsi_xfer *first_xs, *next_xs = NULL;
	struct ahc_softc *ahc;
	struct scb *scb;
	struct hardware_scb *hscb;	
	struct ahc_initiator_tinfo *tinfo;
	struct ahc_tmode_tstate *tstate;
	u_int target_id;
	u_int our_id;
	char channel;
	int s, tcl;
	u_int16_t mask;
	int dontqueue = 0, fromqueue = 0;

	SC_DEBUG(xs->sc_link, SDEV_DB3, ("ahc_action\n"));
	ahc = (struct ahc_softc *)xs->sc_link->adapter_softc;

	/* must protect the queue */
	ahc_lock(ahc, &s);

	if (xs == ahc->platform_data->sc_xxxq.lh_first) {
		/*
		 * Called from ahc_done. Calling with the first entry in
		 * the queue is really just a way of seeing where we're
		 * called from. Now, find the first eligible SCB to send,
		 * e.g. one which will be accepted immediately.
		 */
		if (ahc->platform_data->queue_blocked) {
			ahc_unlock(ahc, &s);
			return (TRY_AGAIN_LATER);
		}

		xs = ahc_first_xs(ahc);
		if (xs == NULL) {
			ahc_unlock(ahc, &s);
			return (TRY_AGAIN_LATER);
		}

		next_xs = ahc_list_next(ahc, xs);
		ahc_list_remove(ahc, xs);
		fromqueue = 1;
		goto get_scb;
	}

	/* determine safety of software queueing */
	dontqueue = xs->flags & SCSI_POLL;
	
	/*
	 * If no new requests are accepted, just insert into the
	 * private queue to wait for our turn.
	 */
	tcl = XS_TCL(xs);
	
	if (ahc->platform_data->queue_blocked ||
	    ahc->platform_data->devqueue_blocked[xs->sc_link->target] ||
	    (!ahc_istagged_device(ahc, xs, 0) &&
	     ahc_pause_index_busy_tcl(ahc, tcl) != SCB_LIST_NULL)) {
		if (dontqueue) {
			ahc_unlock(ahc, &s);
			xs->error = XS_DRIVER_STUFFUP;
			return TRY_AGAIN_LATER;
		}
		ahc_list_insert_tail(ahc, xs);
		ahc_unlock(ahc, &s);
		return SUCCESSFULLY_QUEUED;
	}

	first_xs = ahc_first_xs(ahc);

	/* determine safety of software queueing */
	dontqueue = xs->flags & SCSI_POLL;

	/*
	 * Handle situations where there's already entries in the
	 * queue.
	 */
	if (first_xs != NULL) {
		/*
		 * If we can't queue, we have to abort, since
		 * we have to preserve order.
		 */
		if (dontqueue) {
			ahc_unlock(ahc, &s);
			xs->error = XS_DRIVER_STUFFUP;
			return (TRY_AGAIN_LATER);
		}

		/*
		 * Swap with the first queue entry.
		 */
		ahc_list_insert_tail(ahc, xs);
		xs = first_xs;
		next_xs = ahc_list_next(ahc, xs);
		ahc_list_remove(ahc, xs);
		fromqueue = 1;
	}

get_scb:

	target_id = xs->sc_link->target;
	our_id = SCSI_SCSI_ID(ahc, xs->sc_link);

	/*
	 * get an scb to use.
	 */
	if ((scb = ahc_get_scb(ahc)) == NULL) {
		if (dontqueue) {
			ahc_unlock(ahc, &s);
			xs->error = XS_DRIVER_STUFFUP;
			return (TRY_AGAIN_LATER);
		}

		/*
		 * If we were pulled off the queue, put ourselves
		 * back to where we came from, otherwise tack ourselves
		 * onto the end.
		 */
		if (fromqueue && next_xs != NULL)
			ahc_list_insert_before(ahc, xs, next_xs);
		else
			ahc_list_insert_tail(ahc, xs);

		ahc_unlock(ahc, &s);
		return (SUCCESSFULLY_QUEUED);
	}

	tcl = XS_TCL(xs);

#ifdef DIAGNOSTIC
	if (!ahc_istagged_device(ahc, xs, 0) &&
	    ahc_pause_index_busy_tcl(ahc, tcl) != SCB_LIST_NULL)
		panic("ahc: queuing for busy target");
#endif
	
	scb->io_ctx = xs;
	hscb = scb->hscb;
	
	hscb->control = 0;
	
	timeout_set(&xs->stimeout, ahc_timeout, scb);

	if (ahc_istagged_device(ahc, xs, 0)){
		hscb->control |= TAG_ENB;
	} else {
		ahc_pause_busy_tcl(ahc, tcl, scb->hscb->tag);
	}

	ahc_unlock(ahc, &s);
 
	channel = SCSI_CHANNEL(ahc, xs->sc_link);
	if (ahc->platform_data->inited_channels[channel - 'A'] == 0) {
		if ((channel == 'A' && (ahc->flags & AHC_RESET_BUS_A)) ||
		    (channel == 'B' && (ahc->flags & AHC_RESET_BUS_B))) {
			ahc_lock(ahc, &s);
			ahc_reset_channel(ahc, channel, TRUE);
			ahc_unlock(ahc, &s);
		}
		ahc->platform_data->inited_channels[channel - 'A'] = 1;
	}

	/*
	 * Put all the arguments for the xfer in the scb
	 */
	hscb->scsiid = BUILD_SCSIID(ahc, xs->sc_link, target_id, our_id);
	hscb->lun = XS_LUN(xs);
	
	mask = SCB_GET_TARGET_MASK(ahc, scb);
	tinfo = ahc_fetch_transinfo(ahc, SCSI_CHANNEL(ahc, xs->sc_link), our_id,
				    target_id, &tstate);
	
	if (ahc->platform_data->inited_targets[target_id] == 0) {
		struct ahc_devinfo devinfo;

		ahc_lock(ahc, &s);
		ahc_compile_devinfo(&devinfo, our_id, target_id,
		    XS_LUN(xs), SCSI_CHANNEL(ahc, xs->sc_link),
		    ROLE_INITIATOR);
		ahc_update_neg_request(ahc, &devinfo, tstate, tinfo,
				       /*force*/TRUE);
		ahc->platform_data->inited_targets[target_id] = 1;
		ahc_unlock(ahc, &s);
	}

	hscb->scsirate = tinfo->scsirate;
	hscb->scsioffset = tinfo->curr.offset;
	if ((tstate->ultraenb & mask) != 0)
		hscb->control |= ULTRAENB;
		
	if ((tstate->discenable & mask) != 0)
		hscb->control |= DISCENB;

	if ((tstate->auto_negotiate & mask) != 0) {
		scb->flags |= SCB_AUTO_NEGOTIATE;
		hscb->control |= MK_MESSAGE;
	}

	if (xs->flags & SCSI_RESET) {
		scb->flags |= SCB_DEVICE_RESET;
		hscb->control |= MK_MESSAGE;
		return ahc_execute_scb(scb, NULL, 0);
	}

	return ahc_setup_data(ahc, xs, scb);
}

int
ahc_execute_scb(arg, dm_segs, nsegments)
	void *arg;
	bus_dma_segment_t *dm_segs;
	int nsegments;
{
	struct	scb *scb;
	struct	scsi_xfer *xs;
	struct	ahc_softc *ahc;
	struct	ahc_initiator_tinfo *tinfo;
	struct	ahc_tmode_tstate *tstate;
	u_int	mask;
	int	s;

	scb = (struct scb *)arg;
	xs = scb->io_ctx;
	ahc = (struct ahc_softc *)xs->sc_link->adapter_softc;
	
	if (nsegments != 0) {
		struct	  ahc_dma_seg *sg;
		bus_dma_segment_t *end_seg;
		int op;

		end_seg = dm_segs + nsegments;

		/* Copy the segments into our SG list */
		sg = scb->sg_list;
		while (dm_segs < end_seg) {
			uint32_t len;

			sg->addr = ahc_htole32(dm_segs->ds_addr);
			len = dm_segs->ds_len
			    | ((dm_segs->ds_addr >> 8) & 0x7F000000);
			sg->len = ahc_htole32(len);
			sg++;
			dm_segs++;
		}
		
		/*
		 * Note where to find the SG entries in bus space.
		 * We also set the full residual flag which the 
		 * sequencer will clear as soon as a data transfer
		 * occurs.
		 */
		scb->hscb->sgptr = ahc_htole32(scb->sg_list_phys|SG_FULL_RESID);
		
		if ((xs->flags & SCSI_DATA_IN) != 0)
			op = BUS_DMASYNC_PREREAD;
		else
			op = BUS_DMASYNC_PREWRITE;

		ahc->buffer_dmat = ahc->parent_dmat;
		bus_dmamap_sync(ahc->buffer_dmat, scb->dmamap,
				0, scb->dmamap->dm_mapsize, op);
		
		sg--;
		sg->len |= ahc_htole32(AHC_DMA_LAST_SEG);

		/* Copy the first SG into the "current" data pointer area */
		scb->hscb->dataptr = scb->sg_list->addr;
		scb->hscb->datacnt = scb->sg_list->len;
	} else {
		scb->hscb->sgptr = SG_LIST_NULL;
		scb->hscb->dataptr = 0;
		scb->hscb->datacnt = 0;
	}
	
	scb->sg_count = nsegments;

	ahc_lock(ahc, &s);

	/*
	 * Last time we need to check if this SCB needs to
	 * be aborted.
	 */
	if (xs->flags & ITSDONE) {

		if (!ahc_istagged_device(ahc, xs, 0)){
			ahc_pause_unbusy_tcl(ahc, XS_TCL(xs));
		}
			
		if (nsegments != 0)
			bus_dmamap_unload(ahc->buffer_dmat, scb->dmamap);
		
		ahc_free_scb(ahc, scb);
		ahc_unlock(ahc, &s);
		return (COMPLETE);
	}

#ifdef DIAGNOSTIC
	if (scb->sg_count > 255)
		panic("ahc bad sg_count");
#endif

	/* Fixup byte order */
	scb->hscb->dataptr = ahc_htole32(scb->hscb->dataptr); 
	scb->hscb->datacnt = ahc_htole32(scb->hscb->datacnt);
	scb->hscb->sgptr = ahc_htole32(scb->hscb->sgptr);
	
	tinfo = ahc_fetch_transinfo(ahc, SCSIID_CHANNEL(ahc, scb->hscb->scsiid),
				    SCSIID_OUR_ID(scb->hscb->scsiid),
				    SCSIID_TARGET(ahc, scb->hscb->scsiid),
				    &tstate);

	mask = SCB_GET_TARGET_MASK(ahc, scb);
	scb->hscb->scsirate = tinfo->scsirate;
	scb->hscb->scsioffset = tinfo->curr.offset;
	if ((tstate->ultraenb & mask) != 0)
		scb->hscb->control |= ULTRAENB;

	if ((tstate->discenable & mask) != 0)
		scb->hscb->control |= DISCENB;

	if ((tstate->auto_negotiate & mask) != 0) {
		scb->flags |= SCB_AUTO_NEGOTIATE;
		scb->hscb->control |= MK_MESSAGE;
	}
	
	LIST_INSERT_HEAD(&ahc->pending_scbs, scb, pending_links);

#ifdef AHC_DEBUG
	if ((ahc_debug & AHC_SHOWCMDS)) {
		ahc_print_path(ahc, scb);
		printf("opcode 0x%x tag %x len %d flags %x "
		       "control %x fpos %u rate %x\n",
		       xs->cmdstore.opcode, scb->hscb->tag, 
		       scb->hscb->cdb_len, scb->flags, 
		       scb->hscb->control, ahc->qinfifonext,
		       scb->hscb->scsirate);
	}
#endif

	/*
	 * We only allow one untagged transaction
	 * per target in the initiator role unless
	 * we are storing a full busy target *lun*
	 * table in SCB space.
	 *
	 * This really should not be of any 
	 * concern, as we take care to avoid this
	 * in ahc_done().  XXX smurph
	 */
	if ((scb->hscb->control & (TARGET_SCB|TAG_ENB)) == 0
	 && (ahc->flags & AHC_SCB_BTT) == 0) {
		struct scb_tailq *untagged_q;
		int target_offset;

		target_offset = SCB_GET_TARGET_OFFSET(ahc, scb);
		untagged_q = &(ahc->untagged_queues[target_offset]);
		TAILQ_INSERT_TAIL(untagged_q, scb, links.tqe);
		scb->flags |= SCB_UNTAGGEDQ;
		if (TAILQ_FIRST(untagged_q) != scb) {
			ahc_unlock(ahc, &s);
			return (SUCCESSFULLY_QUEUED);
		}
	}
	
	scb->flags |= SCB_ACTIVE;

	if (!(xs->flags & SCSI_POLL))
		timeout_add(&xs->stimeout, (xs->timeout * hz) / 1000);

	if ((scb->flags & SCB_TARGET_IMMEDIATE) != 0) {
		/* Define a mapping from our tag to the SCB. */
		ahc->scb_data->scbindex[scb->hscb->tag] = scb;
		ahc_pause(ahc);
		if ((ahc->flags & AHC_PAGESCBS) == 0)
			ahc_outb(ahc, SCBPTR, scb->hscb->tag);
		ahc_outb(ahc, SCB_TAG, scb->hscb->tag);
		ahc_outb(ahc, RETURN_1, CONT_MSG_LOOP);
		ahc_unpause(ahc);
	} else {
		ahc_queue_scb(ahc, scb);
	}


	if (!(xs->flags & SCSI_POLL)) {
		ahc_unlock(ahc, &s);
		return (SUCCESSFULLY_QUEUED);
	}
	
	/*
	 * If we can't use interrupts, poll for completion
	 */
	SC_DEBUG(xs->sc_link, SDEV_DB3, ("cmd_poll\n"));
	do {
		if (ahc_poll(ahc, xs->timeout)) {
			if (!(xs->flags & SCSI_SILENT))
				printf("cmd fail\n");
			ahc_timeout(scb);
			break;
		}
	} while (!(xs->flags & ITSDONE));
	ahc_unlock(ahc, &s);
	return (COMPLETE);
}

int
ahc_poll(ahc, wait)
	struct	ahc_softc *ahc;
	int	wait;	/* in msec */
{
	while (--wait) {
		DELAY(1000);
		if ((ahc->chip & AHC_PCI) != 0 && (ahc_inb(ahc, ERROR) & PCIERRSTAT) != 0)
			ahc->bus_intr(ahc);
		if (ahc_inb(ahc, INTSTAT) & INT_PEND)
			break;
	}

	if (wait == 0) {
		printf("%s: board is not responding\n", ahc_name(ahc));
		return (EIO);
	}
	
	ahc_intr((void *)ahc);
	
	return (0);
}

int
ahc_setup_data(ahc, xs, scb)
	struct ahc_softc *ahc;
	struct scsi_xfer *xs;
	struct scb *scb;
{
	struct hardware_scb *hscb;
	
	hscb = scb->hscb;
	xs->resid = xs->status = 0;
	xs->error = XS_NOERROR;
	
	hscb->cdb_len = xs->cmdlen;

	if (hscb->cdb_len > 12) {
		memcpy(hscb->cdb32, xs->cmd,
		       hscb->cdb_len);
		scb->flags |= SCB_CDB32_PTR;
	} else {
		memcpy(hscb->shared_data.cdb,
		       xs->cmd,
		       hscb->cdb_len);
	}

	/* Only use S/G if there is a transfer */
	if (xs->datalen) {
		int error;

		error = bus_dmamap_load(ahc->buffer_dmat,
					scb->dmamap, xs->data,
					xs->datalen, NULL,
					(xs->flags & SCSI_NOSLEEP) ?
					BUS_DMA_NOWAIT : BUS_DMA_WAITOK);
		if (error) {
			if (!ahc_istagged_device(ahc, xs, 0)){
				ahc_pause_unbusy_tcl(ahc, XS_TCL(xs));
			}
			return (TRY_AGAIN_LATER);	/* XXX fvdl */
		}
		error = ahc_execute_scb(scb,
					scb->dmamap->dm_segs,
					scb->dmamap->dm_nsegs);
		return error;
	} else {
		return ahc_execute_scb(scb, NULL, 0);
	}
}

void
ahc_set_recoveryscb(ahc, scb)
	struct ahc_softc *ahc;
	struct scb *scb;
{

	if ((scb->flags & SCB_RECOVERY_SCB) == 0) {
		struct scb *list_scb;

		scb->flags |= SCB_RECOVERY_SCB;

		/*
		 * Take all queued, but not sent SCBs out of the equation.
		 * Also ensure that no new CCBs are queued to us while we
		 * try to fix this problem.
		 */
		ahc->platform_data->queue_blocked = 1;

		/*
		 * Go through all of our pending SCBs and remove
		 * any scheduled timeouts for them.  We will reschedule
		 * them after we've successfully fixed this problem.
		 */
		LIST_FOREACH(list_scb, &ahc->pending_scbs, pending_links) {
			timeout_del(&list_scb->io_ctx->stimeout);
		}
	}
}

void
ahc_timeout(arg)
	void *arg;
{
	struct	scb *scb;
	struct	ahc_softc *ahc;
	int	s, found;
	u_int	last_phase;
	int	target;
	int	lun;
	int	i;
	char	channel;

	scb = (struct scb *)arg; 
	ahc = (struct ahc_softc *)scb->io_ctx->sc_link->adapter_softc;

	ahc_lock(ahc, &s);

	/*
	 * Ensure that the card doesn't do anything
	 * behind our back.  Also make sure that we
	 * didn't "just" miss an interrupt that would
	 * affect this timeout.
	 */
	ahc_pause_and_flushwork(ahc);

	if ((scb->flags & SCB_ACTIVE) == 0) {
		/* Previous timeout took care of me already */
		printf("%s: Timedout SCB already complete. "
		       "Interrupts may not be functioning.\n", ahc_name(ahc));
		ahc_unpause(ahc);
		ahc_unlock(ahc, &s);
		return;
	}
	
	target = SCB_GET_TARGET(ahc, scb);
	channel = SCB_GET_CHANNEL(ahc, scb);
	lun = SCB_GET_LUN(scb);

	ahc_print_path(ahc, scb);
	printf("SCB 0x%x - timed out\n", scb->hscb->tag);
	
	/*
	 * Take a snapshot of the bus state and print out
	 * some information so we can track down driver bugs.
	 */
	ahc_dump_card_state(ahc);
	last_phase = ahc_inb(ahc, LASTPHASE);
	
	if (scb->sg_count > 0) {
		for (i = 0; i < scb->sg_count; i++) {
			printf("sg[%d] - Addr 0x%x : Length %d\n",
			       i,
			       scb->sg_list[i].addr,
			       scb->sg_list[i].len & AHC_SG_LEN_MASK);
		}
	}
	
	if (scb->flags & (SCB_DEVICE_RESET|SCB_ABORT)) {
		/*
		 * Been down this road before.
		 * Do a full bus reset.
		 */
bus_reset:
		ahc_set_transaction_status(scb, CAM_CMD_TIMEOUT);
		found = ahc_reset_channel(ahc, channel, /*Initiate Reset*/TRUE);
		printf("%s: Issued Channel %c Bus Reset. "
		       "%d SCBs aborted\n", ahc_name(ahc), channel, found);
	} else {
		/*
		 * If we are a target, transition to bus free and report
		 * the timeout.
		 * 
		 * The target/initiator that is holding up the bus may not
		 * be the same as the one that triggered this timeout
		 * (different commands have different timeout lengths).
		 * If the bus is idle and we are actiing as the initiator
		 * for this request, queue a BDR message to the timed out
		 * target.  Otherwise, if the timed out transaction is
		 * active:
		 *   Initiator transaction:
		 *	Stuff the message buffer with a BDR message and assert
		 *	ATN in the hopes that the target will let go of the bus
		 *	and go to the mesgout phase.  If this fails, we'll
		 *	get another timeout 2 seconds later which will attempt
		 *	a bus reset.
		 *
		 *   Target transaction:
		 *	Transition to BUS FREE and report the error.
		 *	It's good to be the target!
		 */
		u_int active_scb_index;
		u_int saved_scbptr;

		saved_scbptr = ahc_inb(ahc, SCBPTR);
		active_scb_index = ahc_inb(ahc, SCB_TAG);
		
		if (last_phase != P_BUSFREE 
		  && (ahc_inb(ahc, SEQ_FLAGS) & IDENTIFY_SEEN) != 0
		  && (active_scb_index < ahc->scb_data->numscbs)) {
			struct scb *active_scb;

			/*
			 * If the active SCB is not from our device,
			 * assume that another device is hogging the bus
			 * and wait for it's timeout to expire before
			 * taking additional action.
			 */ 
			active_scb = ahc_lookup_scb(ahc, active_scb_index);
			if (active_scb != scb) {
				u_int	newtimeout;

				ahc_print_path(ahc, active_scb);
				printf("Other SCB Timeout%s",
				       (scb->flags & SCB_OTHERTCL_TIMEOUT) != 0
				       ? " again\n" : "\n");
				scb->flags |= SCB_OTHERTCL_TIMEOUT;
				newtimeout = MAX(active_scb->io_ctx->timeout,
						 scb->io_ctx->timeout);
				timeout_add(&scb->io_ctx->stimeout,
				    (newtimeout * hz) / 1000);
				ahc_unpause(ahc);
				ahc_unlock(ahc, &s);
				return;
			} 
			
			/* It's us */
			if ((scb->hscb->control & TARGET_SCB) != 0) {

				/*
				 * Send back any queued up transactions
				 * and properly record the error condition.
				 */
				ahc_freeze_devq(ahc, scb);
				ahc_set_transaction_status(scb,
							   CAM_CMD_TIMEOUT);
				ahc_freeze_scb(scb);
				ahc_done(ahc, scb);

				/* Will clear us from the bus */
				ahc_restart(ahc);
				ahc_unlock(ahc, &s);
				return;
			} 

			ahc_set_recoveryscb(ahc, active_scb);
			ahc_outb(ahc, MSG_OUT, MSG_BUS_DEV_RESET);
			ahc_outb(ahc, SCSISIGO, last_phase|ATNO);
			ahc_print_path(ahc, active_scb);
			printf("BDR message in message buffer\n");
			active_scb->flags |=  SCB_DEVICE_RESET;
			timeout_add(&active_scb->io_ctx->stimeout, 2 * hz);
			ahc_unpause(ahc);
		} else {
			int	 disconnected;

			/* XXX Shouldn't panic.  Just punt instead */
			if ((scb->hscb->control & TARGET_SCB) != 0)
				panic("Timed-out target SCB but bus idle");

			if (last_phase != P_BUSFREE
			 && (ahc_inb(ahc, SSTAT0) & TARGET) != 0) {
				/* XXX What happened to the SCB? */
				/* Hung target selection.  Goto busfree */
				printf("%s: Hung target selection\n",
				       ahc_name(ahc));
				ahc_restart(ahc);
				ahc_unlock(ahc, &s);
				return;
			}
			if (ahc_search_qinfifo(ahc, target, channel, lun,
					       scb->hscb->tag, ROLE_INITIATOR,
					       /*status*/0, SEARCH_COUNT) > 0) {
				disconnected = FALSE;
			} else {
				disconnected = TRUE;
			}
			
			if (disconnected) {

				ahc_set_recoveryscb(ahc, scb);
				/*
				 * Actually re-queue this SCB in an attempt
				 * to select the device before it reconnects.
				 * In either case (selection or reselection),
				 * we will now issue a target reset to the
				 * timed-out device.
				 *
				 * Set the MK_MESSAGE control bit indicating
				 * that we desire to send a message.  We
				 * also set the disconnected flag since
				 * in the paging case there is no guarantee
				 * that our SCB control byte matches the
				 * version on the card.  We don't want the
				 * sequencer to abort the command thinking
				 * an unsolicited reselection occurred.
				 */
				scb->hscb->control |= MK_MESSAGE|DISCONNECTED;
				scb->flags |= /*SCB_QUEUED_MSG | */
					SCB_DEVICE_RESET;
				
				/*
				 * Remove any cached copy of this SCB in the
				 * disconnected list in preparation for the
				 * queuing of our abort SCB.  We use the
				 * same element in the SCB, SCB_NEXT, for
				 * both the qinfifo and the disconnected list.
				 */
				ahc_search_disc_list(ahc, target, channel,
						     lun, scb->hscb->tag,
						     /*stop_on_first*/TRUE,
						     /*remove*/TRUE,
						     /*save_state*/FALSE);

				/*
				 * In the non-paging case, the sequencer will
				 * never re-reference the in-core SCB.
				 * To make sure we are notified during
				 * reslection, set the MK_MESSAGE flag in
				 * the card's copy of the SCB.
				 */
				if ((ahc->flags & AHC_PAGESCBS) == 0) {
					ahc_outb(ahc, SCBPTR, scb->hscb->tag);
					ahc_outb(ahc, SCB_CONTROL,
						 ahc_inb(ahc, SCB_CONTROL)
						| MK_MESSAGE);
				}
				/*
				 * Clear out any entries in the QINFIFO first
				 * so we are the next SCB for this target
				 * to run.
				 */
				ahc_search_qinfifo(ahc,
						   SCB_GET_TARGET(ahc, scb),
						   channel, SCB_GET_LUN(scb),
						   SCB_LIST_NULL,
						   ROLE_INITIATOR,
						   CAM_REQUEUE_REQ,
						   SEARCH_COMPLETE);
				ahc_print_path(ahc, scb);
				printf("Queuing a BDR SCB\n");
				ahc_qinfifo_requeue_tail(ahc, scb);
				ahc_outb(ahc, SCBPTR, saved_scbptr);
				timeout_add(&scb->io_ctx->stimeout, 2 * hz);
				ahc_unpause(ahc);
			} else {
				/* Go "immediatly" to the bus reset */
				/* This shouldn't happen */
				ahc_set_recoveryscb(ahc, scb);
				ahc_print_path(ahc, scb);
				printf("SCB %d: Immediate reset.  "
					"Flags = 0x%x\n", scb->hscb->tag,
					scb->flags);
				goto bus_reset;
			}
		}
	}
	ahc_unlock(ahc, &s);
}

void
ahc_send_async(ahc, channel, target, lun, code, opt_arg)
	struct ahc_softc *ahc;
	char channel;
	u_int target, lun, code;
	void *opt_arg;
{
	/* Nothing to do here for OpenBSD */
}

void
ahc_platform_set_tags(ahc, devinfo, alg)
	struct ahc_softc *ahc;
	struct ahc_devinfo *devinfo;
	ahc_queue_alg alg;
{
	struct ahc_initiator_tinfo *tinfo;
	struct ahc_tmode_tstate *tstate;

	tinfo = ahc_fetch_transinfo(ahc, devinfo->channel,
				    devinfo->our_scsiid,
				    devinfo->target,
				    &tstate);

	switch (alg) {
	case AHC_QUEUE_BASIC:
	case AHC_QUEUE_TAGGED:
		tstate->tagenable |= devinfo->target_mask;
		break;
	case AHC_QUEUE_NONE:
		tstate->tagenable &= ~devinfo->target_mask;
		break;
	}
}

int
ahc_platform_alloc(ahc, platform_arg)
	struct ahc_softc *ahc;
	void *platform_arg;
{
	ahc->platform_data = malloc(sizeof(struct ahc_platform_data), M_DEVBUF,
	    M_NOWAIT);
	if (ahc->platform_data == NULL)
		return (ENOMEM);
	bzero(ahc->platform_data, sizeof(struct ahc_platform_data));
	
	/* Just do some initialization... */
	ahc->scb_data = NULL;
	ahc->platform_data->ih = NULL;
	ahc->platform_data->channel_b_primary = FALSE;

	return (0);
}

void
ahc_platform_free(ahc)
	struct ahc_softc *ahc;
{
	free(ahc->platform_data, M_DEVBUF);
}

int
ahc_softc_comp(lahc, rahc)
	struct ahc_softc *lahc;
	struct ahc_softc *rahc;
{
	/* We don't sort softcs under OpenBSD so report equal always */
	return (0);
}

void
ahc_check_tags(ahc, xs)
	struct ahc_softc *ahc;
	struct scsi_xfer *xs;
{
	struct ahc_devinfo devinfo;

	if (xs->sc_link->quirks & SDEV_NOTAGS)
		return;

	if (ahc_istagged_device(ahc, xs, 1))
		return;

	ahc_compile_devinfo(&devinfo,
			    SCSI_SCSI_ID(ahc, xs->sc_link),
			    XS_SCSI_ID(xs),
			    XS_LUN(xs),
			    SCSI_CHANNEL(ahc, xs->sc_link),
			    ROLE_INITIATOR);

	ahc_set_tags(ahc, &devinfo, AHC_QUEUE_TAGGED);

	printf("%s: target %d using tagged queuing\n",
	       ahc_name(ahc), XS_SCSI_ID(xs));

	if (ahc->scb_data->maxhscbs >= 16 || 
	    (ahc->flags & AHC_PAGESCBS)) {
		/* Default to 16 tags */
		xs->sc_link->openings += 14;
	} else {
		/*	
		 * Default to 4 tags on whimpy
		 * cards that don't have much SCB
		 * space and can't page.  This prevents
		 * a single device from hogging all
		 * slots.  We should really have a better
		 * way of providing fairness.
		 */
		xs->sc_link->openings += 2;
	}
}

int
ahc_istagged_device(ahc, xs, nocmdcheck)
	struct ahc_softc *ahc;
	struct scsi_xfer *xs;
	int nocmdcheck;
{
	char channel;
	u_int our_id, target;
	struct ahc_tmode_tstate *tstate;
	struct ahc_devinfo devinfo;

	if (xs->sc_link->quirks & SDEV_NOTAGS)
		return 0;

	/*
	 * XXX never do these commands with tags. Should really be
	 * in a higher layer.
	 */
	if (!nocmdcheck && (xs->cmd->opcode == INQUIRY ||
	     xs->cmd->opcode == TEST_UNIT_READY ||
	     xs->cmd->opcode == REQUEST_SENSE))
		return 0;

	channel = SCSI_CHANNEL(ahc, xs->sc_link);
	our_id = SCSI_SCSI_ID(ahc, xs->sc_link);
	target = XS_SCSI_ID(xs);
	(void)ahc_fetch_transinfo(ahc, channel, our_id, target, &tstate);

	ahc_compile_devinfo(&devinfo, our_id, target, XS_LUN(xs),
			    channel, ROLE_INITIATOR);

	return (tstate->tagenable & devinfo.target_mask);
}

#if UNUSED
static void
ahc_dump_targcmd(cmd)
	struct target_cmd *cmd;
{
	uint8_t *byte;
	uint8_t *last_byte;
	int i;

	byte = &cmd->initiator_channel;
	/* Debugging info for received commands */
	last_byte = &cmd[1].initiator_channel;

	i = 0;
	while (byte < last_byte) {
		if (i == 0)
			printf("\t");
		printf("%#x", *byte++);
		i++;
		if (i == 8) {
			printf("\n");
			i = 0;
		} else {
			printf(", ");
		}
	}
}
#endif

#ifndef AHC_INLINES
/* 
 * This is a hack to keep from modifying the main
 * driver code as much as possible.  This function
 * does CAM to SCSI api stuff.
 */
void ahc_set_transaction_status(scb, status)
	struct scb *scb;
	uint32_t status;
{
	/* don't wipe the error */
	if (scb->io_ctx->error == XS_NOERROR){
		switch (status) {
		case CAM_CMD_TIMEOUT:
			status = XS_TIMEOUT;
			break;
		case CAM_BDR_SENT:
		case CAM_SCSI_BUS_RESET:
			status = XS_RESET;
			break;
		case CAM_UNEXP_BUSFREE:
		case CAM_REQ_TOO_BIG:
		case CAM_REQ_ABORTED:
		case CAM_AUTOSENSE_FAIL:
		case CAM_NO_HBA:
			status = XS_DRIVER_STUFFUP;
			break;
		case CAM_SEL_TIMEOUT:
			status = XS_SELTIMEOUT;
			break;
		case CAM_REQUEUE_REQ:
			scb->platform_data->flags |= SCB_REQUEUE;
			scb->io_ctx->error = XS_NOERROR;
			break;
		case CAM_SCSI_STATUS_ERROR:
		default:
			status = scb->io_ctx->error;
			break;
		}
	} else {
		status = scb->io_ctx->error;
	}
	scb->io_ctx->error = status;
}

void ahc_set_transaction_tag(scb, enabled, type)
	struct scb *scb;
	int enabled;
	u_int type;
{
	struct scsi_xfer *xs = scb->io_ctx;
	switch (type) {
	case MSG_SIMPLE_TASK:
	case MSG_ORDERED_TASK:
		if (enabled)
			xs->sc_link->quirks &= ~SDEV_NOTAGS;
		else
			xs->sc_link->quirks |= SDEV_NOTAGS;
		break;
	}
}

void ahc_platform_scb_free(ahc, scb)
	struct ahc_softc *ahc;
	struct scb *scb;
{
	int s;

	ahc_lock(ahc, &s);
	
	if ((ahc->flags & AHC_RESOURCE_SHORTAGE) != 0 ||
	    (scb->flags & SCB_RECOVERY_SCB) != 0) {
		ahc->flags &= ~AHC_RESOURCE_SHORTAGE;
		ahc->platform_data->queue_blocked = 0;
	}
	
	timeout_del(&scb->io_ctx->stimeout);
	
	ahc_unlock(ahc, &s);
}
#endif
@


1.1.1.1
log
@Import OpenBSD 3.3 source repository from CTM 3132 the first time
This opens an OpenBSD-mirabile (aka MirBSD) repository.

### MirBSD is:
# Copyright (c) 1982-2003 by Thorsten "mirabile" Glaser <x86@@ePost.de>
# Copyright © 1968-2003  The authors of And contributors to UNIX®, the
#       C Language, BSD/Berkeley Unix; 386BSD, NetBSD 1.1 and OpenBSD.
#
# Anyone who obtained a copy of this work is hereby permitted to freely use,
# distribute, modify, merge, sublicence, give away or sell it as long as the
# authors are given due credit and the following notice is retained:
#
# This work is provided "as is", with no explicit or implicit warranty what-
# soever. Use it only at your own risk. In no event may an author or contri-
# butor be held liable for any damage, directly or indirectly, that origina-
# ted through or is caused by creation or modification of this work.

MirBSD is my private tree. MirBSD does not differ very much from OpenBSD
and intentionally tracks OpenBSD. That's why it _is_ OpenBSD, just not the
official one. It's like with DarrenBSD.

At time of this writing, no advertising for MirBSD must be done,
because the advertising clause has not yet been sorted out.

http://templeofhate.com/tglaser/MirBSD/index.php
@
text
@@


1.1.1.2
log
@Import OpenBSD repository of CTM 3155 (roughly today at noon).
Mostly in order to go 3.3-current and ease further merges of
both OpenBSD and ELFdiffs after the MirBSD has been enabled
to build again.
@
text
@d32 1
a32 1
 * $Id: aic7xxx_openbsd.c,v 1.11 2003/03/21 14:58:06 drahn Exp $
d35 1
a35 1
 * $OpenBSD: aic7xxx_openbsd.c,v 1.11 2003/03/21 14:58:06 drahn Exp $
d734 1
a734 1
		       ahc_le32toh(scb->sg_list->len) & AHC_SG_LEN_MASK);
d1066 1
a1066 1
		scb->hscb->sgptr = ahc_htole32(SG_LIST_NULL);
d1098 5
@


1.1.1.3
log
@Import OpenBSD cvs as of now, CTM delta 3255, just before the i386 flag day
@
text
@d32 1
a32 1
 * $Id: aic7xxx_openbsd.c,v 1.12 2003/04/27 11:22:52 ho Exp $
d35 1
a35 1
 * $OpenBSD: aic7xxx_openbsd.c,v 1.12 2003/04/27 11:22:52 ho Exp $
d516 1
a516 1
	ahc_controller_info(ahc, ahc_info, sizeof ahc_info);
@


1.1.1.4
log
@Import OpenBSD source tree again, with critical bug fixes
(OpenSSL, bc, dc, sensorsd, pf, ...)
@
text
@d32 1
a32 1
 * $Id: aic7xxx_openbsd.c,v 1.13 2003/09/29 19:28:16 mickey Exp $
d35 1
a35 1
 * $OpenBSD: aic7xxx_openbsd.c,v 1.13 2003/09/29 19:28:16 mickey Exp $
d97 1
a97 1
 * Routines to manage busy targets.  The old driver didn't need to
d112 1
a112 1
	u_int retval;
d136 1
a136 1

d153 1
a153 1
void
d159 1
a159 1

d201 1
a201 1

d204 1
a204 1

d295 2
a296 2

	if (ahc_createdmamem(ahc, scb_data->sg_dmat, PAGE_SIZE,
d298 1
a298 1
			     &sg_map->sg_physaddr, &sg_map->sg_dmasegs,
d313 1
a313 1

d329 1
a329 1

d331 1
a331 1
		dma_flags = ((ahc->chip & AHC_VL) !=0) ?
d334 1
a334 1

d338 1
a338 1
					  MAXBSIZE, 0, dma_flags,
d340 1
a340 1
		if (error !=0)
d342 1
a342 1

d377 1
a377 1

d404 2
a405 2
	    AHC_SCB_MAX * sizeof(struct hardware_scb),
	    &scb_data->hscb_dmamap, (caddr_t *)&scb_data->hscbs,
d409 1
a409 1

d421 1
a421 1

d442 1
a442 1
	return (0);
d481 1
a481 1
			       AHC_SCB_MAX * sizeof(struct hardware_scb),
d515 1
a515 1

d538 1
a538 1

d589 2
a590 2
	ahc = (struct ahc_softc *)arg;

d592 1
a592 1

d594 1
a594 1
	if ((ahc->chip & AHC_PCI) != 0) {
d606 1
a606 1

d611 1
a611 5

	bus_dmamap_sync(ahc->scb_data->hscb_dmat, ahc->scb_data->hscb_dmamap,
	    0, ahc->scb_data->hscb_dmamap->dm_mapsize,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

d613 1
a613 1
	return 1;
d633 1
a633 5

	bus_dmamap_sync(ahc->scb_data->hscb_dmat, ahc->scb_data->hscb_dmamap,
	    0, ahc->scb_data->hscb_dmamap->dm_mapsize,
	    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

d642 2
a643 2
#endif

d655 1
a655 1

d661 3
a663 3
		printf("ahc_done: opcode 0x%x tag %x flags %x status %d error %d\n",
		    xs->cmdstore.opcode, scb->hscb->tag,
		    scb->flags, xs->status, xs->error);
d666 1
a666 1

d672 1
a672 1

d680 1
a680 1

d686 1
a686 1
	 * XXX if we are holding two commands per lun,
d734 1
a734 1
		    ahc_le32toh(scb->sg_list->len) & AHC_SG_LEN_MASK);
d737 1
a737 1

d745 1
a745 1

d803 1
a803 1
	struct hardware_scb *hscb;
d845 1
a845 1

d851 1
a851 1

d932 1
a932 1

d935 1
a935 1

d937 1
a937 1

d947 1
a947 1

d964 1
a964 1

d968 1
a968 1

d986 1
a986 1

d1021 1
a1021 1

d1041 1
a1041 1

d1044 1
a1044 1
		 * We also set the full residual flag which the
d1049 1
a1049 1

d1058 1
a1058 1

a1061 4
		bus_dmamap_sync(ahc->scb_data->sg_dmat, scb->sg_map->sg_dmamap,
		    0, scb->sg_map->sg_dmamap->dm_mapsize,
		    BUS_DMASYNC_PREWRITE);

d1070 1
a1070 1

d1084 1
a1084 1

d1087 1
a1087 1

d1116 1
a1116 5

	bus_dmamap_sync(ahc->scb_data->hscb_dmat, ahc->scb_data->hscb_dmamap,
	    0, ahc->scb_data->hscb_dmamap->dm_mapsize,
	    BUS_DMASYNC_PREREAD | BUS_DMASYNC_PREWRITE);

d1124 2
a1125 2
		       xs->cmdstore.opcode, scb->hscb->tag,
		       scb->hscb->cdb_len, scb->flags,
d1137 1
a1137 1
	 * This really should not be of any
d1155 1
a1155 1

d1179 1
a1179 1

d1213 1
a1213 1

d1215 1
a1215 1

d1226 1
a1226 1

d1230 1
a1230 1

a1246 1
		ahc->buffer_dmat = ahc->parent_dmat;
d1253 1
a1253 1
			if (!ahc_istagged_device(ahc, xs, 0)) {
d1309 1
a1309 1
	scb = (struct scb *)arg;
d1330 1
a1330 1

d1337 1
a1337 1

d1344 1
a1344 1

d1353 1
a1353 1

d1368 1
a1368 1
		 *
a1389 5
		bus_dmamap_sync(ahc->scb_data->hscb_dmat,
		    ahc->scb_data->hscb_dmamap,
		    0, ahc->scb_data->hscb_dmamap->dm_mapsize,
		    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);

d1392 2
a1393 2

		if (last_phase != P_BUSFREE
d1403 1
a1403 1
			 */
d1420 2
a1421 2
			}

d1439 1
a1439 1
			}
a1451 4
			bus_dmamap_sync(ahc->scb_data->hscb_dmat,
			    ahc->scb_data->hscb_dmamap,
			    0, ahc->scb_data->hscb_dmamap->dm_mapsize,
			    BUS_DMASYNC_POSTREAD | BUS_DMASYNC_POSTWRITE);
d1473 1
a1473 1

d1496 1
a1496 1

d1601 1
a1601 1

d1651 1
a1651 1
	if (ahc->scb_data->maxhscbs >= 16 ||
d1656 1
a1656 1
		/*
d1732 1
a1732 1
/*
d1800 1
a1800 1

d1806 1
a1806 1

d1808 1
a1808 1

@


1.1.1.5
log
@Time to import OpenBSD once again. Expect breakage.
@
text
@d32 1
a32 1
 * $Id: aic7xxx_openbsd.c,v 1.14 2003/10/21 18:58:48 jmc Exp $
d35 1
a35 1
 * $OpenBSD: aic7xxx_openbsd.c,v 1.14 2003/10/21 18:58:48 jmc Exp $
d734 1
a734 1
		 * that any untransferred data should be
d795 1
a795 1
	 * discontinuous physically, hence the "page per segment" limit
d1389 1
a1389 1
		 * If the bus is idle and we are acting as the initiator
@


1.1.1.6
log
@Import OpenBSD again, for various reasons.
@
text
@a0 3
/*	$OpenBSD: aic7xxx_openbsd.c,v 1.16 2003/12/28 21:29:27 krw Exp $	*/
/*	$NetBSD: aic7xxx_osm.c,v 1.14 2003/11/02 11:07:44 wiz Exp $	*/

d32 1
a32 1
 * //depot/aic7xxx/freebsd/dev/aic7xxx/aic7xxx_osm.c#12 $
d34 2
a35 4
 * $FreeBSD: src/sys/dev/aic7xxx/aic7xxx_osm.c,v 1.31 2002/11/30 19:08:58 scottl Exp $
 */
/*
 * Ported from FreeBSD by Pascal Renauld, Network Storage Solutions, Inc. - April 2003
a37 3
#include <sys/cdefs.h>
/* __KERNEL_RCSID(0, "$NetBSD: aic7xxx_osm.c,v 1.14 2003/11/02 11:07:44 wiz Exp $"); */

a40 17
#ifndef AHC_TMODE_ENABLE
#define AHC_TMODE_ENABLE 0
#endif


int32_t		ahc_action(struct scsi_xfer *);
int		ahc_execute_scb(void *, bus_dma_segment_t *, int);
int		ahc_poll(struct ahc_softc *, int);
int		ahc_setup_data(struct ahc_softc *, struct scsi_xfer *,
			       struct scb *);
void		ahc_set_recoveryscb(struct ahc_softc *, struct scb *);

static void	ahc_minphys(struct buf *);
void		ahc_adapter_req_set_xfer_mode(struct ahc_softc *, struct scb *);



d45 3
d65 440
d509 2
a510 1
ahc_attach(struct ahc_softc *ahc)
d512 3
a514 2
	char ahc_info[256];
	int i, s;
d516 6
a521 5
	LIST_INIT(&ahc->pending_scbs);
	for (i = 0; i < AHC_NUM_TARGETS; i++)
		TAILQ_INIT(&ahc->untagged_queues[i]);

        ahc_lock(ahc, &s);
d523 4
d530 1
a530 1
	ahc->sc_channel.adapter_target = ahc->our_id;
d532 6
a537 6
		ahc->sc_channel.adapter_buswidth = 16;
	ahc->sc_channel.adapter_softc = ahc;
	ahc->sc_channel.adapter = &ahc_switch;
	ahc->sc_channel.openings = 16;
	ahc->sc_channel.device = &ahc_dev;
	ahc->sc_channel.flags = SCSIDEBUG_LEVEL;
d541 9
a549 2
		ahc->sc_channel_b = ahc->sc_channel;
		ahc->sc_channel_b.adapter_target = ahc->our_id_b;
d552 7
a558 19
	ahc_controller_info(ahc, ahc_info, sizeof ahc_info);
	printf("%s: %s\n", ahc->sc_dev.dv_xname, ahc_info);

	ahc_intr_enable(ahc, TRUE);

	if (ahc->flags & AHC_RESET_BUS_A)
		ahc_reset_channel(ahc, 'A', TRUE);
	if ((ahc->features & AHC_TWIN) && ahc->flags & AHC_RESET_BUS_B)
		ahc_reset_channel(ahc, 'B', TRUE);

	if ((ahc->flags & AHC_PRIMARY_CHANNEL) == 0) {
		/*
		 * Ensure SCSI_IS_SCSIBUS_B() returns false for sc_channel
		 * until sc_channel_b has been properly initialized by scsi
		 * layer.
		 */
		ahc->sc_channel_b.scsibus = 0xff;
		ahc->sc_child = config_found((void *)&ahc->sc_dev,
		    &ahc->sc_channel, scsiprint);
d560 1
a560 2
			ahc->sc_child_b = config_found((void *)&ahc->sc_dev,
			    &ahc->sc_channel_b, scsiprint);
d563 3
a565 3
		 * Ensure SCSI_IS_SCSIBUS_B() returns false for sc_channel_b
		 * until sc_channel has been properly initialized by scsi
		 * layer.
a566 1
		ahc->sc_channel.scsibus = 0xff;
d568 2
a569 4
			ahc->sc_child = config_found((void *)&ahc->sc_dev,
			    &ahc->sc_channel_b, scsiprint);
		ahc->sc_child_b = config_found((void *)&ahc->sc_dev,
		    &ahc->sc_channel, scsiprint);
a570 1

d572 1
a572 1
	return (1);
d579 2
a580 1
ahc_platform_intr(void *arg)
d582 8
a589 1
	struct	ahc_softc *ahc = (struct ahc_softc *)arg;
d591 22
a612 1
	bus_dmamap_sync(ahc->parent_dmat, ahc->scb_data->hscb_dmamap,
d616 2
a617 1
	return ahc_intr(ahc);
d626 3
a628 1
ahc_done(struct ahc_softc *ahc, struct scb *scb)
d630 7
a636 2
	struct scsi_xfer *xs = scb->xs;
	int s;
d638 1
a638 1
	bus_dmamap_sync(ahc->parent_dmat, ahc->scb_data->hscb_dmamap,
d642 10
d666 12
d685 14
a698 3
		bus_dmamap_sync(ahc->parent_dmat, scb->dmamap, 0,
				scb->dmamap->dm_mapsize, op);
		bus_dmamap_unload(ahc->parent_dmat, scb->dmamap);
d714 1
a714 1
			struct scsi_xfer *txs = list_scb->xs;
d716 2
a717 2
				timeout_add(&list_scb->xs->stimeout,
				    (list_scb->xs->timeout * hz)/1000);
d720 1
a720 1
		if (xs->error != CAM_REQ_INPROG)
a725 26
	/* Translate the CAM status code to a SCSI error code. */
	switch (xs->error) {
	case CAM_REQ_INPROG:
	case CAM_REQ_CMP:
		xs->error = XS_NOERROR;
		break;
	case CAM_BUSY:
		xs->error = XS_BUSY;
		break;
	case CAM_CMD_TIMEOUT:
		xs->error = XS_TIMEOUT;
		break;
	case CAM_BDR_SENT:
	case CAM_SCSI_BUS_RESET:
	case CAM_REQUEUE_REQ:
		xs->error = XS_RESET;
		break;
	case CAM_SEL_TIMEOUT:
		xs->error = XS_SELTIMEOUT;
		break;
	default:
		xs->error = XS_DRIVER_STUFFUP;
		break;
	}

	/* Don't clobber any existing error state */
d727 1
a727 1
	  /* Don't clobber any existing error state */
d732 7
a738 6
		 * Zero any sense not transferred by the
		 * device.  The SCSI spec mandates that any
		 * untransferred data should be assumed to be
		 * zero.  Complete the 'bounce' of sense information
		 * through buffers accessible via bus-space by
		 * copying it into the clients csio.
d745 7
a751 2
	if (scb->flags & SCB_FREEZE_QUEUE) {
		scb->flags &= ~SCB_FREEZE_QUEUE;
d754 1
a754 1
        ahc_lock(ahc, &s);       
a755 1
        ahc_unlock(ahc, &s);       
d757 28
a784 2
	xs->flags |= ITSDONE;
	scsi_done(xs);
d805 2
a806 1
ahc_action(struct scsi_xfer *xs)
d808 1
d812 2
d816 4
a819 2
	int s;
	int dontqueue = 0;
d824 52
d879 27
a911 1
	ahc_lock(ahc, &s);
d913 16
d930 1
a930 2
		xs->error = XS_DRIVER_STUFFUP;
		return (TRY_AGAIN_LATER);
a931 1
	ahc_unlock(ahc, &s);
d933 9
d944 22
a965 2
	SC_DEBUG(periph, SCSIPI_DB3, ("start scb(%p)\n", scb));
	scb->xs = xs;
a969 1
	hscb->control = 0;
d971 33
a1003 3
	hscb->lun = xs->sc_link->lun;
	if (xs->xs_control & XS_CTL_RESET) {
		hscb->cdb_len = 0;
d1006 1
a1006 1
		ahc_execute_scb(scb, NULL, 0);
a1008 2
	timeout_set(&xs->stimeout, ahc_timeout, scb);

d1013 4
a1016 1
ahc_execute_scb(void *arg, bus_dma_segment_t *dm_segs, int nsegments)
a1022 1

d1024 1
a1024 1
	int	s, target;
d1027 1
a1027 3
	xs = scb->xs;
	xs->error = CAM_REQ_INPROG;
	xs->status = 0;
d1034 1
a1034 1
		
d1052 1
a1052 1
		 * We also set the full residual flag which the 
d1063 3
a1065 2
		bus_dmamap_sync(ahc->parent_dmat, scb->dmamap, 0,
				scb->dmamap->dm_mapsize, op);
d1070 1
a1070 1
		bus_dmamap_sync(ahc->parent_dmat, scb->sg_map->sg_dmamap,
d1092 5
d1098 1
a1098 1
			bus_dmamap_unload(ahc->parent_dmat, scb->dmamap);
d1105 5
a1117 1

d1122 1
a1122 1
	    	scb->hscb->control |= DISCENB;
d1129 1
a1129 4
	if ((tstate->tagenable & mask) != 0)
		ahc_set_transaction_tag(scb, TRUE, MSG_SIMPLE_TASK);

	bus_dmamap_sync(ahc->parent_dmat, ahc->scb_data->hscb_dmamap,
d1135 11
a1145 2
	if (!(xs->flags & SCSI_POLL))
		timeout_add(&xs->stimeout, (xs->timeout * hz) / 1000);
d1158 1
a1158 1
	    && (ahc->flags & AHC_SCB_BTT) == 0) {
d1171 1
d1174 3
d1183 2
a1184 1
		ahc_outb(ahc, TARG_IMMEDIATE_SCB, scb->hscb->tag);
d1190 1
a1199 18

	target = xs->sc_link->target;
	if (ahc->inited_target[target] == INITED_TARGET_INQUIRYOK) {
		struct	ahc_initiator_tinfo *tinfo;
		struct	ahc_tmode_tstate *tstate;
		struct	ahc_devinfo devinfo;

		ahc_adapter_req_set_xfer_mode(ahc, scb);

		ahc_scb_devinfo(ahc, &devinfo, scb);
		tinfo = ahc_fetch_transinfo(ahc, devinfo.channel,
		    devinfo.our_scsiid, devinfo.target, &tstate);
		ahc_update_neg_request(ahc, &devinfo, tstate, tinfo,
		    AHC_NEG_IF_NON_ASYNC);

		ahc->inited_target[target] = INITED_TARGET_MODEOK;
	}

a1207 6

	if (ahc->inited_target[target] == INITED_TARGET_START) {
		if ((xs->cmd->opcode == INQUIRY) && (xs->error == XS_NOERROR))
			ahc->inited_target[target] = INITED_TARGET_INQUIRYOK;
	}

d1213 3
a1215 1
ahc_poll(struct ahc_softc *ahc, int wait)
d1219 2
d1231 1
d1236 4
a1239 2
ahc_setup_data(struct ahc_softc *ahc, struct scsi_xfer *xs,
	       struct scb *scb)
d1242 1
a1242 1
	
d1245 1
a1245 1
	xs->error = CAM_REQ_INPROG;
a1247 10
	if (hscb->cdb_len > sizeof(hscb->cdb32)) {
		int s;

		ahc_set_transaction_status(scb, CAM_REQ_INVALID);
		ahc_lock(ahc, &s);
		ahc_free_scb(ahc, scb);
		ahc_unlock(ahc, &s);
		scsi_done(xs);
		return (COMPLETE);
	}
d1250 2
a1251 1
		memcpy(hscb->cdb32, xs->cmd, hscb->cdb_len);
d1254 3
a1256 1
		memcpy(hscb->shared_data.cdb, xs->cmd, hscb->cdb_len);
d1258 1
a1258 1
		
d1263 2
a1264 1
                error = bus_dmamap_load(ahc->parent_dmat,
d1270 3
a1272 7
#ifdef AHC_DEBUG
                        printf("%s: in ahc_setup_data(): bus_dmamap_load() "
			       "= %d\n",
			       ahc_name(ahc), error);
#endif
			xs->error = XS_BUSY;
			scsi_done(xs);
d1274 1
a1274 1
}
d1285 4
a1288 1
ahc_set_recoveryscb(struct ahc_softc *ahc, struct scb *scb) {
d1296 7
d1308 1
a1308 1
			timeout_del(&list_scb->xs->stimeout);
d1314 2
a1315 1
ahc_timeout(void *arg)
d1319 1
a1319 2
	int	s;
	int	found;
d1327 1
a1327 1
	ahc = (struct ahc_softc *)scb->xs->sc_link->adapter_softc;
d1331 6
d1354 5
d1361 1
d1370 1
d1385 1
a1385 1
		 * 
d1407 1
a1407 1
		bus_dmamap_sync(ahc->parent_dmat,
d1415 2
a1416 1
		if ((ahc_inb(ahc, SEQ_FLAGS) & NOT_IDENTIFIED) == 0
d1421 5
a1425 5
			 * If the active SCB is not us, assume that
			 * the active SCB has a longer timeout than
			 * the timedout SCB, and wait for the active
			 * SCB to timeout.
			 */ 
d1432 1
a1432 1
			 	       (scb->flags & SCB_OTHERTCL_TIMEOUT) != 0
d1435 3
a1437 3
				newtimeout = MAX(active_scb->xs->timeout,
						 scb->xs->timeout);
				timeout_add(&scb->xs->stimeout,
d1442 1
a1442 1
			} 
d1445 1
a1445 1
			if ((scb->flags & SCB_TARGET_SCB) != 0) {
d1451 5
a1455 6
				ahc_abort_scbs(ahc, SCB_GET_TARGET(ahc, scb),
					       SCB_GET_CHANNEL(ahc, scb),
					       SCB_GET_LUN(scb),
					       scb->hscb->tag,
					       ROLE_TARGET,
					       CAM_CMD_TIMEOUT);
d1464 1
a1464 1
			ahc_outb(ahc, MSG_OUT, HOST_MSG);
d1469 1
a1469 1
			timeout_add(&active_scb->xs->stimeout, 2 * hz);
d1474 1
a1474 1
			bus_dmamap_sync(ahc->parent_dmat,
d1479 1
a1479 1
			if ((scb->flags & SCB_TARGET_SCB) != 0)
a1491 1

d1520 2
a1521 1
				scb->flags |= SCB_DEVICE_RESET;
a1548 1

d1565 1
a1565 1
				timeout_add(&scb->xs->stimeout, 2 * hz);
d1568 2
a1569 2
				/* Go "immediately" to the bus reset. */
				/* This shouldn't happen. */
d1582 9
d1593 4
a1596 2
ahc_platform_set_tags(struct ahc_softc *ahc,
		      struct ahc_devinfo *devinfo, int alg)
d1598 1
d1601 4
a1604 4
	ahc_fetch_transinfo(ahc, devinfo->channel, devinfo->our_scsiid,
			    devinfo->target, &tstate);

	/* XXXX Need to check quirks before doing this! XXXX */
d1618 3
a1620 1
ahc_platform_alloc(struct ahc_softc *ahc, void *platform_arg)
d1622 10
a1631 7
	if (sizeof(struct ahc_platform_data) > 0) {
		ahc->platform_data = malloc(sizeof(struct ahc_platform_data),
		    M_DEVBUF, M_NOWAIT);
		if (ahc->platform_data == NULL)
			return (ENOMEM);
		bzero(ahc->platform_data, sizeof(struct ahc_platform_data));
	}
d1637 2
a1638 1
ahc_platform_free(struct ahc_softc *ahc)
d1640 1
a1640 2
	if (sizeof(struct ahc_platform_data) > 0)
		free(ahc->platform_data, M_DEVBUF);
d1644 3
a1646 1
ahc_softc_comp(struct ahc_softc *lahc, struct ahc_softc *rahc)
d1648 1
d1653 3
a1655 2
ahc_send_async(struct ahc_softc *ahc, char channel, u_int target, u_int lun,
		u_int code, void *opt_arg)
d1657 35
a1691 1
	/* Nothing to do here for OpenBSD */
d1694 5
a1698 2
void
ahc_adapter_req_set_xfer_mode(struct ahc_softc *ahc, struct scb *scb)
d1700 2
a1701 1
	struct ahc_initiator_tinfo *tinfo;
a1702 1
	struct ahc_syncrate *syncrate;
a1703 3
	u_int16_t quirks;
	u_int width, ppr_options, period, offset;
	int s;
d1705 51
a1755 1
	s = splbio();
d1757 39
a1795 25
	ahc_scb_devinfo(ahc, &devinfo, scb);
	quirks = scb->xs->sc_link->quirks;
	tinfo = ahc_fetch_transinfo(ahc, devinfo.channel,
	    devinfo.our_scsiid, devinfo.target, &tstate);

	tstate->discenable |= (ahc->user_discenable & devinfo.target_mask);

	if (quirks & SDEV_NOTAGS)
		tstate->tagenable &= ~devinfo.target_mask;
	else if (ahc->user_tagenable & devinfo.target_mask)
		tstate->tagenable |= devinfo.target_mask;

	if (quirks & SDEV_NOWIDE)
		width = MSG_EXT_WDTR_BUS_8_BIT;
	else
		width = MSG_EXT_WDTR_BUS_16_BIT;

	ahc_validate_width(ahc, NULL, &width, ROLE_UNKNOWN);
	if (width > tinfo->user.width)
		width = tinfo->user.width;
	ahc_set_width(ahc, &devinfo, width, AHC_TRANS_GOAL, FALSE);

	if (quirks & SDEV_NOSYNC) {
		period = 0;
		offset = 0;
d1797 1
a1797 2
		period = tinfo->user.period;
		offset = tinfo->user.offset;
d1799 2
d1802 16
a1817 5
	/* XXX Look at saved INQUIRY flags for PPR capabilities XXX */ 
	ppr_options = tinfo->user.ppr_options;
	/* XXX Other reasons to avoid ppr? XXX */
	if (width < MSG_EXT_WDTR_BUS_16_BIT)
		ppr_options = 0;
d1819 5
a1823 3
	if ((tstate->discenable & devinfo.target_mask) == 0 ||
	    (tstate->tagenable & devinfo.target_mask) == 0)
		ppr_options &= ~MSG_EXT_PPR_PROT_IUS;
d1825 1
a1825 9
	syncrate = ahc_find_syncrate(ahc, &period, &ppr_options,
	    AHC_SYNCRATE_MAX);
	ahc_validate_offset(ahc, NULL, syncrate, &offset, width,
	    ROLE_UNKNOWN);

	if (offset == 0) {
		period = 0;
		ppr_options = 0;
	}
d1827 4
a1830 3
	if (ppr_options != 0 && tinfo->user.transport_version >= 3) {
		tinfo->goal.transport_version = tinfo->user.transport_version;
		tinfo->curr.transport_version = tinfo->user.transport_version;
d1833 1
a1833 2
	ahc_set_syncrate(ahc, &devinfo, syncrate, period, offset, ppr_options,
	    AHC_TRANS_GOAL, FALSE);
d1835 1
a1835 1
	splx(s);
d1837 1
@


1.1.1.7
log
@Import OpenBSD as of today again (seems pretty stable, I hope)

Prominent changes: more bgpd, tcpmd5; tcpdump/isakmpd fixes
@
text
@d1 1
a1 1
/*	$OpenBSD: aic7xxx_openbsd.c,v 1.21 2004/01/24 15:49:31 krw Exp $	*/
d54 9
a62 5
int	ahc_action(struct scsi_xfer *);
int	ahc_execute_scb(void *, bus_dma_segment_t *, int);
int	ahc_poll(struct ahc_softc *, int);
int	ahc_setup_data(struct ahc_softc *, struct scsi_xfer *, struct scb *);
void	ahc_set_recoveryscb(struct ahc_softc *, struct scb *);
a63 2
void	ahc_minphys(struct buf *);
void	ahc_adapter_req_set_xfer_mode(struct ahc_softc *, struct scb *);
d112 1
d120 2
a121 4
	if (bootverbose) {
		ahc_controller_info(ahc, ahc_info, sizeof ahc_info);
		printf("%s: %s\n", ahc->sc_dev.dv_xname, ahc_info);
	}
d245 1
a245 26
		switch (xs->status) {
		case SCSI_TASKSET_FULL:
			/* SCSI Layer won't requeue, so we force infinite
			 * retries until queue space is available. XS_BUSY
			 * is dangerous because if the NOSLEEP flag is set
			 * it can cause the I/O to return EIO. XS_BUSY code
			 * falls through to XS_TIMEOUT anyway.
			 */
			xs->error = XS_TIMEOUT;
			xs->retries++;
			break;
		case SCSI_BUSY:
			xs->error = XS_BUSY;
			break;
		case SCSI_CHECK:
		case SCSI_TERMINATED:
			if ((scb->flags & SCB_SENSE) == 0) {
				/* CHECK on CHECK? */
				xs->error = XS_DRIVER_STUFFUP;
			} else
				xs->error = XS_NOERROR;
			break;
		default:
			xs->error = XS_NOERROR;
			break;
		}
d255 1
a256 3
	case CAM_REQUEUE_REQ:
		xs->error = XS_TIMEOUT;
		xs->retries++;
d297 1
a297 1
void
d347 1
a347 1
	SC_DEBUG(xs->sc_link, SDEV_DB3, ("start scb(%p)\n", scb));
d378 1
a378 1
	int	s;
d476 1
a476 1
		scb->hscb->control |= TAG_ENB;
d507 2
a508 6
			if (xs->flags & SCSI_POLL)
				goto poll;
			else {		
				ahc_unlock(ahc, &s);
				return (SUCCESSFULLY_QUEUED);
			}
a525 11
		if (ahc->inited_target[xs->sc_link->target] == 0) {
			struct	ahc_devinfo devinfo;

			ahc_adapter_req_set_xfer_mode(ahc, scb);
			ahc_scb_devinfo(ahc, &devinfo, scb);
			ahc_update_neg_request(ahc, &devinfo, tstate, tinfo,
			    AHC_NEG_IF_NON_ASYNC);

			ahc->inited_target[xs->sc_link->target] = 1;
		}

a532 1
poll:
d535 17
d561 5
a605 1
		xs->flags |= ITSDONE;
a632 1
			xs->flags |= ITSDONE;
@


