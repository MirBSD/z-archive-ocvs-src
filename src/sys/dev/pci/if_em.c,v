head	1.1;
branch	1.1.1;
access;
symbols
	tg-mergetmp-mirosx-1:1.1.1.6
	tg-mergefixes-1-branch:1.1.1.6.0.8
	tg-mergefixes-1-base:1.1.1.6
	MIROS_X:1.1.1.6.0.6
	MIROS_X_BASE:1.1.1.6
	tg-mergetmp-3:1.1.1.6
	MIRBSD_XP_MIRPPC:1.1.1.6.0.4
	MIRBSD_XP_SPARC_BASE:1.1.1.6
	MIRBSD_XP_SPARC:1.1.1.6.0.2
	MIRBSD_7quater:1.1.1.4
	cvs-200405160640:1.1.1.6
	cvs-200401271800:1.1.1.5
	cvs-200401261630:1.1.1.5
	cvs-200401021645:1.1.1.5
	MIRBSD_7_ALPHA:1.1.1.4.0.6
	MIRBSD_7:1.1.1.4.0.4
	cvs-200312222040:1.1.1.5
	MIRBSD_7ter:1.1.1.4
	MIRBSD_7_DEV:1.1.1.4.0.2
	cvs-200310020700:1.1.1.4
	cvs-200309271030:1.1.1.4
	cvs-200309261655:1.1.1.4
	cvs-200309252100:1.1.1.4
	cvs-200309251530:1.1.1.4
	cvs-200308302005:1.1.1.4
	cvs-200308171200:1.1.1.3
	ctm-3496:1.1.1.3
	ctm-3449:1.1.1.3
	ctm-3437:1.1.1.3
	cvs-200307191805:1.1.1.3
	ctm-3425:1.1.1.3
	cvs-200307091500:1.1.1.3
	cvs-200307072125:1.1.1.3
	ctm-3389:1.1.1.3
	cvs-200307021520:1.1.1.3
	cvs-200306301405:1.1.1.3
	cvs-200306291430:1.1.1.2
	ctm-3341:1.1.1.2
	MIRBSD_5:1.1.1.1
	cvs-200306082100:1.1.1.1
	ctm-3316:1.1.1.1
	ctm-3272:1.1.1.1
	cvs-200305131745:1.1.1.1
	ctm-3264:1.1.1.1
	cvs-200305071630:1.1.1.1
	ctm-3255:1.1.1.1
	ctm-3229:1.1.1.1
	MIRBSD_4:1.1.1.1
	ctm-3203:1.1.1.1
	cvs-20030410-1130:1.1.1.1
	ctm-3155:1.1.1.1
	ctm-3132:1.1.1.1
	openbsd:1.1.1;
locks; strict;
comment	@ * @;


1.1
date	2003.03.22.17.51.21;	author tg;	state Exp;
branches
	1.1.1.1;
next	;

1.1.1.1
date	2003.03.22.17.51.21;	author tg;	state Exp;
branches;
next	1.1.1.2;

1.1.1.2
date	2003.06.19.12.49.47;	author tg;	state Exp;
branches;
next	1.1.1.3;

1.1.1.3
date	2003.06.30.14.12.28;	author tg;	state Exp;
branches;
next	1.1.1.4;

1.1.1.4
date	2003.08.30.23.22.35;	author tg;	state Exp;
branches;
next	1.1.1.5;

1.1.1.5
date	2003.12.22.21.03.00;	author tg;	state Exp;
branches;
next	1.1.1.6;

1.1.1.6
date	2004.05.16.09.01.00;	author tg;	state Stab;
branches;
next	;


desc
@@


1.1
log
@Initial revision
@
text
@/**************************************************************************

Copyright (c) 2001-2002 Intel Corporation
All rights reserved.

Redistribution and use in source and binary forms of the Software, with or
without modification, are permitted provided that the following conditions
are met:

 1. Redistributions of source code of the Software may retain the above
    copyright notice, this list of conditions and the following disclaimer.

 2. Redistributions in binary form of the Software may reproduce the above
    copyright notice, this list of conditions and the following disclaimer
    in the documentation and/or other materials provided with the
    distribution.

 3. Neither the name of the Intel Corporation nor the names of its
    contributors shall be used to endorse or promote products derived from
    this Software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE
ARE DISCLAIMED. IN NO EVENT SHALL THE INTEL OR ITS CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY
OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF
SUCH DAMAGE.

***************************************************************************/

/*$FreeBSD$*/

#include "bpfilter.h"
#include "vlan.h"

#include <sys/param.h>
#include <sys/systm.h>
#include <sys/sockio.h>
#include <sys/mbuf.h>
#include <sys/malloc.h>
#include <sys/kernel.h>
#include <sys/device.h>
#include <sys/socket.h>

#include <net/if.h>
#include <net/if_dl.h>
#include <net/if_media.h>

#ifdef INET
#include <netinet/in.h>
#include <netinet/in_systm.h>
#include <netinet/in_var.h>
#include <netinet/ip.h>
#include <netinet/if_ether.h>
#endif

#if NVLAN > 0
#include <net/if_types.h>
#include <net/if_vlan_var.h>
#endif

#if NBPFILTER > 0
#include <net/bpf.h>
#endif

#include <uvm/uvm_extern.h>

#include <dev/pci/pcireg.h>
#include <dev/pci/pcivar.h>
#include <dev/pci/pcidevs.h>

#include <dev/pci/if_em.h>

/*********************************************************************
 *  Set this to one to display debug statistics                                                   
 *********************************************************************/
int             em_display_debug_stats = 0;

/*********************************************************************
 *  Linked list of board private structures for all NICs found
 *********************************************************************/
#if 0
struct em_softc *em_em_softc_list = NULL;
#endif

/*********************************************************************
 *  Driver version
 *********************************************************************/

char em_driver_version[] = "1.3.14";


/*********************************************************************
 *  PCI Device ID Table
 *********************************************************************/
const struct pci_matchid em_devices[] = {
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82542 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82543GC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544EI_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LX },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SC },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545EM_LX },
};

/*********************************************************************
 *  Function prototypes            
 *********************************************************************/
int  em_probe(struct device *, void *, void *);
void em_attach(struct device *, struct device *, void *);

#if 0
int  em_detach(void *);
int  em_shutdown(void *);
#endif
int  em_intr(void *);
void em_start(struct ifnet *);
int  em_ioctl(struct ifnet *, IOCTL_CMD_TYPE, caddr_t);
void em_watchdog(struct ifnet *);
void em_init(void *);
void em_stop(void *);
void em_media_status(struct ifnet *, struct ifmediareq *);
int  em_media_change(struct ifnet *);
void em_identify_hardware(struct em_softc *);
int  em_allocate_pci_resources(struct em_softc *);
void em_free_pci_resources(struct em_softc *);
void em_local_timer(void *);
int  em_hardware_init(struct em_softc *);
void em_setup_interface(struct em_softc *);
int  em_setup_transmit_structures(struct em_softc *);
void em_initialize_transmit_unit(struct em_softc *);
int  em_setup_receive_structures(struct em_softc *);
void em_initialize_receive_unit(struct em_softc *);
void em_enable_intr(struct em_softc *);
void em_disable_intr(struct em_softc *);
void em_free_transmit_structures(struct em_softc *);
void em_free_receive_structures(struct em_softc *);
void em_update_stats_counters(struct em_softc *);
void em_clean_transmit_interrupts(struct em_softc *);
int  em_allocate_receive_structures(struct em_softc *);
int  em_allocate_transmit_structures(struct em_softc *);
void em_process_receive_interrupts(struct em_softc *);
void em_receive_checksum(struct em_softc *, 
				     struct em_rx_desc * rx_desc,
				     struct mbuf *);
#if 0
void em_transmit_checksum_setup(struct em_softc *,
					    struct mbuf *,
					    struct em_tx_buffer *,
					    u_int32_t *,
					    u_int32_t *);
#endif /* 0 */
void em_set_promisc(struct em_softc *);
void em_disable_promisc(struct em_softc *);
void em_set_multi(struct em_softc *);
void em_print_hw_stats(struct em_softc *);
void em_print_link_status(struct em_softc *);
int  em_get_buf(struct em_rx_buffer *, struct em_softc *,
			    struct mbuf *);
void em_enable_vlans(struct em_softc *em_softc);


int em_malloc_dma(struct em_softc *sc, struct em_dmamap *emm,
			 bus_size_t size);
void em_free_dma(struct em_softc *sc, struct em_dmamap *emm);

/*********************************************************************
 *  FreeBSD Device Interface Entry Points                    
 *********************************************************************/

struct cfattach em_ca = {
	sizeof(struct em_softc), em_probe, em_attach
};

struct cfdriver em_cd = {
	0, "em", DV_IFNET
};

/*********************************************************************
 *  Device identification routine
 *
 *  em_probe determines if the driver should be loaded on
 *  adapter based on PCI vendor/device id of the adapter.
 *
 *  return 0 on success, positive on failure
 *********************************************************************/

int
em_probe(struct device *parent, void *match, void *aux)
{
	INIT_DEBUGOUT("em_probe: begin");

	return (pci_matchbyid((struct pci_attach_args *)aux, em_devices,
	    sizeof(em_devices)/sizeof(em_devices[0])));
}

/*********************************************************************
 *  Device initialization routine
 *
 *  The attach entry point is called when the driver is being loaded.
 *  This routine identifies the type of hardware, allocates all resources 
 *  and initializes the hardware.     
 *  
 *********************************************************************/

void 
em_attach(struct device *parent, struct device *self, void *aux)
{
        struct pci_attach_args *pa = aux;
#if 0
	pci_chipset_tag_t pc = pa->pa_pc;
#endif
	struct em_softc *sc = (struct em_softc *)self;
	int             s;
	int             tsize, rsize;

	INIT_DEBUGOUT("em_attach: begin");
	s = splimp();

	sc->osdep.em_pa = *pa;

	timeout_set(&sc->em_timeout, em_local_timer, sc);

	/* Determine hardware revision */
	em_identify_hardware(sc);

	/* Parameters (to be read from user) */
	sc->num_tx_desc = MAX_TXD;
	sc->num_rx_desc = MAX_RXD;
	sc->tx_int_delay = TIDV;
	sc->rx_int_delay = RIDV;
	sc->hw.autoneg = DO_AUTO_NEG;
	sc->hw.wait_autoneg_complete = WAIT_FOR_AUTO_NEG_DEFAULT;
	sc->hw.autoneg_advertised = AUTONEG_ADV_DEFAULT;
	sc->hw.tbi_compatibility_en = TRUE;
	sc->rx_buffer_len = EM_RXBUFFER_2048;

	sc->hw.fc_high_water = FC_DEFAULT_HI_THRESH;
	sc->hw.fc_low_water  = FC_DEFAULT_LO_THRESH;
	sc->hw.fc_pause_time = FC_DEFAULT_TX_TIMER;
	sc->hw.fc_send_xon   = TRUE;
	sc->hw.fc = em_fc_full;

	/* Set the max frame size assuming standard ethernet sized frames */   
	sc->hw.max_frame_size = 
	ETHERMTU + ETHER_HDR_LEN + ETHER_CRC_LEN;

	sc->hw.min_frame_size = 
	MINIMUM_ETHERNET_PACKET_SIZE + ETHER_CRC_LEN;

	/* This controls when hardware reports transmit completion status. */
	if ((EM_REPORT_TX_EARLY == 0) || (EM_REPORT_TX_EARLY == 1)) {
		sc->hw.report_tx_early = EM_REPORT_TX_EARLY;
	} else {
		if (sc->hw.mac_type < em_82543) {
			sc->hw.report_tx_early = 0;
		} else {
			sc->hw.report_tx_early = 1;
		}
	}

	if (em_allocate_pci_resources(sc)) {
		printf("%s: Allocation of PCI resources failed\n", 
		       sc->sc_dv.dv_xname);
		em_free_pci_resources(sc);
		splx(s);
		return;
	}

	tsize = EM_ROUNDUP(sc->num_tx_desc *
			   sizeof(struct em_tx_desc), 4096);

	/* Allocate Transmit Descriptor ring */
	if(em_malloc_dma(sc, &sc->osdep.em_tx, tsize)) {
		printf("%s: Unable to allocate TxDescriptor memory\n", 
		       sc->sc_dv.dv_xname);
		em_free_pci_resources(sc);
		splx(s);
		return;
	}

	sc->tx_desc_base = (struct em_tx_desc *)sc->osdep.em_tx.emm_kva;

	rsize = EM_ROUNDUP(sc->num_rx_desc *
			   sizeof(struct em_rx_desc), 4096);

	/* Allocate Receive Descriptor ring */
	if(em_malloc_dma(sc, &sc->osdep.em_rx, rsize)) {
		printf("%s: Unable to allocate rx_desc memory\n", 
		       sc->sc_dv.dv_xname);
		em_free_pci_resources(sc);
		em_free_dma(sc, &sc->osdep.em_tx);
		splx(s);
		return;
	}

	sc->rx_desc_base = (struct em_rx_desc *)sc->osdep.em_rx.emm_kva;

	/* Initialize the hardware */
	if (em_hardware_init(sc)) {
		printf("%s: Unable to initialize the hardware\n",
		       sc->sc_dv.dv_xname);
		em_free_pci_resources(sc);
		em_free_dma(sc, &sc->osdep.em_tx);
		em_free_dma(sc, &sc->osdep.em_rx);
		splx(s);
		return;
	}

	/* Copy the permanent MAC address out of the EEPROM */
	if (em_read_mac_addr(&sc->hw) < 0) {
		printf("%s: EEPROM read error while reading mac address\n",
		       sc->sc_dv.dv_xname);
		return;
	}

	memcpy((char *)&sc->arpcom.ac_enaddr, sc->hw.mac_addr,
	       ETH_LENGTH_OF_ADDRESS);

	printf(", address: %s\n", ether_sprintf(sc->arpcom.ac_enaddr));

	/* Setup OS specific network interface */
	em_setup_interface(sc);

	/* Initialize statistics */
	em_clear_hw_cntrs(&sc->hw);
	em_update_stats_counters(sc);
	sc->hw.get_link_status = 1;
	em_check_for_link(&sc->hw);

	/* Print the link status */
	if (sc->link_active == 1) {
		em_get_speed_and_duplex(&sc->hw, &sc->link_speed, 
					&sc->link_duplex);
	}

	INIT_DEBUGOUT("em_attach: end");
	splx(s);
}

/*********************************************************************
 *  Device removal routine
 *
 *  The detach entry point is called when the driver is being removed.
 *  This routine stops the em_softc and deallocates all the resources
 *  that were allocated for driver operation.
 *  
 *  return 0 on success, positive on failure
 *********************************************************************/
#if 0
int
em_detach(void* arg)
{
	struct em_softc *sc = arg;
	struct ifnet   *ifp = &sc->arpcom.ac_if;
	int             s;

	INIT_DEBUGOUT("em_detach: begin");
	s = splimp();

	em_stop(sc);
	em_phy_hw_reset(&sc->hw);
	if_detach(ifp);
	ether_ifdetach(ifp);
	em_free_pci_resources(sc);

	/* Free Transmit Descriptor ring */
	if (sc->tx_desc_base) {
		em_free_dma(sc, &sc->osdep.em_tx);
		sc->tx_desc_base = NULL;
	}

	/* Free Receive Descriptor ring */
	if (sc->rx_desc_base) {
		em_free_dma(sc, &sc->osdep.em_rx);
		sc->rx_desc_base = NULL;
	}

#if 0
	/* Remove from the em_softc list */
	if (em_em_softc_list == sc)
		em_em_softc_list = sc->next;
	if (sc->next != NULL)
		sc->next->prev = sc->prev;
	if (sc->prev != NULL)
		sc->prev->next = sc->next;
#endif /* 0 */

	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
	ifp->if_timer = 0;

	splx(s);
	return(0);
}

int
em_shutdown(void* arg)
{
	struct em_softc *sc = arg;
	em_stop(sc);
	return(0);
}

#endif /* 0 */

/*********************************************************************
 *  Transmit entry point
 *
 *  em_start is called by the stack to initiate a transmit.
 *  The driver will remain in this routine as long as there are
 *  packets to transmit and transmit resources are available.
 *  In case resources are not available stack is notified and
 *  the packet is requeued.
 **********************************************************************/

void
em_start(struct ifnet *ifp)
{
	int             i, s;
	struct mbuf    *m_head;
	u_int32_t       txd_upper; 
	u_int32_t       txd_lower;
	struct em_tx_buffer   *tx_buffer;
	struct em_tx_desc *current_tx_desc = NULL;
	struct em_softc * sc = ifp->if_softc;

	if (!sc->link_active)
		return;

	s = splimp();      

	for(;;) {
#if NVLAN > 0
		struct ifvlan *ifv = NULL;
#endif

		IFQ_POLL(&ifp->if_snd, m_head);

		if (m_head == NULL) break;

		if (sc->num_tx_desc_avail <= TX_CLEANUP_THRESHOLD)
			em_clean_transmit_interrupts(sc);

		if (sc->num_tx_desc_avail <= TX_CLEANUP_THRESHOLD) {
			ifp->if_flags |= IFF_OACTIVE;
			sc->no_tx_desc_avail++;
			break;
		}

		tx_buffer =  SIMPLEQ_FIRST(&sc->free_tx_buffer_list);
		if (!tx_buffer) {
			sc->no_tx_buffer_avail1++;
			/* 
			 * OK so we should not get here but I've seen
			 * it so let us try to clean up and then try
			 * to get a tx_buffer again and only break if
			 * we still don't get one.
			 */
			em_clean_transmit_interrupts(sc);
			tx_buffer = SIMPLEQ_FIRST(&sc->free_tx_buffer_list);
			if (!tx_buffer) {
				ifp->if_flags |= IFF_OACTIVE;
				sc->no_tx_buffer_avail2++;
				break;
			}
		}

		IFQ_DEQUEUE(&ifp->if_snd, m_head);

		SIMPLEQ_REMOVE_HEAD(&sc->free_tx_buffer_list, tx_buffer,
				    em_tx_entry);

		tx_buffer->num_tx_desc_used = 0;
		tx_buffer->m_head = m_head;
#if 0
		if (ifp->if_hwassist > 0) {
			em_transmit_checksum_setup(sc,  m_head, tx_buffer, 
						   &txd_upper, &txd_lower);
		} else {
#endif
			txd_upper = 0;
			txd_lower = 0;
#if 0
		}
#endif

#if NVLAN > 0
		/* Find out if we are in vlan mode */
		if ((m_head->m_flags & (M_PROTO1|M_PKTHDR)) == 
		    (M_PROTO1|M_PKTHDR) &&
		    m_head->m_pkthdr.rcvif != NULL &&
		    m_head->m_pkthdr.rcvif->if_type == IFT_L2VLAN)
			ifv = m_head->m_pkthdr.rcvif->if_softc;
#endif

		if (bus_dmamap_load_mbuf(sc->osdep.em_pa.pa_dmat,
					 tx_buffer->dmamap,
					 m_head, BUS_DMA_NOWAIT))
			return;

		for (i = 0; i < tx_buffer->dmamap->dm_nsegs; i++) {
			bus_addr_t addr= tx_buffer->dmamap->dm_segs[i].ds_addr;
			bus_size_t len = tx_buffer->dmamap->dm_segs[i].ds_len;

			current_tx_desc = sc->next_avail_tx_desc;
			current_tx_desc->buffer_addr = htole64(addr);

			current_tx_desc->lower.data = htole32(txd_lower | len);
			current_tx_desc->upper.data = htole32(txd_upper);

			if (current_tx_desc == sc->last_tx_desc)
				sc->next_avail_tx_desc =
				sc->first_tx_desc;
			else
				sc->next_avail_tx_desc++;

			sc->num_tx_desc_avail--;
			tx_buffer->num_tx_desc_used++;
		}

		/* Put this tx_buffer at the end in the "in use" list */
		SIMPLEQ_INSERT_TAIL(&sc->used_tx_buffer_list, tx_buffer, 
				   em_tx_entry);

#if NVLAN > 0
		if (ifv != NULL) {
			/* Tell hardware to add tag */
			current_tx_desc->lower.data |=
				htole32(E1000_TXD_CMD_VLE);

			/* Set the vlan id */
			current_tx_desc->upper.fields.special =
				htole16(ifv->ifv_tag);
		}
#endif

		/* 
		 * Last Descriptor of Packet needs End Of Packet
		 * (EOP), Report Status (RS) and append Ethernet CRC
		 * (IFCS) bits set.
		 */
		current_tx_desc->lower.data |=
			htole32(sc->txd_cmd|E1000_TXD_CMD_EOP);

#if NBPFILTER > 0
		/*
		 * If there's a BPF listener, bounce a copy of this frame
		 * to him.
		 */
		if (ifp->if_bpf)
			bpf_mtap(ifp->if_bpf, m_head);
#endif

		/* 
		 * Advance the Transmit Descriptor Tail (Tdt), this
		 * tells the E1000 that this frame is available to
		 * transmit.
		 */
		E1000_WRITE_REG(&sc->hw, TDT, 
				(((_BSD_PTRDIFF_T_) sc->next_avail_tx_desc -
				  (_BSD_PTRDIFF_T_) sc->first_tx_desc) >> 4));
	} /* end of while loop */

	splx(s);

	/* Set timeout in case chip has problems transmitting */
	ifp->if_timer = EM_TX_TIMEOUT;

	return;
}

/*********************************************************************
 *  Ioctl entry point
 *
 *  em_ioctl is called when the user wants to configure the
 *  interface.
 *
 *  return 0 on success, positive on failure
 **********************************************************************/

int
em_ioctl(struct ifnet *ifp, IOCTL_CMD_TYPE command, caddr_t data)
{
	int             s, error = 0;
	struct ifreq   *ifr = (struct ifreq *) data;
	struct ifaddr  *ifa = (struct ifaddr *)data;
	struct em_softc * sc = ifp->if_softc;

	s = splimp();

        if ((error = ether_ioctl(ifp, &sc->arpcom, command, data)) > 0) {
                splx(s);
                return (error);
        }

	switch (command) {
	case SIOCSIFADDR:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFADDR (Set Interface "
			       "Addr)");
		ifp->if_flags |= IFF_UP;
                switch (ifa->ifa_addr->sa_family) {
#ifdef INET
                case AF_INET:
                        em_init(sc);
                        arp_ifinit(&sc->arpcom, ifa);
                        break;
#endif /* INET */
                default:
                        em_init(sc);
                        break;
                }
		break;
	case SIOCSIFMTU:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFMTU (Set Interface MTU)");
		if (ifr->ifr_mtu > MAX_JUMBO_FRAME_SIZE - ETHER_HDR_LEN) {
			error = EINVAL;
		} else {
			ifp->if_mtu = ifr->ifr_mtu;
			sc->hw.max_frame_size = 
			ifp->if_mtu + ETHER_HDR_LEN + ETHER_CRC_LEN;
			em_init(sc);
		}
		break;
	case SIOCSIFFLAGS:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFFLAGS (Set Interface "
			       "Flags)");
		if (ifp->if_flags & IFF_UP) {
			if (ifp->if_flags & IFF_RUNNING &&
			    ifp->if_flags & IFF_PROMISC) {
				em_set_promisc(sc);
			} else if (ifp->if_flags & IFF_RUNNING &&
				   !(ifp->if_flags & IFF_PROMISC)) {
				em_disable_promisc(sc);
			} else
				em_init(sc);
		} else {
			if (ifp->if_flags & IFF_RUNNING) {
				em_stop(sc);
			}
		}
		break;
	case SIOCADDMULTI:
	case SIOCDELMULTI:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOC(ADD|DEL)MULTI");
#if 0
		if (ifp->if_flags & IFF_RUNNING) {
			em_disable_intr(sc);
			em_set_multi(sc);
			if (sc->hw.mac_type == em_82542_rev2_0)
				em_initialize_receive_unit(sc);
			em_enable_intr(sc);
		}
		break;
#endif /* 0 */
                error = (command == SIOCADDMULTI)
                        ? ether_addmulti(ifr, &sc->arpcom)
                        : ether_delmulti(ifr, &sc->arpcom);

                if (error == ENETRESET) {
                        if (ifp->if_flags & IFF_RUNNING) {
				em_disable_intr(sc);
				em_set_multi(sc);
				if (sc->hw.mac_type == em_82542_rev2_0)
					em_initialize_receive_unit(sc);
				em_enable_intr(sc);
			}
                        error = 0;
                }
		break;
	case SIOCSIFMEDIA:
	case SIOCGIFMEDIA:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFMEDIA (Get/Set Interface "
			       "Media)");
		error = ifmedia_ioctl(ifp, ifr, &sc->media, command);
		break;
#if 0
	case SIOCSIFCAP:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFCAP (Set Capabilities)");
		mask = ifr->ifr_reqcap ^ ifp->if_capenable;
		if (mask & IFCAP_HWCSUM) {
			if (IFCAP_HWCSUM & ifp->if_capenable)
				ifp->if_capenable &= ~IFCAP_HWCSUM;
			else
				ifp->if_capenable |= IFCAP_HWCSUM;
			if (ifp->if_flags & IFF_RUNNING)
				em_init(sc);
		}
		break;
#endif /* 0 */
	default:
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%d)\n",
				(int)command);
		error = EINVAL;
	}

	splx(s);
	return(error);
}

void
em_set_promisc(struct em_softc * sc)
{

	u_int32_t       reg_rctl;
	struct ifnet   *ifp = &sc->arpcom.ac_if;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	if (ifp->if_flags & IFF_PROMISC) {
		reg_rctl |= (E1000_RCTL_UPE | E1000_RCTL_MPE);
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else if (ifp->if_flags & IFF_ALLMULTI) {
		reg_rctl |= E1000_RCTL_MPE;
		reg_rctl &= ~E1000_RCTL_UPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	}

	return;
}

void
em_disable_promisc(struct em_softc * sc)
{
	u_int32_t       reg_rctl;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	reg_rctl &=  (~E1000_RCTL_UPE);
	reg_rctl &=  (~E1000_RCTL_MPE);
	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);

	return;
}


/*********************************************************************
 *  Multicast Update
 *
 *  This routine is called whenever multicast address list is updated.
 *
 **********************************************************************/

void
em_set_multi(struct em_softc * sc)
{
	u_int32_t reg_rctl = 0;
	u_int8_t  mta[MAX_NUM_MULTICAST_ADDRESSES * ETH_LENGTH_OF_ADDRESS];
	u_int16_t pci_cmd_word;
#if 0
	struct ifmultiaddr  *ifma;
#endif
	int mcnt = 0;
        struct pci_attach_args *pa = &sc->osdep.em_pa;
#if 0
	struct ifnet   *ifp = &sc->arpcom.ac_if;
#endif

	IOCTL_DEBUGOUT("em_set_multi: begin");

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			pci_cmd_word = sc->hw.pci_cmd_word & 
				       ~CMD_MEM_WRT_INVALIDATE;
			pci_conf_write(pa->pa_pc, pa->pa_tag,
				       PCI_COMMAND_STATUS_REG, pci_cmd_word);
		}
		reg_rctl |= E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
	}

#if 0
#if __FreeBSD_version < 500000 
	LIST_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#else
	TAILQ_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#endif
		if (ifma->ifma_addr->sa_family != AF_LINK)
			continue;

		bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),
		      &mta[mcnt*ETH_LENGTH_OF_ADDRESS], ETH_LENGTH_OF_ADDRESS);
		mcnt++;
	}
#endif /* 0 */

	if (mcnt > MAX_NUM_MULTICAST_ADDRESSES) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl |= E1000_RCTL_MPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0);

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl &= ~E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			pci_conf_write(pa->pa_pc, pa->pa_tag,
				       PCI_COMMAND_STATUS_REG, 
				       sc->hw.pci_cmd_word);
		}
	}

	return;
}

/*********************************************************************
 *  Watchdog entry point
 *
 *  This routine is called whenever hardware quits transmitting.
 *
 **********************************************************************/

void
em_watchdog(struct ifnet *ifp)
{
	struct em_softc * sc;
	sc = ifp->if_softc;

	/* If we are in this routine because of pause frames, then
	 * don't reset the hardware.
	 */
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_TXOFF) {
		ifp->if_timer = EM_TX_TIMEOUT;
		return;
	}

	printf("%s: watchdog timeout -- resetting\n", sc->sc_dv.dv_xname);

	ifp->if_flags &= ~IFF_RUNNING;

	em_stop(sc);
	em_init(sc);

	ifp->if_oerrors++;
	return;
}

/*********************************************************************
 *  Timer routine
 *
 *  This routine checks for link status and updates statistics.
 *
 **********************************************************************/

void
em_local_timer(void *arg)
{
	int s;
	struct ifnet   *ifp;
	struct em_softc * sc = arg;
	ifp = &sc->arpcom.ac_if;

	s = splimp();

	em_check_for_link(&sc->hw);
	em_print_link_status(sc);
	em_update_stats_counters(sc);   
	if (em_display_debug_stats && ifp->if_flags & IFF_RUNNING) {
		em_print_hw_stats(sc);
	}
	timeout_add(&sc->em_timeout, 2*hz);

	splx(s);
	return;
}

void
em_print_link_status(struct em_softc * sc)
{
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw, 
						&sc->link_speed, 
						&sc->link_duplex);
			sc->link_active = 1;
		}
	} else {
		if (sc->link_active == 1) {
			sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
	}

	return;
}

/*********************************************************************
 *  Init entry point
 *
 *  This routine is used in two ways. It is used by the stack as
 *  init entry point in network interface structure. It is also used
 *  by the driver as a hw/sw initialization routine to get to a 
 *  consistent state.
 *
 *  return 0 on success, positive on failure
 **********************************************************************/

void
em_init(void *arg)
{
	int             s;
	struct ifnet   *ifp;
	struct em_softc * sc= arg;

	INIT_DEBUGOUT("em_init: begin");

	s = splimp();

	em_stop(sc);

	/* Initialize the hardware */
	if (em_hardware_init(sc)) {
		printf("%s: Unable to initialize the hardware\n", 
		       sc->sc_dv.dv_xname);
		splx(s);
		return;
	}

	em_enable_vlans(sc);

	/* Prepare transmit descriptors and buffers */
	if (em_setup_transmit_structures(sc)) {
		printf("%s: Could not setup transmit structures\n", 
		       sc->sc_dv.dv_xname);
		em_stop(sc); 
		splx(s);
		return;
	}
	em_initialize_transmit_unit(sc);

	/* Setup Multicast table */
	em_set_multi(sc);

	/* Prepare receive descriptors and buffers */
	if (em_setup_receive_structures(sc)) {
		printf("%s: Could not setup receive structures\n", 
		       sc->sc_dv.dv_xname);
		em_stop(sc);
		splx(s);
		return;
	}
	em_initialize_receive_unit(sc);

	ifp = &sc->arpcom.ac_if;
	ifp->if_flags |= IFF_RUNNING;
	ifp->if_flags &= ~IFF_OACTIVE;

#if 0
	if (sc->hw.mac_type >= em_82543) {
		if (ifp->if_capenable & IFCAP_TXCSUM)
			ifp->if_hwassist = EM_CHECKSUM_FEATURES;
		else
			ifp->if_hwassist = 0;
	}
#endif /* 0 */

	timeout_add(&sc->em_timeout, 2*hz);
	em_clear_hw_cntrs(&sc->hw);
	em_enable_intr(sc);

	splx(s);
	return;
}


/*********************************************************************
 *
 *  This routine disables all traffic on the em_softc by issuing a
 *  global reset on the MAC and deallocates TX/RX buffers. 
 *
 **********************************************************************/

void
em_stop(void *arg)
{
	struct ifnet   *ifp;
	struct em_softc * sc = arg;
	ifp = &sc->arpcom.ac_if;

	INIT_DEBUGOUT("em_stop: begin\n");
	em_disable_intr(sc);
	em_reset_hw(&sc->hw);
	timeout_del(&sc->em_timeout);
	em_free_transmit_structures(sc);
	em_free_receive_structures(sc);


	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);

	return;
}

/*********************************************************************
 *
 *  Interrupt Service routine
 *
 **********************************************************************/

int 
em_intr(void *arg)
{
	u_int32_t       loop_cnt = EM_MAX_INTR;
	u_int32_t       reg_icr;
	struct ifnet    *ifp;
	struct em_softc *sc= arg;

	ifp = &sc->arpcom.ac_if;

	em_disable_intr(sc);
	while (loop_cnt > 0 && 
	       (reg_icr = E1000_READ_REG(&sc->hw, ICR)) != 0) {

		/* Link status change */
		if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
			timeout_del(&sc->em_timeout);
			sc->hw.get_link_status = 1;
			em_check_for_link(&sc->hw);
			em_print_link_status(sc);
			timeout_add(&sc->em_timeout, 2*hz); 
		}

		if (ifp->if_flags & IFF_RUNNING) {
			em_process_receive_interrupts(sc);
			em_clean_transmit_interrupts(sc);
		}
		loop_cnt--;
	}

	em_enable_intr(sc);

	if (ifp->if_flags & IFF_RUNNING && IFQ_IS_EMPTY(&ifp->if_snd) == 0)
		em_start(ifp);

	return (EM_MAX_INTR != loop_cnt);
}


/*********************************************************************
 *
 *  Media Ioctl callback
 *
 *  This routine is called whenever the user queries the status of
 *  the interface using ifconfig.
 *
 **********************************************************************/
void
em_media_status(struct ifnet *ifp, struct ifmediareq *ifmr)
{
	struct em_softc * sc= ifp->if_softc;

	INIT_DEBUGOUT("em_media_status: begin");

	em_check_for_link(&sc->hw);
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw, 
						&sc->link_speed, 
						&sc->link_duplex);
			sc->link_active = 1;
		}
	} else {
		if (sc->link_active == 1) {
			sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
	}

	ifmr->ifm_status = IFM_AVALID;
	ifmr->ifm_active = IFM_ETHER;

	if (!sc->link_active)
		return;

	ifmr->ifm_status |= IFM_ACTIVE;

	if (sc->hw.media_type == em_media_type_fiber) {
		ifmr->ifm_active |= IFM_1000_SX | IFM_FDX;
	} else {
		switch (sc->link_speed) {
		case 10:
			ifmr->ifm_active |= IFM_10_T;
			break;
		case 100:
			ifmr->ifm_active |= IFM_100_TX;
			break;
		case 1000:
			ifmr->ifm_active |= IFM_1000_T;
			break;
		}
		if (sc->link_duplex == FULL_DUPLEX)
			ifmr->ifm_active |= IFM_FDX;
		else
			ifmr->ifm_active |= IFM_HDX;
	}
	return;
}

/*********************************************************************
 *
 *  Media Ioctl callback
 *
 *  This routine is called when the user changes speed/duplex using
 *  media/mediopt option with ifconfig.
 *
 **********************************************************************/
int
em_media_change(struct ifnet *ifp)
{
	struct em_softc * sc = ifp->if_softc;
	struct ifmedia  *ifm = &sc->media;

	INIT_DEBUGOUT("em_media_change: begin");

	if (IFM_TYPE(ifm->ifm_media) != IFM_ETHER)
		return(EINVAL);

	switch (IFM_SUBTYPE(ifm->ifm_media)) {
	case IFM_AUTO:
		sc->hw.autoneg = DO_AUTO_NEG;
		sc->hw.autoneg_advertised = AUTONEG_ADV_DEFAULT;
		break;
	case IFM_1000_SX:
	case IFM_1000_T:
		sc->hw.autoneg = DO_AUTO_NEG;
		sc->hw.autoneg_advertised = ADVERTISE_1000_FULL;
		break;
	case IFM_100_TX:
		sc->hw.autoneg = FALSE;
		sc->hw.autoneg_advertised = 0;
		if ((ifm->ifm_media & IFM_GMASK) == IFM_FDX)
			sc->hw.forced_speed_duplex = em_100_full;
		else
			sc->hw.forced_speed_duplex	= em_100_half;
		break;
	case IFM_10_T:
		sc->hw.autoneg = FALSE;
		sc->hw.autoneg_advertised = 0;
		if ((ifm->ifm_media & IFM_GMASK) == IFM_FDX)
			sc->hw.forced_speed_duplex = em_10_full;
		else
			sc->hw.forced_speed_duplex	= em_10_half;
		break;
	default:
		printf("%s: Unsupported media type\n", sc->sc_dv.dv_xname);
	}

	em_init(sc);

	return(0);
}
/* Section end: Other registered entry points */


/*********************************************************************
 *
 *  Determine hardware revision.
 *
 **********************************************************************/
void
em_identify_hardware(struct em_softc * sc)
{
	u_int32_t reg;
	struct pci_attach_args *pa = &sc->osdep.em_pa;

	/* Make sure our PCI config space has the necessary stuff set */
	sc->hw.pci_cmd_word = pci_conf_read(pa->pa_pc, pa->pa_tag,
					    PCI_COMMAND_STATUS_REG);
	if (!((sc->hw.pci_cmd_word & PCI_COMMAND_MASTER_ENABLE) &&
	      (sc->hw.pci_cmd_word & PCI_COMMAND_MEM_ENABLE))) {
		printf("%s: Memory Access and/or Bus Master bits not set!\n", 
		       sc->sc_dv.dv_xname);
		sc->hw.pci_cmd_word |= 
		(PCI_COMMAND_MASTER_ENABLE | PCI_COMMAND_MEM_ENABLE);
		pci_conf_write(pa->pa_pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
			       sc->hw.pci_cmd_word);
	}

	/* Save off the information about this board */
	sc->hw.vendor_id = PCI_VENDOR(pa->pa_id);
	sc->hw.device_id = PCI_PRODUCT(pa->pa_id);

	reg = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_CLASS_REG);
	sc->hw.revision_id = PCI_REVISION(reg);

	reg = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_SUBSYS_ID_REG);

	sc->hw.subsystem_vendor_id = PCI_VENDOR(reg);
	sc->hw.subsystem_id = PCI_PRODUCT(reg);

	/* Set MacType, etc. based on this PCI info */
	switch (sc->hw.device_id) {
	case E1000_DEV_ID_82542:
		sc->hw.mac_type = (sc->hw.revision_id == 3) ?
				       em_82542_rev2_1 : em_82542_rev2_0;
		break;
	case E1000_DEV_ID_82543GC_FIBER:
	case E1000_DEV_ID_82543GC_COPPER:
		sc->hw.mac_type = em_82543;
		break;
	case E1000_DEV_ID_82544EI_FIBER:
	case E1000_DEV_ID_82544EI_COPPER:
	case E1000_DEV_ID_82544GC_COPPER:
	case E1000_DEV_ID_82544GC_LOM:
		sc->hw.mac_type = em_82544;
		break;
	case E1000_DEV_ID_82540EM:
		sc->hw.mac_type = em_82540;
		break;
	case E1000_DEV_ID_82545EM_FIBER:
	case E1000_DEV_ID_82545EM_COPPER:
		sc->hw.mac_type = em_82545;
		break;
	case E1000_DEV_ID_82546EB_FIBER:
	case E1000_DEV_ID_82546EB_COPPER:
		sc->hw.mac_type = em_82546;
		break;
	default:
		INIT_DEBUGOUT1("Unknown device id 0x%x", sc->hw.device_id);
	}
	return;
}

int
em_allocate_pci_resources(struct em_softc * sc)
{
	int             i, val, rid;
	pci_intr_handle_t       ih;
	const char              *intrstr = NULL;
	struct pci_attach_args *pa = &sc->osdep.em_pa;
	pci_chipset_tag_t       pc = pa->pa_pc;

	val = pci_conf_read(pa->pa_pc, pa->pa_tag, EM_MMBA);
	if (PCI_MAPREG_TYPE(val) != PCI_MAPREG_TYPE_MEM) {
		printf(": mmba isn't memory");
		return (ENXIO);
        }
        if (pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE(val), 0,
	    &sc->osdep.em_btag, &sc->osdep.em_bhandle,
	    &sc->osdep.em_membase, &sc->osdep.em_memsize, 0)) {
		printf(": can't find mem space");
		return (ENXIO);
	}

#if 0
        if (pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE_32BIT, 0,
	    &sc->osdep.em_btag, &sc->osdep.em_bhandle, &sc->osdep.em_membase,
	    &sc->osdep.em_memsize, 0) &&
       	    pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE_64BIT, 0,
    	    &sc->osdep.em_btag, &sc->osdep.em_bhandle, &sc->osdep.em_membase,
	    	&sc->osdep.em_memsize, 0)) {
                printf(": can't find mem space");
                return (ENXIO);
        }
#endif /* 0 */

	if (sc->hw.mac_type > em_82543) {
		/* Figure our where our IO BAR is ? */
		rid = EM_MMBA;
		for (i = 0; i < 5; i++) {
			val = pci_conf_read(pa->pa_pc, pa->pa_tag, rid);
			if (val & 0x00000001) {
				sc->io_rid = rid;
				break;
			}
			rid += 4;
		}
        	if (pci_mapreg_map(pa, rid, PCI_MAPREG_TYPE_IO, 0,
				   &sc->osdep.em_iobtag,
				   &sc->osdep.em_iobhandle,
				   &sc->osdep.em_iobase,
				   &sc->osdep.em_iosize, 0)) {
                	printf(": can't find io space");
                	return (ENXIO);
        	}
	}

        if (pci_intr_map(pa, &ih)) {
                printf(": couldn't map interrupt\n");
                return (ENXIO);
        }

        intrstr = pci_intr_string(pc, ih);
        sc->sc_intrhand = pci_intr_establish(pc, ih, IPL_NET, em_intr, sc,
                                              sc->sc_dv.dv_xname);
        if (sc->sc_intrhand == NULL) {
                printf(": couldn't establish interrupt");
                if (intrstr != NULL)
                        printf(" at %s", intrstr);
                printf("\n");
		return (ENXIO);
        }
        printf(": %s", intrstr);
		
	sc->hw.back = &sc->osdep;

	return(0);
}

void
em_free_pci_resources(struct em_softc* sc)
{
	struct pci_attach_args *pa = &sc->osdep.em_pa;
	pci_chipset_tag_t       pc = pa->pa_pc;

	if(sc->sc_intrhand)
		pci_intr_disestablish(pc, sc->sc_intrhand);
	sc->sc_intrhand = 0;

	if(sc->osdep.em_iobase)
		bus_space_unmap(sc->osdep.em_iobtag, sc->osdep.em_iobhandle,
				sc->osdep.em_iosize);
	sc->osdep.em_iobase = 0;

	if(sc->osdep.em_membase)
		bus_space_unmap(sc->osdep.em_btag, sc->osdep.em_bhandle,
				sc->osdep.em_memsize);
	sc->osdep.em_membase = 0;

}

/*********************************************************************
 *
 *  Initialize the hardware to a configuration as specified by the
 *  em_softc structure. The controller is reset, the EEPROM is
 *  verified, the MAC address is set, then the shared initialization
 *  routines are called.
 *
 **********************************************************************/
int
em_hardware_init(struct em_softc * sc)
{
	/* Issue a global reset */
	em_reset_hw(&sc->hw);

	/* Make sure we have a good EEPROM before we read from it */
	if (em_validate_eeprom_checksum(&sc->hw) < 0) {
		printf("%s: The EEPROM Checksum Is Not Valid\n",
		       sc->sc_dv.dv_xname);
		return(EIO);
	}

	if (em_read_part_num(&sc->hw, &(sc->part_num)) < 0) {
		printf("%s: EEPROM read error while reading part number\n",
		       sc->sc_dv.dv_xname);
		return(EIO);
	}

	if (em_init_hw(&sc->hw) < 0) {
		printf("%s: Hardware Initialization Failed",
		       sc->sc_dv.dv_xname);
		return(EIO);
	}

	em_check_for_link(&sc->hw);
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU)
		sc->link_active = 1;
	else
		sc->link_active = 0;

	if (sc->link_active) {
		em_get_speed_and_duplex(&sc->hw, 
					&sc->link_speed, 
					&sc->link_duplex);
	} else {
		sc->link_speed = 0;
		sc->link_duplex = 0;
	}

	return(0);
}

/*********************************************************************
 *
 *  Setup networking device structure and register an interface.
 *
 **********************************************************************/
void
em_setup_interface(struct em_softc * sc)
{
	struct ifnet   *ifp;
	INIT_DEBUGOUT("em_setup_interface: begin");

	ifp = &sc->arpcom.ac_if;
	ifp->if_mtu = ETHERMTU;
	ifp->if_output = ether_output;
	ifp->if_baudrate = 1000000000;
#if 0
	ifp->if_init =  em_init;
#endif
	ifp->if_softc = sc;
	ifp->if_flags = IFF_BROADCAST | IFF_SIMPLEX | IFF_MULTICAST;
	ifp->if_ioctl = em_ioctl;
	ifp->if_start = em_start;
	ifp->if_watchdog = em_watchdog;
	IFQ_SET_MAXLEN(&ifp->if_snd, sc->num_tx_desc - 1);
	IFQ_SET_READY(&ifp->if_snd);

	bcopy(sc->sc_dv.dv_xname, ifp->if_xname, IFNAMSIZ);
	

#if 0
	if (sc->hw.mac_type >= em_82543) {
		ifp->if_capabilities = IFCAP_HWCSUM;
		ifp->if_capenable = ifp->if_capabilities;
	}
#endif /* 0 */

	/* 
	 * Specify the media types supported by this em_softc and register
	 * callbacks to update media and link information
	 */
	ifmedia_init(&sc->media, IFM_IMASK, em_media_change,
		     em_media_status);
	if (sc->hw.media_type == em_media_type_fiber) {
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_SX | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_SX, 
			    0, NULL);
	} else {
		ifmedia_add(&sc->media, IFM_ETHER | IFM_10_T, 0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_10_T | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_100_TX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_100_TX | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_T | IFM_FDX, 
			    0, NULL);
		ifmedia_add(&sc->media, IFM_ETHER | IFM_1000_T, 0, NULL);
	}
	ifmedia_add(&sc->media, IFM_ETHER | IFM_AUTO, 0, NULL);
	ifmedia_set(&sc->media, IFM_ETHER | IFM_AUTO);

	if_attach(ifp);
	ether_ifattach(ifp);

	return;
}


/*********************************************************************
 *
 *  Allocate memory for tx_buffer structures. The tx_buffer stores all 
 *  the information needed to transmit a packet on the wire. 
 *
 **********************************************************************/
int
em_allocate_transmit_structures(struct em_softc * sc)
{
	if (!(sc->tx_buffer_area =
	      (struct em_tx_buffer *) malloc(sizeof(struct em_tx_buffer) *
					     sc->num_tx_desc, M_DEVBUF,
					     M_NOWAIT))) {
		printf("%s: Unable to allocate tx_buffer memory\n", 
		       sc->sc_dv.dv_xname);
		return ENOMEM;
	}

	bzero(sc->tx_buffer_area,
	      sizeof(struct em_tx_buffer) * sc->num_tx_desc);

	return 0;
}

/*********************************************************************
 *
 *  Allocate and initialize transmit structures. 
 *
 **********************************************************************/
int
em_setup_transmit_structures(struct em_softc* sc)
{
	struct em_tx_buffer   *tx_buffer;
	int             i;

	if (em_allocate_transmit_structures(sc))
		return ENOMEM;

	sc->first_tx_desc = sc->tx_desc_base;
	sc->last_tx_desc =
	sc->first_tx_desc + (sc->num_tx_desc - 1);


	SIMPLEQ_INIT(&sc->free_tx_buffer_list);
	SIMPLEQ_INIT(&sc->used_tx_buffer_list);

	tx_buffer = sc->tx_buffer_area;

	/* Setup the linked list of the tx_buffer's */
	for (i = 0; i < sc->num_tx_desc; i++, tx_buffer++) {
		bzero((void *) tx_buffer, sizeof(struct em_tx_buffer));
		if (bus_dmamap_create(sc->osdep.em_pa.pa_dmat, MCLBYTES, 32,
				      MCLBYTES, 0, BUS_DMA_NOWAIT,
				      &tx_buffer->dmamap))
			return ENOBUFS;
		SIMPLEQ_INSERT_TAIL(&sc->free_tx_buffer_list, 
				   tx_buffer, em_tx_entry);
	}

	bzero((void *) sc->first_tx_desc,
	      (sizeof(struct em_tx_desc)) * sc->num_tx_desc);

	/* Setup TX descriptor pointers */
	sc->next_avail_tx_desc = sc->first_tx_desc;
	sc->oldest_used_tx_desc = sc->first_tx_desc;

	/* Set number of descriptors available */
	sc->num_tx_desc_avail = sc->num_tx_desc;

	/* Set checksum context */
	sc->active_checksum_context = OFFLOAD_NONE;

	return 0;
}

/*********************************************************************
 *
 *  Enable transmit unit.
 *
 **********************************************************************/
void
em_initialize_transmit_unit(struct em_softc * sc)
{
	u_int32_t       reg_tctl;
	u_int32_t       reg_tipg = 0;

	/* Setup the Base and Length of the Tx Descriptor Ring */
	E1000_WRITE_REG(&sc->hw, TDBAL,
			sc->osdep.em_tx.emm_dmamap->dm_segs[0].ds_addr);
	E1000_WRITE_REG(&sc->hw, TDBAH, 0);
	E1000_WRITE_REG(&sc->hw, TDLEN, 
			sc->num_tx_desc *
			sizeof(struct em_tx_desc));

	/* Setup the HW Tx Head and Tail descriptor pointers */
	E1000_WRITE_REG(&sc->hw, TDH, 0);
	E1000_WRITE_REG(&sc->hw, TDT, 0);


	HW_DEBUGOUT2("Base = %x, Length = %x\n", 
		     E1000_READ_REG(&sc->hw, TDBAL),
		     E1000_READ_REG(&sc->hw, TDLEN));


	/* Set the default values for the Tx Inter Packet Gap timer */
	switch (sc->hw.mac_type) {
	case em_82543:
	case em_82544:
	case em_82540:
	case em_82545:
	case em_82546:
		if (sc->hw.media_type == em_media_type_fiber)
			reg_tipg = DEFAULT_82543_TIPG_IPGT_FIBER;
		else
			reg_tipg = DEFAULT_82543_TIPG_IPGT_COPPER;
		reg_tipg |= DEFAULT_82543_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
		reg_tipg |= DEFAULT_82543_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
		break;
	case em_82542_rev2_0:
	case em_82542_rev2_1:
		reg_tipg = DEFAULT_82542_TIPG_IPGT;
		reg_tipg |= DEFAULT_82542_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
		reg_tipg |= DEFAULT_82542_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
		break;
	default:
		printf("%s: Invalid mac type detected\n", sc->sc_dv.dv_xname);
	}
	E1000_WRITE_REG(&sc->hw, TIPG, reg_tipg);
	E1000_WRITE_REG(&sc->hw, TIDV, sc->tx_int_delay);

	/* Program the Transmit Control Register */
	reg_tctl = E1000_TCTL_PSP | E1000_TCTL_EN |
		   (E1000_COLLISION_THRESHOLD << E1000_CT_SHIFT);
	if (sc->link_duplex == 1) {
		reg_tctl |= E1000_FDX_COLLISION_DISTANCE << E1000_COLD_SHIFT;
	} else {
		reg_tctl |= E1000_HDX_COLLISION_DISTANCE << E1000_COLD_SHIFT;
	}
	E1000_WRITE_REG(&sc->hw, TCTL, reg_tctl);

	/* Setup Transmit Descriptor Settings for this adapter */   
	sc->txd_cmd = E1000_TXD_CMD_IFCS;

	if (sc->tx_int_delay > 0)
		sc->txd_cmd |= E1000_TXD_CMD_IDE;

	if (sc->hw.report_tx_early == 1)
		sc->txd_cmd |= E1000_TXD_CMD_RS;
	else
		sc->txd_cmd |= E1000_TXD_CMD_RPS;

	return;
}

/*********************************************************************
 *
 *  Free all transmit related data structures.
 *
 **********************************************************************/
void
em_free_transmit_structures(struct em_softc* sc)
{
	struct em_tx_buffer   *tx_buffer;
	int             i;

	INIT_DEBUGOUT("free_transmit_structures: begin");

	if (sc->tx_buffer_area != NULL) {
		tx_buffer = sc->tx_buffer_area;
		for (i = 0; i < sc->num_tx_desc; i++, tx_buffer++) {
			if (tx_buffer->m_head != NULL)
				m_freem(tx_buffer->m_head);
			tx_buffer->m_head = NULL;

			bus_dmamap_unload(sc->osdep.em_pa.pa_dmat,
			    tx_buffer->dmamap);
			bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat,
			    tx_buffer->dmamap);
		}
	}
	if (sc->tx_buffer_area != NULL) {
		free(sc->tx_buffer_area, M_DEVBUF);
		sc->tx_buffer_area = NULL;
	}
	return;
}

/*********************************************************************
 *
 *  The offload context needs to be set when we transfer the first
 *  packet of a particular protocol (TCP/UDP). We change the
 *  context only if the protocol type changes.
 *
 **********************************************************************/
#if 0
void
em_transmit_checksum_setup(struct em_softc * sc,
			   struct mbuf *mp,
			   struct em_tx_buffer *tx_buffer,
			   u_int32_t *txd_upper,
			   u_int32_t *txd_lower) 
{
	struct em_context_desc *TXD;
	struct em_tx_desc * current_tx_desc;
	if (mp->m_pkthdr.csum_flags) {

		if (mp->m_pkthdr.csum_flags & CSUM_TCP) {
			*txd_upper = E1000_TXD_POPTS_TXSM << 8;
			*txd_lower = E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D;
			if (sc->active_checksum_context == OFFLOAD_TCP_IP)
				return;
			else
				sc->active_checksum_context = OFFLOAD_TCP_IP;

		} else if (mp->m_pkthdr.csum_flags & CSUM_UDP) {
			*txd_upper = E1000_TXD_POPTS_TXSM << 8;
			*txd_lower = E1000_TXD_CMD_DEXT | E1000_TXD_DTYP_D;
			if (sc->active_checksum_context == OFFLOAD_UDP_IP)
				return;
			else
				sc->active_checksum_context = OFFLOAD_UDP_IP;
		} else {
			*txd_upper = 0;
			*txd_lower = 0;
			return;
		}
	} else {
		*txd_upper = 0;
		*txd_lower = 0;
		return;
	}

	/* If we reach this point, the checksum offload context
	 * needs to be reset.
	 */
	current_tx_desc = sc->next_avail_tx_desc;
	TXD = (struct em_context_desc *)current_tx_desc;

	TXD->lower_setup.ip_fields.ipcss = ETHER_HDR_LEN;
	TXD->lower_setup.ip_fields.ipcso = 
	ETHER_HDR_LEN + offsetof(struct ip, ip_sum);
	TXD->lower_setup.ip_fields.ipcse = 
	ETHER_HDR_LEN + sizeof(struct ip) - 1;

	TXD->upper_setup.tcp_fields.tucss = 
	ETHER_HDR_LEN + sizeof(struct ip);
	TXD->upper_setup.tcp_fields.tucse = 0;

	if (sc->active_checksum_context == OFFLOAD_TCP_IP) {
		TXD->upper_setup.tcp_fields.tucso = 
		ETHER_HDR_LEN + sizeof(struct ip) + 
		offsetof(struct tcphdr, th_sum);
	} else if (sc->active_checksum_context == OFFLOAD_UDP_IP) {
		TXD->upper_setup.tcp_fields.tucso = 
		ETHER_HDR_LEN + sizeof(struct ip) + 
		offsetof(struct udphdr, uh_sum);
	}

	TXD->tcp_seg_setup.data = 0;
	TXD->cmd_and_length = E1000_TXD_CMD_DEXT;

	if (current_tx_desc == sc->last_tx_desc)
		sc->next_avail_tx_desc = sc->first_tx_desc;
	else
		sc->next_avail_tx_desc++;

	sc->num_tx_desc_avail--;

	tx_buffer->num_tx_desc_used++;
	return;
}
#endif /* 0 */


/*********************************************************************
 *
 *  Get a buffer from system mbuf buffer pool.
 *
 **********************************************************************/
int
em_get_buf(struct em_rx_buffer *rx_buffer, struct em_softc *sc,
	   struct mbuf *mp)
{
	struct mbuf    *nmp;
	struct ifnet   *ifp;

	ifp = &sc->arpcom.ac_if;

	if (mp == NULL) {
		MGETHDR(nmp, M_DONTWAIT, MT_DATA);
		if (nmp == NULL) {
			sc->mbuf_alloc_failed++;
			return(ENOBUFS);
		}
		MCLGET(nmp, M_DONTWAIT);
		if ((nmp->m_flags & M_EXT) == 0) {
			m_freem(nmp);
			sc->mbuf_cluster_failed++;
			return(ENOBUFS);
		}
		nmp->m_len = nmp->m_pkthdr.len = MCLBYTES;
	} else {
		nmp = mp;
		nmp->m_len = nmp->m_pkthdr.len = MCLBYTES;
		nmp->m_data = nmp->m_ext.ext_buf;
		nmp->m_next = NULL;
	}

	if (bus_dmamap_load_mbuf(sc->osdep.em_pa.pa_dmat,
				 rx_buffer->dmamap,
				 nmp, BUS_DMA_NOWAIT))
		return(ENOBUFS);

	if (ifp->if_mtu <= ETHERMTU)
		m_adj(nmp, ETHER_ALIGN);

	rx_buffer->m_head = nmp;
	rx_buffer->buffer_addr = 
		rx_buffer->dmamap->dm_segs[0].ds_addr + ETHER_ALIGN;

	return(0);
}

/*********************************************************************
 *
 *  Allocate memory for rx_buffer structures. Since we use one 
 *  rx_buffer per received packet, the maximum number of rx_buffer's 
 *  that we'll need is equal to the number of receive descriptors 
 *  that we've allocated.
 *
 **********************************************************************/
int
em_allocate_receive_structures(struct em_softc* sc)
{
	int             i;
	struct em_rx_buffer   *rx_buffer;

	if (!(sc->rx_buffer_area =
	      (struct em_rx_buffer *) malloc(sizeof(struct em_rx_buffer) *
					     sc->num_rx_desc, M_DEVBUF,
					     M_NOWAIT))) {
		printf("%s: Unable to allocate rx_buffer memory\n", 
		       sc->sc_dv.dv_xname);
		return(ENOMEM);
	}

	bzero(sc->rx_buffer_area,
	      sizeof(struct em_rx_buffer) * sc->num_rx_desc);

	for (i = 0, rx_buffer = sc->rx_buffer_area;
	    i < sc->num_rx_desc; i++, rx_buffer++) {

		if (bus_dmamap_create(sc->osdep.em_pa.pa_dmat,
				      MCLBYTES, 1, MCLBYTES, 0,
				      BUS_DMA_NOWAIT,
				      &rx_buffer->dmamap))
			return ENOBUFS;

		if (em_get_buf(rx_buffer, sc, NULL) == ENOBUFS) {
			rx_buffer->m_head = NULL;
			return(ENOBUFS);
		}
	}

	return(0);
}

/*********************************************************************
 *
 *  Allocate and initialize receive structures.
 *  
 **********************************************************************/
int
em_setup_receive_structures(struct em_softc * sc)
{
	struct em_rx_buffer   *rx_buffer;
	struct em_rx_desc     *rx_desc;
	int             i;

	if (em_allocate_receive_structures(sc))
		return ENOMEM;

	SIMPLEQ_INIT(&sc->rx_buffer_list);

	sc->first_rx_desc =
	(struct em_rx_desc *) sc->rx_desc_base;
	sc->last_rx_desc =
	sc->first_rx_desc + (sc->num_rx_desc - 1);

	rx_buffer = (struct em_rx_buffer *) sc->rx_buffer_area;

	bzero((void *) sc->first_rx_desc,
	      (sizeof(struct em_rx_desc)) * sc->num_rx_desc);

	/* Build a linked list of rx_buffer's */
	for (i = 0, rx_desc = sc->first_rx_desc;
	    i < sc->num_rx_desc;
	    i++, rx_buffer++, rx_desc++) {
		if (rx_buffer->m_head == NULL)
			printf("%s: Receive buffer memory not allocated", 
			       sc->sc_dv.dv_xname);
		else {
			rx_desc->buffer_addr = htole64(rx_buffer->buffer_addr);
			SIMPLEQ_INSERT_TAIL(&sc->rx_buffer_list, 
					   rx_buffer, em_rx_entry);
		}
	}

	/* Setup our descriptor pointers */
	sc->next_rx_desc_to_check = sc->first_rx_desc;

	return(0);
}

/*********************************************************************
 *
 *  Enable receive unit.
 *  
 **********************************************************************/
void
em_initialize_receive_unit(struct em_softc * sc)
{
	u_int32_t       reg_rctl;
#if 0
	u_int32_t       reg_rxcsum;
#endif
	struct ifnet    *ifp;

	ifp = &sc->arpcom.ac_if;

	/*
	 * Make sure receives are disabled while setting up the
	 * descriptor ring
	 */
	E1000_WRITE_REG(&sc->hw, RCTL, 0);

	/* Set the Receive Delay Timer Register */
	E1000_WRITE_REG(&sc->hw, RDTR, 
			sc->rx_int_delay | E1000_RDT_FPDB);

	/* Setup the Base and Length of the Rx Descriptor Ring */
	E1000_WRITE_REG(&sc->hw, RDBAL, 
			sc->osdep.em_rx.emm_dmamap->dm_segs[0].ds_addr);
	E1000_WRITE_REG(&sc->hw, RDBAH, 0);
	E1000_WRITE_REG(&sc->hw, RDLEN, sc->num_rx_desc *
			sizeof(struct em_rx_desc));

	/* Setup the HW Rx Head and Tail Descriptor Pointers */
	E1000_WRITE_REG(&sc->hw, RDH, 0);
	E1000_WRITE_REG(&sc->hw, RDT,
			(((_BSD_PTRDIFF_T_) sc->last_rx_desc -
			  (_BSD_PTRDIFF_T_) sc->first_rx_desc) >> 4));

	/* Setup the Receive Control Register */
	reg_rctl = E1000_RCTL_EN | E1000_RCTL_BAM | E1000_RCTL_LBM_NO |
		   E1000_RCTL_RDMTS_HALF |
		   (sc->hw.mc_filter_type << E1000_RCTL_MO_SHIFT);

	if (sc->hw.tbi_compatibility_on == TRUE)
		reg_rctl |= E1000_RCTL_SBP;


	switch (sc->rx_buffer_len) {
	default:
	case EM_RXBUFFER_2048:
		reg_rctl |= E1000_RCTL_SZ_2048;
		break;
	case EM_RXBUFFER_4096:
		reg_rctl |= E1000_RCTL_SZ_4096|E1000_RCTL_BSEX|E1000_RCTL_LPE;
		break;            
	case EM_RXBUFFER_8192:
		reg_rctl |= E1000_RCTL_SZ_8192|E1000_RCTL_BSEX|E1000_RCTL_LPE;
		break;
	case EM_RXBUFFER_16384:
		reg_rctl |= E1000_RCTL_SZ_16384|E1000_RCTL_BSEX|E1000_RCTL_LPE;
		break;
	}

	if (ifp->if_mtu > ETHERMTU)
		reg_rctl |= E1000_RCTL_LPE;

#if 0
	/* Enable 82543 Receive Checksum Offload for TCP and UDP */
	if ((sc->hw.mac_type >= em_82543) && 
	    (ifp->if_capenable & IFCAP_RXCSUM)) {
		reg_rxcsum = E1000_READ_REG(&sc->hw, RXCSUM);
		reg_rxcsum |= (E1000_RXCSUM_IPOFL | E1000_RXCSUM_TUOFL);
		E1000_WRITE_REG(&sc->hw, RXCSUM, reg_rxcsum);
	}
#endif /* 0 */

	/* Enable Receives */
	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);

	return;
}

/*********************************************************************
 *
 *  Free receive related data structures.
 *
 **********************************************************************/
void
em_free_receive_structures(struct em_softc * sc)
{
	struct em_rx_buffer   *rx_buffer;
	int             i;

	INIT_DEBUGOUT("free_receive_structures: begin");

	if (sc->rx_buffer_area != NULL) {
		rx_buffer = sc->rx_buffer_area;
		for (i = 0; i < sc->num_rx_desc; i++, rx_buffer++) {
			if (rx_buffer->m_head != NULL)
				m_freem(rx_buffer->m_head);
			rx_buffer->m_head = NULL;

			bus_dmamap_unload(sc->osdep.em_pa.pa_dmat,
			    rx_buffer->dmamap);
			bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat,
			    rx_buffer->dmamap);
		}
	}
	if (sc->rx_buffer_area != NULL) {
		free(sc->rx_buffer_area, M_DEVBUF);
		sc->rx_buffer_area = NULL;
	}
	return;
}

/*********************************************************************
 *
 *  This routine executes in interrupt context. It replenishes
 *  the mbufs in the descriptor and sends data which has been
 *  dma'ed into host memory to upper layer.
 *
 *********************************************************************/
void
em_process_receive_interrupts(struct em_softc* sc)
{
	struct mbuf         *mp;
	struct ifnet        *ifp;
	struct ether_header *eh;
	u_int16_t           len;
	u_int8_t            last_byte;
	u_int8_t            accept_frame = 0;
	u_int8_t            eop = 0;
	u_int32_t           pkt_len = 0;

	/* Pointer to the receive descriptor being examined. */
	struct em_rx_desc   *current_desc;
	struct em_rx_desc   *last_desc_processed;
	struct em_rx_buffer *rx_buffer;

	ifp = &sc->arpcom.ac_if;
	current_desc = sc->next_rx_desc_to_check;

	if (!((current_desc->status) & E1000_RXD_STAT_DD)) {
#ifdef DBG_STATS
		sc->no_pkts_avail++;
#endif
		return;
	}

	while (current_desc->status & E1000_RXD_STAT_DD) {

		/* Get a pointer to the actual receive buffer */
		rx_buffer = SIMPLEQ_FIRST(&sc->rx_buffer_list);

		if (rx_buffer == NULL) {
			printf("%s: Found null rx_buffer\n",
			       sc->sc_dv.dv_xname);
			return;
		}

		mp = rx_buffer->m_head;      
		accept_frame = 1;

		if (current_desc->status & E1000_RXD_STAT_EOP) {
			eop = 1;
			len = letoh16(current_desc->length) - ETHER_CRC_LEN;
		} else {
			eop = 0;
			len = letoh16(current_desc->length);
		}

		if (current_desc->errors & E1000_RXD_ERR_FRAME_ERR_MASK) {

			/* Compute packet length for tbi_accept macro */
			pkt_len = letoh16(current_desc->length);
			if (sc->fmp != NULL) {
				pkt_len += sc->fmp->m_pkthdr.len; 
			}

			last_byte = *(mtod(rx_buffer->m_head,caddr_t) + 
				      letoh16(current_desc->length) - 1);

			if (TBI_ACCEPT(&sc->hw, current_desc->status, 
				       current_desc->errors, 
				       pkt_len, last_byte)) {
				em_tbi_adjust_stats(&sc->hw, 
						    &sc->stats, 
						    pkt_len, 
						    sc->hw.mac_addr);
				len--;
			} else {
				accept_frame = 0;
			}
		}

		if (accept_frame) {

			if (em_get_buf(rx_buffer, sc, NULL) == ENOBUFS) {
				sc->dropped_pkts++;
				em_get_buf(rx_buffer, sc, mp);
				if (sc->fmp != NULL) m_freem(sc->fmp);
				sc->fmp = NULL;
				sc->lmp = NULL;
				break;
			}

			/* Assign correct length to the current fragment */
			mp->m_len = len;

			if (sc->fmp == NULL) {
				mp->m_pkthdr.len = len;
				sc->fmp = mp;	 /* Store the first mbuf */
				sc->lmp = mp;
			} else {
				/* Chain mbuf's together */
				mp->m_flags &= ~M_PKTHDR;
				sc->lmp->m_next = mp;
				sc->lmp = sc->lmp->m_next;
				sc->fmp->m_pkthdr.len += len;
			}

			if (eop) {
				sc->fmp->m_pkthdr.rcvif = ifp;
#if NBPFILTER > 0
				/*
				 * Handle BPF listeners. Let the BPF
				 * user see the packet.
				 */
				if (ifp->if_bpf)
					bpf_mtap(ifp->if_bpf, sc->fmp);
#endif


				eh = mtod(sc->fmp, struct ether_header *);

				/* Remove ethernet header from mbuf */
				m_adj(sc->fmp, sizeof(struct ether_header));
				em_receive_checksum(sc, current_desc, 
						    sc->fmp);
#if 0
				if (current_desc->status & E1000_RXD_STAT_VP)
					VLAN_INPUT_TAG(eh, sc->fmp, 
					     letoh16(current_desc->special));
				else
#endif /* 0 */
					ether_input(ifp, eh, sc->fmp);

				sc->fmp = NULL;
				sc->lmp = NULL;
			}
		} else {
			sc->dropped_pkts++;
			em_get_buf(rx_buffer, sc, mp);
			if (sc->fmp != NULL) m_freem(sc->fmp);
			sc->fmp = NULL;
			sc->lmp = NULL;
		}

		/* Zero out the receive descriptors status  */
		current_desc->status = 0;

		if (rx_buffer->m_head != NULL) {
			current_desc->buffer_addr =
				htole64(rx_buffer->buffer_addr);
		}

		/* Advance our pointers to the next descriptor
		 * (checking for wrap). */
		if (current_desc == sc->last_rx_desc)
			sc->next_rx_desc_to_check = sc->first_rx_desc;
		else
			((sc)->next_rx_desc_to_check)++;

		last_desc_processed = current_desc;
		current_desc = sc->next_rx_desc_to_check;
		/* 
		 * Put the buffer that we just indicated back at the
		 * end of our list
		 */
		SIMPLEQ_REMOVE_HEAD(&sc->rx_buffer_list, rx_buffer,
				    em_rx_entry);
		SIMPLEQ_INSERT_TAIL(&sc->rx_buffer_list, 
				   rx_buffer, em_rx_entry);

		/* Advance the E1000's Receive Queue #0  "Tail Pointer". */
		E1000_WRITE_REG(&sc->hw, RDT, 
				(((u_long) last_desc_processed -
				  (u_long) sc->first_rx_desc) >> 4));
	}
	return;
}

/*********************************************************************
 *
 *  Verify that the hardware indicated that the checksum is valid. 
 *  Inform the stack about the status of checksum so that stack
 *  doesn't spend time verifying the checksum.
 *
 *********************************************************************/
void
em_receive_checksum(struct em_softc *sc,
		    struct em_rx_desc *rx_desc,
		    struct mbuf *mp)
{
#if 0
	/* 82543 or newer only */
	if ((sc->hw.mac_type < em_82543) ||
	    /* Ignore Checksum bit is set */
	    (rx_desc->status & E1000_RXD_STAT_IXSM)) {
		mp->m_pkthdr.csum_flags = 0;
		return;
	}

	if (rx_desc->status & E1000_RXD_STAT_IPCS) {
		/* Did it pass? */
		if (!(rx_desc->errors & E1000_RXD_ERR_IPE)) {
			/* IP Checksum Good */
			mp->m_pkthdr.csum_flags = CSUM_IP_CHECKED;
			mp->m_pkthdr.csum_flags |= CSUM_IP_VALID;

		} else {
			mp->m_pkthdr.csum_flags = 0;
		}
	}

	if (rx_desc->status & E1000_RXD_STAT_TCPCS) {
		/* Did it pass? */        
		if (!(rx_desc->errors & E1000_RXD_ERR_TCPE)) {
			mp->m_pkthdr.csum_flags |= 
			(CSUM_DATA_VALID | CSUM_PSEUDO_HDR);
			mp->m_pkthdr.csum_data = htons(0xffff);
		}
	}

	return;
#endif /* 0 */
}


void em_enable_vlans(struct em_softc * sc)
{
	uint32_t ctrl;

	E1000_WRITE_REG(&sc->hw, VET, QTAG_TYPE);

	ctrl = E1000_READ_REG(&sc->hw, CTRL);
	ctrl |= E1000_CTRL_VME; 
	E1000_WRITE_REG(&sc->hw, CTRL, ctrl);

	return;
}

void
em_enable_intr(struct em_softc* sc)
{
	E1000_WRITE_REG(&sc->hw, IMS, (IMS_ENABLE_MASK));
	return;
}

void
em_disable_intr(struct em_softc *sc)
{
	E1000_WRITE_REG(&sc->hw, IMC, 
			(0xffffffff & ~E1000_IMC_RXSEQ));
	return;
}

void em_write_pci_cfg(struct em_hw *hw,
		      uint32_t reg,
		      uint16_t *value)
{
        struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pci_chipset_tag_t pc = pa->pa_pc;
	pci_conf_write(pc, pa->pa_tag, reg, *value);
}

void em_read_pci_cfg(struct em_hw *hw, uint32_t reg,
		     uint16_t *value)
{
        struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pci_chipset_tag_t pc = pa->pa_pc;
	*value = pci_conf_read(pc, pa->pa_tag, reg);
	return;
}

uint32_t em_io_read(struct em_hw *hw, uint32_t port)
{
#if 0
	return(inl(port));
#endif
	return bus_space_read_4(
                ((struct em_osdep *)(hw)->back)->em_iobtag,
		((struct em_osdep *)(hw)->back)->em_iobhandle,
		port);
}

void em_io_write(struct em_hw *hw, uint32_t port, uint32_t value)
{
#if 0
	outl(port, value);
#endif
	bus_space_write_4(
			((struct em_osdep *)(hw)->back)->em_iobtag,
			((struct em_osdep *)(hw)->back)->em_iobhandle,
			port,
			value);
	return;
} 

/**********************************************************************
 *
 *  Update the board statistics counters. 
 *
 **********************************************************************/
void
em_update_stats_counters(struct em_softc *sc)
{
	struct ifnet   *ifp;

	sc->stats.crcerrs += E1000_READ_REG(&sc->hw, CRCERRS);
	sc->stats.symerrs += E1000_READ_REG(&sc->hw, SYMERRS);
	sc->stats.mpc += E1000_READ_REG(&sc->hw, MPC);
	sc->stats.scc += E1000_READ_REG(&sc->hw, SCC);
	sc->stats.ecol += E1000_READ_REG(&sc->hw, ECOL);
	sc->stats.mcc += E1000_READ_REG(&sc->hw, MCC);
	sc->stats.latecol += E1000_READ_REG(&sc->hw, LATECOL);
	sc->stats.colc += E1000_READ_REG(&sc->hw, COLC);
	sc->stats.dc += E1000_READ_REG(&sc->hw, DC);
	sc->stats.sec += E1000_READ_REG(&sc->hw, SEC);
	sc->stats.rlec += E1000_READ_REG(&sc->hw, RLEC);
	sc->stats.xonrxc += E1000_READ_REG(&sc->hw, XONRXC);
	sc->stats.xontxc += E1000_READ_REG(&sc->hw, XONTXC);
	sc->stats.xoffrxc += E1000_READ_REG(&sc->hw, XOFFRXC);
	sc->stats.xofftxc += E1000_READ_REG(&sc->hw, XOFFTXC);
	sc->stats.fcruc += E1000_READ_REG(&sc->hw, FCRUC);
	sc->stats.prc64 += E1000_READ_REG(&sc->hw, PRC64);
	sc->stats.prc127 += E1000_READ_REG(&sc->hw, PRC127);
	sc->stats.prc255 += E1000_READ_REG(&sc->hw, PRC255);
	sc->stats.prc511 += E1000_READ_REG(&sc->hw, PRC511);
	sc->stats.prc1023 += E1000_READ_REG(&sc->hw, PRC1023);
	sc->stats.prc1522 += E1000_READ_REG(&sc->hw, PRC1522);
	sc->stats.gprc += E1000_READ_REG(&sc->hw, GPRC);
	sc->stats.bprc += E1000_READ_REG(&sc->hw, BPRC);
	sc->stats.mprc += E1000_READ_REG(&sc->hw, MPRC);
	sc->stats.gptc += E1000_READ_REG(&sc->hw, GPTC);

	/* For the 64-bit byte counters the low dword must be read first. */
	/* Both registers clear on the read of the high dword */

	sc->stats.gorcl += E1000_READ_REG(&sc->hw, GORCL); 
	sc->stats.gorch += E1000_READ_REG(&sc->hw, GORCH);
	sc->stats.gotcl += E1000_READ_REG(&sc->hw, GOTCL);
	sc->stats.gotch += E1000_READ_REG(&sc->hw, GOTCH);

	sc->stats.rnbc += E1000_READ_REG(&sc->hw, RNBC);
	sc->stats.ruc += E1000_READ_REG(&sc->hw, RUC);
	sc->stats.rfc += E1000_READ_REG(&sc->hw, RFC);
	sc->stats.roc += E1000_READ_REG(&sc->hw, ROC);
	sc->stats.rjc += E1000_READ_REG(&sc->hw, RJC);

	sc->stats.torl += E1000_READ_REG(&sc->hw, TORL);
	sc->stats.torh += E1000_READ_REG(&sc->hw, TORH);
	sc->stats.totl += E1000_READ_REG(&sc->hw, TOTL);
	sc->stats.toth += E1000_READ_REG(&sc->hw, TOTH);

	sc->stats.tpr += E1000_READ_REG(&sc->hw, TPR);
	sc->stats.tpt += E1000_READ_REG(&sc->hw, TPT);
	sc->stats.ptc64 += E1000_READ_REG(&sc->hw, PTC64);
	sc->stats.ptc127 += E1000_READ_REG(&sc->hw, PTC127);
	sc->stats.ptc255 += E1000_READ_REG(&sc->hw, PTC255);
	sc->stats.ptc511 += E1000_READ_REG(&sc->hw, PTC511);
	sc->stats.ptc1023 += E1000_READ_REG(&sc->hw, PTC1023);
	sc->stats.ptc1522 += E1000_READ_REG(&sc->hw, PTC1522);
	sc->stats.mptc += E1000_READ_REG(&sc->hw, MPTC);
	sc->stats.bptc += E1000_READ_REG(&sc->hw, BPTC);

	if (sc->hw.mac_type >= em_82543) {
		sc->stats.algnerrc += 
		E1000_READ_REG(&sc->hw, ALGNERRC);
		sc->stats.rxerrc += 
		E1000_READ_REG(&sc->hw, RXERRC);
		sc->stats.tncrs += 
		E1000_READ_REG(&sc->hw, TNCRS);
		sc->stats.cexterr += 
		E1000_READ_REG(&sc->hw, CEXTERR);
		sc->stats.tsctc += 
		E1000_READ_REG(&sc->hw, TSCTC);
		sc->stats.tsctfc += 
		E1000_READ_REG(&sc->hw, TSCTFC);
	}
	ifp = &sc->arpcom.ac_if;

	/* Fill out the OS statistics structure */
	ifp->if_ipackets = sc->stats.gprc;
	ifp->if_opackets = sc->stats.gptc;
	ifp->if_ibytes = sc->stats.gorcl;
	ifp->if_obytes = sc->stats.gotcl;
	ifp->if_imcasts = sc->stats.mprc;
	ifp->if_collisions = sc->stats.colc;

	/* Rx Errors */
	ifp->if_ierrors =
	sc->dropped_pkts +
	sc->stats.rxerrc +
	sc->stats.crcerrs +
	sc->stats.algnerrc +
	sc->stats.rlec + sc->stats.rnbc + 
	sc->stats.mpc + sc->stats.cexterr;

	/* Tx Errors */
	ifp->if_oerrors = sc->stats.ecol + sc->stats.latecol;

}


/**********************************************************************
 *
 *  This routine is called only when em_display_debug_stats is enabled.
 *  This routine provides a way to take a look at important statistics
 *  maintained by the driver and hardware.
 *
 **********************************************************************/
void
em_print_hw_stats(struct em_softc *sc)
{
#ifdef DBG_STATS
	printf("%s: Packets not Avail = %ld\n", sc->sc_dv.dv_xname, 
	       sc->no_pkts_avail);
	printf("%s: CleanTxInterrupts = %ld\n", sc->sc_dv.dv_xname, 
	       sc->clean_tx_interrupts);
#endif

	printf("%s: Tx Descriptors not Avail = %ld\n", sc->sc_dv.dv_xname, 
	       sc->no_tx_desc_avail);
	printf("%s: Tx Buffer not avail1 = %ld\n", sc->sc_dv.dv_xname, 
	       sc->no_tx_buffer_avail1);
	printf("%s: Tx Buffer not avail2 = %ld\n", sc->sc_dv.dv_xname, 
	       sc->no_tx_buffer_avail2);
	printf("%s: Std Mbuf Failed = %ld\n",sc->sc_dv.dv_xname, 
	       sc->mbuf_alloc_failed);
	printf("%s: Std Cluster Failed = %ld\n",sc->sc_dv.dv_xname, 
	       sc->mbuf_cluster_failed);

	printf("%s: Symbol errors = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.symerrs);
	printf("%s: Sequence errors = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.sec);
	printf("%s: Defer count = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.dc);

	printf("%s: Missed Packets = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.mpc);
	printf("%s: Receive No Buffers = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.rnbc);
	printf("%s: Receive length errors = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.rlec);
	printf("%s: Receive errors = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.rxerrc);
	printf("%s: Crc errors = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.crcerrs);
	printf("%s: Alignment errors = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.algnerrc);
	printf("%s: Carrier extension errors = %lld\n", sc->sc_dv.dv_xname,
	       (long long)sc->stats.cexterr);
	printf("%s: Driver dropped packets = %ld\n", sc->sc_dv.dv_xname, 
	       sc->dropped_pkts);

	printf("%s: XON Rcvd = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.xonrxc);
	printf("%s: XON Xmtd = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.xontxc);
	printf("%s: XOFF Rcvd = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.xoffrxc);
	printf("%s: XOFF Xmtd = %lld\n", sc->sc_dv.dv_xname, 
	       (long long)sc->stats.xofftxc);

	printf("%s: Good Packets Rcvd = %lld\n", sc->sc_dv.dv_xname,
	       (long long)sc->stats.gprc);
	printf("%s: Good Packets Xmtd = %lld\n", sc->sc_dv.dv_xname,
	       (long long)sc->stats.gptc);
}


/**********************************************************************
 *
 *  Examine each tx_buffer in the used queue. If the hardware is done
 *  processing the packet then free associated resources. The
 *  tx_buffer is put back on the free queue. 
 *
 **********************************************************************/
void
em_clean_transmit_interrupts(struct em_softc* sc)
{
	struct em_tx_buffer *tx_buffer;
	struct em_tx_desc   *tx_desc;
	int             s;
	struct ifnet   *ifp;

	s = splimp();
#ifdef DBG_STATS
	sc->clean_tx_interrupts++;
#endif

	for (tx_buffer = SIMPLEQ_FIRST(&sc->used_tx_buffer_list);
	    tx_buffer; 
	    tx_buffer = SIMPLEQ_FIRST(&sc->used_tx_buffer_list)) {

		/* 
		 * Get hold of the next descriptor that the em will
		 * report status back to (this will be the last
		 * descriptor of a given tx_buffer). We only want to
		 * free the tx_buffer (and it resources) if the driver
		 * is done with ALL of the descriptors.  If the driver
		 * is done with the last one then it is done with all
		 * of them.
		 */

		tx_desc = sc->oldest_used_tx_desc +
			  (tx_buffer->num_tx_desc_used - 1);

		/* Check for wrap case */
		if (tx_desc > sc->last_tx_desc)
			tx_desc -= sc->num_tx_desc;


		/* 
		 * If the descriptor done bit is set free tx_buffer
		 * and associated resources
		 */
		if (tx_desc->upper.fields.status & E1000_TXD_STAT_DD) {

			SIMPLEQ_REMOVE_HEAD(&sc->used_tx_buffer_list, 
					   tx_buffer,
					   em_tx_entry);

			if ((tx_desc == sc->last_tx_desc))
				sc->oldest_used_tx_desc =
				sc->first_tx_desc;
			else
				sc->oldest_used_tx_desc = (tx_desc + 1);

			/* Make available the descriptors that were
			 * previously used */
			sc->num_tx_desc_avail +=
			tx_buffer->num_tx_desc_used;

			tx_buffer->num_tx_desc_used = 0;

			if (tx_buffer->m_head) {
				m_freem(tx_buffer->m_head);
				tx_buffer->m_head = NULL;
			}
			/* Return this "Software packet" back to the
			 * "free" list */
			SIMPLEQ_INSERT_TAIL(&sc->free_tx_buffer_list, 
					   tx_buffer, em_tx_entry);
		} else {
			/* 
			 * Found a tx_buffer that the em is not done
			 * with then there is no reason to check the
			 * rest of the queue.
			 */
			break;
		}
	}		      /* end for each tx_buffer */

	ifp = &sc->arpcom.ac_if;

	/* Tell the stack that it is OK to send packets */
	if (sc->num_tx_desc_avail > TX_CLEANUP_THRESHOLD) {
		ifp->if_timer = 0;
		ifp->if_flags &= ~IFF_OACTIVE;
	}
	splx(s);
	return;
}

int em_malloc_dma(struct em_softc *sc, struct em_dmamap *emm,
			 bus_size_t size)
{
	bus_dma_tag_t	dma_tag = sc->osdep.em_pa.pa_dmat;

	emm->emm_size = size;

        if (bus_dmamem_alloc(dma_tag, size, PAGE_SIZE, 0, &emm->emm_seg, 1,
			     &emm->emm_rseg, BUS_DMA_NOWAIT)) {
		goto fail0;
        }
        if (bus_dmamem_map(dma_tag, &emm->emm_seg, emm->emm_rseg, size,
			   &emm->emm_kva, BUS_DMA_NOWAIT)) {
		goto fail1;
        }
        if (bus_dmamap_create(dma_tag, size, 1, size, 0, BUS_DMA_NOWAIT,
			      &emm->emm_dmamap)) {
		goto fail2;
        }
        if (bus_dmamap_load(dma_tag, emm->emm_dmamap, emm->emm_kva, size,
			    NULL, BUS_DMA_NOWAIT)) {
		goto fail3;
        }
       	 
	return 0;

 fail3:
	bus_dmamap_destroy(dma_tag, emm->emm_dmamap);
 fail2:
	bus_dmamem_unmap(dma_tag, emm->emm_kva, size);
 fail1:
	bus_dmamem_free(dma_tag, &emm->emm_seg, emm->emm_rseg);
 fail0:
	return (ENOBUFS);
}

void em_free_dma(struct em_softc *sc, struct em_dmamap *emm)
{
	bus_dmamap_unload(sc->osdep.em_pa.pa_dmat, emm->emm_dmamap);
	bus_dmamap_destroy(sc->osdep.em_pa.pa_dmat, emm->emm_dmamap);
	bus_dmamem_unmap(sc->osdep.em_pa.pa_dmat, emm->emm_kva, emm->emm_size);
	bus_dmamem_free(sc->osdep.em_pa.pa_dmat, &emm->emm_seg, emm->emm_rseg);
}
@


1.1.1.1
log
@Import OpenBSD 3.3 source repository from CTM 3132 the first time
This opens an OpenBSD-mirabile (aka MirBSD) repository.

### MirBSD is:
# Copyright (c) 1982-2003 by Thorsten "mirabile" Glaser <x86@@ePost.de>
# Copyright  1968-2003  The authors of And contributors to UNIX, the
#       C Language, BSD/Berkeley Unix; 386BSD, NetBSD 1.1 and OpenBSD.
#
# Anyone who obtained a copy of this work is hereby permitted to freely use,
# distribute, modify, merge, sublicence, give away or sell it as long as the
# authors are given due credit and the following notice is retained:
#
# This work is provided "as is", with no explicit or implicit warranty what-
# soever. Use it only at your own risk. In no event may an author or contri-
# butor be held liable for any damage, directly or indirectly, that origina-
# ted through or is caused by creation or modification of this work.

MirBSD is my private tree. MirBSD does not differ very much from OpenBSD
and intentionally tracks OpenBSD. That's why it _is_ OpenBSD, just not the
official one. It's like with DarrenBSD.

At time of this writing, no advertising for MirBSD must be done,
because the advertising clause has not yet been sorted out.

http://templeofhate.com/tglaser/MirBSD/index.php
@
text
@@


1.1.1.2
log
@sync with OpenBSD, this gives us a fair amount of fixes
@
text
@d3 1
a3 1
Copyright (c) 2001-2003, Intel Corporation
d6 11
a16 9
Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

 1. Redistributions of source code must retain the above copyright notice,
    this list of conditions and the following disclaimer.

 2. Redistributions in binary form must reproduce the above copyright
    notice, this list of conditions and the following disclaimer in the
    documentation and/or other materials provided with the distribution.
d19 2
a20 2
    contributors may be used to endorse or promote products derived from
    this software without specific prior written permission.
d25 8
a32 8
ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE
LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS
INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN
CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)
ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
POSSIBILITY OF SUCH DAMAGE.
d36 1
a36 2
/*$FreeBSD: if_em.c,v 1.26 2003/06/05 17:51:37 pdeuskar Exp $*/
/* $OpenBSD: if_em.c,v 1.9 2003/06/13 19:21:21 henric Exp $ */
a78 6
#ifdef DEBUG
#define EM_KASSERT(exp,msg)        do { if (!(exp)) panic msg; } while (0)
#else
#define EM_KASSERT(exp,msg)
#endif

d80 1
a80 1
 *  Set this to one to display debug statistics
d87 3
a89 3

struct em_softc *em_adapter_list = NULL;

d95 1
a95 1
char em_driver_version[] = "1.6.6";
d108 1
a108 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82544GC_LOM },
d114 1
a114 8
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EM_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LOM },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_QUAD },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LP }
d118 1
a118 1
 *  Function prototypes
d129 1
a129 1
int  em_ioctl(struct ifnet *, u_long, caddr_t);
d153 1
a153 1
void em_process_receive_interrupts(struct em_softc *, int);
d155 1
a155 1
				     struct em_rx_desc *,
d157 1
d160 1
d163 1
d169 1
a169 1
int  em_get_buf(int i, struct em_softc *,
d171 6
a176 12
void em_enable_vlans(struct em_softc *);
int  em_encap(struct em_softc *, struct mbuf *);
void em_smartspeed(struct em_softc *);
int  em_82547_fifo_workaround(struct em_softc *, int);
void em_82547_update_fifo_head(struct em_softc *, int);
int  em_82547_tx_fifo_reset(struct em_softc *);
void em_82547_move_tail(void *);
int  em_dma_malloc(struct em_softc *, bus_size_t,
    struct em_dma_alloc *, int);
void em_dma_free(struct em_softc *, struct em_dma_alloc *);
void em_print_debug_info(struct em_softc *);
int  em_is_valid_ether_addr(u_int8_t *);
d179 1
a179 1
 *  FreeBSD Device Interface Entry Points		     
a214 1
 *  return 0 on success, positive on failure
d220 1
a220 1
	struct pci_attach_args *pa = aux;
d225 2
a226 3
	int		s;
	int		tsize, rsize;
	int		error = 0;
a230 13
#ifdef __FreeBSD__
	/* Allocate, clear, and link in our sc structure */
	if (!(sc = device_get_softc(dev))) {
		printf("em: sc structure allocation failed\n");
		splx(s);
		return(ENOMEM);
	}
	bzero(sc, sizeof(struct em_softc ));
	sc->dev = dev;
	sc->osdep.dev = dev;
	sc->sc_dv.dv_xname = device_get_unit(dev);
#endif /* __FreeBSD__ */

d233 1
a233 37
	if (em_adapter_list != NULL)
		em_adapter_list->prev = sc;
	sc->next = em_adapter_list;
	em_adapter_list = sc;

#ifdef __FreeBSD__
	/* SYSCTL stuff */
	sysctl_ctx_init(&sc->sysctl_ctx);
	sc->sysctl_tree = SYSCTL_ADD_NODE(&sc->sysctl_ctx,
					       SYSCTL_STATIC_CHILDREN(_hw),
					       OID_AUTO,
					       device_get_nameunit(dev),
					       CTLFLAG_RD,
					       0, "");
	if (sc->sysctl_tree == NULL) {
		error = EIO;
		goto err_sysctl;
	}

	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
			SYSCTL_CHILDREN(sc->sysctl_tree),
			OID_AUTO, "debug_info", CTLTYPE_INT|CTLFLAG_RW,
			(void *)sc, 0,
			em_sysctl_debug_info, "I", "Debug Information");

	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
			SYSCTL_CHILDREN(sc->sysctl_tree),
			OID_AUTO, "stats", CTLTYPE_INT|CTLFLAG_RW,
			(void *)sc, 0,
			em_sysctl_stats, "I", "Statistics");

	callout_handle_init(&sc->timer_handle);
	callout_handle_init(&sc->tx_fifo_timer_handle);
#endif /* __FreeBSD__ */

	timeout_set(&sc->timer_handle, em_local_timer, sc);
	timeout_set(&sc->tx_fifo_timer_handle, em_82547_move_tail, sc);
d239 4
a242 6
	sc->num_tx_desc = EM_MAX_TXD;
	sc->num_rx_desc = EM_MAX_RXD;
	sc->tx_int_delay = EM_TIDV;
	sc->tx_abs_int_delay = EM_TADV;
	sc->rx_int_delay = EM_RDTR;
	sc->rx_abs_int_delay = EM_RADV;
a248 4
	/*
	 * These parameters control the automatic generation(Tx) and
	 * response(Rx) to Ethernet PAUSE frames.
	 */
d255 1
a255 6
	sc->hw.phy_init_script = 1;

	/*
	 * Set the max frame size assuming standard ethernet
	 * sized frames
	 */
d257 1
a257 1
	    ETHERMTU + ETHER_HDR_LEN + ETHER_CRC_LEN;
d260 1
a260 7
	    MINIMUM_ETHERNET_PACKET_SIZE + ETHER_CRC_LEN;

	/*
	 * This controls when hardware reports transmit completion
	 * status.
	 */
	sc->hw.report_tx_early = 1;
d262 10
d276 3
a278 2
		error = ENXIO;
		goto err_pci;
a280 4

	/* Initialize eeprom parameters */
	em_init_eeprom_params(&sc->hw);

d285 2
a286 2
	if (em_dma_malloc(sc, tsize, &sc->txdma, BUS_DMA_NOWAIT)) {
		printf("%s: Unable to allocate tx_desc memory\n", 
d288 3
a290 2
		error = ENOMEM;
		goto err_tx_desc;
d292 2
a293 1
	sc->tx_desc_base = (struct em_tx_desc *)sc->txdma.dma_vaddr;
d299 1
a299 1
	if (em_dma_malloc(sc, rsize, &sc->rxdma, BUS_DMA_NOWAIT)) {
d302 4
a305 2
		error = ENOMEM;
		goto err_rx_desc;
d307 2
a308 1
	sc->rx_desc_base = (struct em_rx_desc *) sc->rxdma.dma_vaddr;
d314 5
a318 2
		error = EIO;
		goto err_hw_init;
d325 1
a325 8
		error = EIO;
		goto err_mac_addr;
	}

	if (!em_is_valid_ether_addr(sc->hw.mac_addr)) {
		printf("%s: Invalid mac address\n", sc->sc_dv.dv_xname);
		error = EIO;
		goto err_mac_addr;
d328 2
a329 2
	bcopy(sc->hw.mac_addr, sc->interface_data.ac_enaddr,
	      ETHER_ADDR_LEN);
d331 1
a331 1
	printf(", address: %s\n", ether_sprintf(sc->interface_data.ac_enaddr));
a349 17
	return;

err_mac_addr:
err_hw_init:
	em_dma_free(sc, &sc->rxdma);
err_rx_desc:
	em_dma_free(sc, &sc->txdma);
err_tx_desc:
err_pci:
	em_free_pci_resources(sc);
#ifdef __FreeBSD__
	sysctl_ctx_free(&sc->sysctl_ctx);
#endif /* __FreeBSD__ */
/*err_sysctl:*/
	splx(s);
	return;

d356 1
a356 1
 *  This routine stops the adapter and deallocates all the resources
d361 1
a361 1
#ifdef __FreeBSD__
d366 2
a367 2
	struct ifnet   *ifp = &sc->interface_data.ac_if;
	int		s;
d374 2
a375 5
#if __FreeBSD_version < 500000
	ether_ifdetach(&sc->interface_data.ac_if, ETHER_BPF_SUPPORTED);
#else
	ether_ifdetach(&sc->interface_data.ac_if);
#endif
d380 1
a380 1
		em_dma_free(sc, &sc->txdma);
d386 1
a386 1
		em_dma_free(sc, &sc->rxdma);
d390 4
a393 3
	/* Remove from the adapter list */
	if (em_adapter_list == sc)
		em_adapter_list = sc->next;
d398 1
a406 6
/*********************************************************************
 *
 *  Shutdown entry point
 *
 **********************************************************************/

d415 1
a415 1
#endif /* __FreeBSD__ */
d430 1
a430 1
	int		s;
d432 5
a436 1
	struct em_softc *sc = ifp->if_softc;
d441 6
a446 1
	s = splimp();	   
a447 1
	for (;;) {
d452 4
a455 1
		if (em_encap(sc, m_head)) {
d457 1
d461 18
d481 75
d557 4
a560 1
		/* Send a copy of the frame to the BPF listener */
d565 9
a573 2
		/* Set timeout in case hardware has problems transmitting */
		ifp->if_timer = EM_TX_TIMEOUT;
a574 1
	}	
d576 4
d593 1
a593 1
em_ioctl(struct ifnet *ifp, u_long command, caddr_t data)
d595 1
a595 1
	int		s, error = 0;
d602 4
a605 4
	if ((error = ether_ioctl(ifp, &sc->interface_data, command, data)) > 0) {
		splx(s);
		return (error);
	}
a608 6
#ifdef __FreeBSD__
	case SIOCGIFADDR:
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFADDR (Get/Set Interface Addr)");
		ether_ioctl(ifp, command, data);
		break;
#endif /* __FreeBSD__ */
d612 1
a612 2
		em_init(sc);
		switch (ifa->ifa_addr->sa_family) {
d614 4
a617 3
		case AF_INET:
			arp_ifinit(&sc->interface_data, ifa);
			break;
d619 4
a622 3
		default:
			break;
		}
d636 2
a637 1
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCSIFFLAGS (Set Interface Flags)");
d639 7
a645 1
			if (!(ifp->if_flags & IFF_RUNNING))
a646 3

			em_disable_promisc(sc);
			em_set_promisc(sc);
d656 13
a668 3
		error = (command == SIOCADDMULTI)
			? ether_addmulti(ifr, &sc->interface_data)
			: ether_delmulti(ifr, &sc->interface_data);
d670 2
a671 2
		if (error == ENETRESET) {
			if (ifp->if_flags & IFF_RUNNING) {
d674 1
a674 1
				if (sc->hw.mac_type == em_82542_rev2_0) {
d676 1
a676 5
				}
#ifdef DEVICE_POLLING
				if (!(ifp->if_ipending & IFF_POLLING))
#endif
					em_enable_intr(sc);
d678 2
a679 2
			error = 0;
		}
d683 2
a684 1
		IOCTL_DEBUGOUT("ioctl rcv'd: SIOCxIFMEDIA (Get/Set Interface Media)");
d687 1
a687 1
#ifdef __FreeBSD__
d700 1
a700 1
#endif /* __FreeBSD__ */
d702 2
a703 1
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%d)\n", (int)command);
d711 110
d854 1
a854 1
 *  Init entry point
d856 1
a856 4
 *  This routine is used in two ways. It is used by the stack as
 *  init entry point in network interface structure. It is also used
 *  by the driver as a hw/sw initialization routine to get to a 
 *  consistent state.
a857 1
 *  return 0 on success, positive on failure
d861 1
a861 1
em_init(void *arg)
d863 1
a863 1
	int		s;
d866 1
d868 1
a868 1
	INIT_DEBUGOUT("em_init: begin");
d870 7
a876 1
	s = splimp();
d878 3
a880 1
	em_stop(sc);
d882 51
a932 6
	/* Initialize the hardware */
	if (em_hardware_init(sc)) {
		printf("%s: Unable to initialize the hardware\n", 
		       sc->sc_dv.dv_xname);
		splx(s);
		return;
d960 1
a960 1
	ifp = &sc->interface_data.ac_if;
d964 1
a964 1
#ifdef __FreeBSD__
d971 1
a971 1
#endif /* __FreeBSD__ */
d973 1
a973 1
	timeout_add(&sc->timer_handle, 2*hz);
d975 1
a975 10
#ifdef DEVICE_POLLING
        /*
         * Only enable interrupts if we are not polling, make sure
         * they are off otherwise.
         */
        if (ifp->if_ipending & IFF_POLLING)
                em_disable_intr(sc);
        else
#endif /* DEVICE_POLLING */
		em_enable_intr(sc);
d982 6
a987 2
#ifdef DEVICE_POLLING
static poll_handler_t em_poll;
d989 2
a990 2
static void
em_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
d992 3
a994 2
	struct em_softc *sc = ifp->if_softc;
	u_int32_t reg_icr;
d996 10
a1005 18
	if (cmd == POLL_DEREGISTER) {	    /* final call, enable interrupts */
		em_enable_intr(sc);
		return;
	}
	if (cmd == POLL_AND_CHECK_STATUS) {
		reg_icr = E1000_READ_REG(&sc->hw, ICR);
		if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
			untimeout(em_local_timer, sc, sc->timer_handle);
			sc->hw.get_link_status = 1;
			em_check_for_link(&sc->hw);
			em_print_link_status(sc);
			sc->timer_handle = timeout(em_local_timer, sc, 2*hz);
		}
	}
	if (ifp->if_flags & IFF_RUNNING) {
		em_process_receive_interrupts(sc, count);
		em_clean_transmit_interrupts(sc);
	}
d1007 1
a1007 2
	if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
		em_start(ifp);
a1008 1
#endif /* DEVICE_POLLING */
d1015 1
d1019 4
a1022 4
	u_int32_t	loop_cnt = EM_MAX_INTR;
	u_int32_t	reg_icr;
	struct ifnet	*ifp;
	struct em_softc *sc = arg;
d1024 1
a1024 1
	ifp = &sc->interface_data.ac_if;
d1026 3
a1028 3
#ifdef DEVICE_POLLING
	if (ifp->if_ipending & IFF_POLLING)
		return;
d1030 8
a1037 19
	if (ether_poll_register(em_poll, ifp)) {
		em_disable_intr(sc);
		em_poll(ifp, 0, 1);
		return;
	}
#endif /* DEVICE_POLLING */
	reg_icr = E1000_READ_REG(&sc->hw, ICR);
	if (!reg_icr) {
		return (0);
	}

	/* Link status change */
	if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
		timeout_del(&sc->timer_handle);
		sc->hw.get_link_status = 1;
		em_check_for_link(&sc->hw);
		em_print_link_status(sc);
		timeout_add(&sc->timer_handle, 2*hz); 
	}
a1038 1
	while (loop_cnt > 0) {
d1040 1
a1040 1
			em_process_receive_interrupts(sc, -1);
d1046 2
d1051 1
a1051 1
	return (1);
a1054 1

d1128 1
a1128 1
	struct ifmedia	*ifm = &sc->media;
d1169 1
a1169 460

#ifdef __FreeBSD__
void
em_tx_cb(void *arg, bus_dma_segment_t *seg, int nsegs, bus_size_t mapsize, int error)
{
	struct em_q *q = arg;

	if (error)
		return;
	EM_KASSERT(nsegs <= EM_MAX_SCATTER,
		("Too many DMA segments returned when mapping tx packet"));
	q->nsegs = nsegs;
	bcopy(seg, q->segs, nsegs * sizeof(seg[0]));
}
#endif /* __FreeBSD__ */

#define EM_FIFO_HDR		 0x10
#define EM_82547_PKT_THRESH	 0x3e0
#define EM_82547_TX_FIFO_SIZE	 0x2800
#define EM_82547_TX_FIFO_BEGIN	 0xf00
/*********************************************************************
 *
 *  This routine maps the mbufs to tx descriptors.
 *
 *  return 0 on success, positive on failure
 **********************************************************************/
int
em_encap(struct em_softc *sc, struct mbuf *m_head)
{
	u_int32_t	txd_upper;
	u_int32_t	txd_lower;
	int		i, j, error;
#if NVLAN > 0
	struct ifvlan *ifv = NULL;
#endif
	struct em_q	q;

	struct em_buffer   *tx_buffer = NULL;
	struct em_tx_desc *current_tx_desc = NULL;
	/*struct ifnet	 *ifp = &sc->interface_data.ac_if;*/

	/*
	 * Force a cleanup if number of TX descriptors
	 * available hits the threshold
	 */
	if (sc->num_tx_desc_avail <= EM_TX_CLEANUP_THRESHOLD) {
		em_clean_transmit_interrupts(sc);
		if (sc->num_tx_desc_avail <= EM_TX_CLEANUP_THRESHOLD) {
			sc->no_tx_desc_avail1++;
			return (ENOBUFS);
		}
	}

	/*
	 * Map the packet for DMA.
	 */
	if (bus_dmamap_create(sc->txtag, MCLBYTES, 32, 0, 0, BUS_DMA_NOWAIT,
	    &q.map)) {
		sc->no_tx_map_avail++;
		return (ENOMEM);
	}
	error = bus_dmamap_load_mbuf(sc->txtag, q.map,
				     m_head, BUS_DMA_NOWAIT);
	if (error != 0) {
		sc->no_tx_dma_setup++;
		bus_dmamap_destroy(sc->txtag, q.map);
		return (error);
	}
	EM_KASSERT(q.map->dm_nsegs!= 0, ("em_encap: empty packet"));

	if (q.map->dm_nsegs > sc->num_tx_desc_avail) {
		sc->no_tx_desc_avail2++;
		bus_dmamap_destroy(sc->txtag, q.map);
		return (ENOBUFS);
	}


#ifdef __FreeBSD__
	if (ifp->if_hwassist > 0) {
		em_transmit_checksum_setup(sc,	m_head,
					   &txd_upper, &txd_lower);
	} else
#endif /* __FreeBSD__ */
		txd_upper = txd_lower = 0;


	/* Find out if we are in vlan mode */
#if NVLAN > 0
	if ((m_head->m_flags & (M_PROTO1|M_PKTHDR)) == (M_PROTO1|M_PKTHDR) &&
	    m_head->m_pkthdr.rcvif != NULL &&
	    m_head->m_pkthdr.rcvif->if_type == IFT_L2VLAN)
		ifv = m_head->m_pkthdr.rcvif->if_softc;
#endif

	i = sc->next_avail_tx_desc;
	for (j = 0; j < q.map->dm_nsegs; j++) {
		tx_buffer = &sc->tx_buffer_area[i];
		current_tx_desc = &sc->tx_desc_base[i];

		current_tx_desc->buffer_addr = htole64(q.map->dm_segs[j].ds_addr);
		current_tx_desc->lower.data = htole32(
		    sc->txd_cmd | txd_lower | q.map->dm_segs[j].ds_len);
		current_tx_desc->upper.data = htole32(txd_upper);

		if (++i == sc->num_tx_desc)
			i = 0;
		
		tx_buffer->m_head = NULL;
	}

	sc->num_tx_desc_avail -= q.map->dm_nsegs;
	sc->next_avail_tx_desc = i;

#if NVLAN > 0
	if (ifv != NULL) {
		/* Set the vlan id */
		current_tx_desc->upper.fields.special = htole16(ifv->ifv_tag);

		/* Tell hardware to add tag */
		current_tx_desc->lower.data |= htole32(E1000_TXD_CMD_VLE);
	}
#endif

	tx_buffer->m_head = m_head;
	tx_buffer->map = q.map;
	bus_dmamap_sync(sc->txtag, q.map, 0, q.map->dm_mapsize,
	    BUS_DMASYNC_PREWRITE);

	/* 
	 * Last Descriptor of Packet needs End Of Packet (EOP) 
	 */
	current_tx_desc->lower.data |= htole32(E1000_TXD_CMD_EOP);

	/* 
	 * Advance the Transmit Descriptor Tail (Tdt), this tells the E1000
	 * that this frame is available to transmit.
	 */
	if (sc->hw.mac_type == em_82547 &&
	    sc->link_duplex == HALF_DUPLEX) {
		em_82547_move_tail(sc);
	} else {
		E1000_WRITE_REG(&sc->hw, TDT, i);
		if (sc->hw.mac_type == em_82547) {
			em_82547_update_fifo_head(sc, m_head->m_pkthdr.len);
		}
	}

	return (0);
}

/*********************************************************************
 *
 * 82547 workaround to avoid controller hang in half-duplex environment.
 * The workaround is to avoid queuing a large packet that would span
 * the internal Tx FIFO ring boundary. We need to reset the FIFO pointers
 * in this case. We do that only when FIFO is queiced.
 *
 **********************************************************************/
void
em_82547_move_tail(void *arg)
{
	int s;
	struct em_softc *sc = arg;
	uint16_t hw_tdt;
	uint16_t sw_tdt;
	struct em_tx_desc *tx_desc;
	uint16_t length = 0;
	boolean_t eop = 0;

	s = splimp();
	hw_tdt = E1000_READ_REG(&sc->hw, TDT);
	sw_tdt = sc->next_avail_tx_desc;

	while (hw_tdt != sw_tdt) {
		tx_desc = &sc->tx_desc_base[hw_tdt];
		length += tx_desc->lower.flags.length;
		eop = tx_desc->lower.data & E1000_TXD_CMD_EOP;
		if(++hw_tdt == sc->num_tx_desc)
			hw_tdt = 0;

		if(eop) {
			if (em_82547_fifo_workaround(sc, length)) {
				sc->tx_fifo_wrk++;
				timeout_add(&sc->tx_fifo_timer_handle, 1);
				splx(s);
				return;
			}
			else {
				E1000_WRITE_REG(&sc->hw, TDT, hw_tdt);
				em_82547_update_fifo_head(sc, length);
				length = 0;
			}
		}
	}
	splx(s);
	return;
}

int
em_82547_fifo_workaround(struct em_softc *sc, int len)
{
	int fifo_space, fifo_pkt_len;

	fifo_pkt_len = EM_ROUNDUP(len + EM_FIFO_HDR, EM_FIFO_HDR);

	if (sc->link_duplex == HALF_DUPLEX) {
		fifo_space = EM_82547_TX_FIFO_SIZE - sc->tx_fifo_head;

		if (fifo_pkt_len >= (EM_82547_PKT_THRESH + fifo_space)) {
			if (em_82547_tx_fifo_reset(sc)) {
				return(0);
			}
			else {
				return(1);
			}
		}
	}

	return(0);
}

void
em_82547_update_fifo_head(struct em_softc *sc, int len)
{
	int fifo_pkt_len = EM_ROUNDUP(len + EM_FIFO_HDR, EM_FIFO_HDR);

	/* tx_fifo_head is always 16 byte aligned */
	sc->tx_fifo_head += fifo_pkt_len;
	if (sc->tx_fifo_head >= EM_82547_TX_FIFO_SIZE) {
		sc->tx_fifo_head -= EM_82547_TX_FIFO_SIZE;
	}

	return;
}


int
em_82547_tx_fifo_reset(struct em_softc *sc)
{
	uint32_t tctl;

	if ( (E1000_READ_REG(&sc->hw, TDT) ==
	      E1000_READ_REG(&sc->hw, TDH)) &&
	     (E1000_READ_REG(&sc->hw, TDFT) ==
	      E1000_READ_REG(&sc->hw, TDFH)) &&
	     (E1000_READ_REG(&sc->hw, TDFTS) ==
	      E1000_READ_REG(&sc->hw, TDFHS)) &&
	     (E1000_READ_REG(&sc->hw, TDFPC) == 0)) {

		/* Disable TX unit */
		tctl = E1000_READ_REG(&sc->hw, TCTL);
		E1000_WRITE_REG(&sc->hw, TCTL, tctl & ~E1000_TCTL_EN);

		/* Reset FIFO pointers */
		E1000_WRITE_REG(&sc->hw, TDFT, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFH, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFTS, EM_82547_TX_FIFO_BEGIN);
		E1000_WRITE_REG(&sc->hw, TDFHS, EM_82547_TX_FIFO_BEGIN);

		/* Re-enable TX unit */
		E1000_WRITE_REG(&sc->hw, TCTL, tctl);
		E1000_WRITE_FLUSH(&sc->hw);

		sc->tx_fifo_head = 0;
		sc->tx_fifo_reset++;

		return(TRUE);
	}
	else {
		return(FALSE);
	}
}

void
em_set_promisc(struct em_softc * sc)
{

	u_int32_t	reg_rctl;
	struct ifnet   *ifp = &sc->interface_data.ac_if;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	if (ifp->if_flags & IFF_PROMISC) {
		reg_rctl |= (E1000_RCTL_UPE | E1000_RCTL_MPE);
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else if (ifp->if_flags & IFF_ALLMULTI) {
		reg_rctl |= E1000_RCTL_MPE;
		reg_rctl &= ~E1000_RCTL_UPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	}

	return;
}

void
em_disable_promisc(struct em_softc * sc)
{
	u_int32_t	reg_rctl;

	reg_rctl = E1000_READ_REG(&sc->hw, RCTL);

	reg_rctl &=  (~E1000_RCTL_UPE);
	reg_rctl &=  (~E1000_RCTL_MPE);
	E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);

	return;
}


/*********************************************************************
 *  Multicast Update
 *
 *  This routine is called whenever multicast address list is updated.
 *
 **********************************************************************/

void
em_set_multi(struct em_softc * sc)
{
	u_int32_t reg_rctl = 0;
	u_int8_t  mta[MAX_NUM_MULTICAST_ADDRESSES * ETH_LENGTH_OF_ADDRESS];
#ifdef __FreeBSD__
	struct ifmultiaddr  *ifma;
#endif
	int mcnt = 0;
#ifdef __FreeBSD__
	struct ifnet   *ifp = &sc->interface_data.ac_if;
#endif

	IOCTL_DEBUGOUT("em_set_multi: begin");

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			em_pci_clear_mwi(&sc->hw);
		}
		reg_rctl |= E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
	}

#ifdef __FreeBSD__
#if __FreeBSD_version < 500000 
	LIST_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#else
	TAILQ_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#endif
		if (ifma->ifma_addr->sa_family != AF_LINK)
			continue;

		if (mcnt == MAX_NUM_MULTICAST_ADDRESSES) break;

		bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),
		      &mta[mcnt*ETH_LENGTH_OF_ADDRESS], ETH_LENGTH_OF_ADDRESS);
		mcnt++;
	}
#endif /* __FreeBSD__ */

	if (mcnt >= MAX_NUM_MULTICAST_ADDRESSES) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl |= E1000_RCTL_MPE;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
	} else
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0);

	if (sc->hw.mac_type == em_82542_rev2_0) {
		reg_rctl = E1000_READ_REG(&sc->hw, RCTL);
		reg_rctl &= ~E1000_RCTL_RST;
		E1000_WRITE_REG(&sc->hw, RCTL, reg_rctl);
		msec_delay(5);
		if (sc->hw.pci_cmd_word & CMD_MEM_WRT_INVALIDATE) {
			em_pci_set_mwi(&sc->hw);
		}
	}

	return;
}


/*********************************************************************
 *  Timer routine
 *
 *  This routine checks for link status and updates statistics.
 *
 **********************************************************************/

void
em_local_timer(void *arg)
{
	int s;
	struct ifnet   *ifp;
	struct em_softc * sc = arg;
	ifp = &sc->interface_data.ac_if;

	s = splimp();

	em_check_for_link(&sc->hw);
	em_print_link_status(sc);
	em_update_stats_counters(sc);	
	if (em_display_debug_stats && ifp->if_flags & IFF_RUNNING) {
		em_print_hw_stats(sc);
	}
	em_smartspeed(sc);

	timeout_add(&sc->timer_handle, 2*hz);

	splx(s);
	return;
}

void
em_print_link_status(struct em_softc * sc)
{
	if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
		if (sc->link_active == 0) {
			em_get_speed_and_duplex(&sc->hw, 
						&sc->link_speed, 
						&sc->link_duplex);
			sc->link_active = 1;
			sc->smartspeed = 0;
		}
	} else {
		if (sc->link_active == 1) {
			sc->link_speed = 0;
			sc->link_duplex = 0;
			sc->link_active = 0;
		}
	}

	return;
}

/*********************************************************************
 *
 *  This routine disables all traffic on the sc by issuing a
 *  global reset on the MAC and deallocates TX/RX buffers. 
 *
 **********************************************************************/

void
em_stop(void *arg)
{
	struct ifnet   *ifp;
	struct em_softc * sc = arg;
	ifp = &sc->interface_data.ac_if;

	INIT_DEBUGOUT("em_stop: begin\n");
	em_disable_intr(sc);
	em_reset_hw(&sc->hw);
	timeout_del(&sc->timer_handle);
	timeout_del(&sc->tx_fifo_timer_handle);
	em_free_transmit_structures(sc);
	em_free_receive_structures(sc);


	/* Tell the stack that the interface is no longer active */
	ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);

	return;
}
d1188 1
a1188 1
		printf("%s: Memory Access and/or Bus Master bits were not set!\n", 
d1202 36
a1237 10

	reg = pci_conf_read(pa->pa_pc, pa->pa_tag, PCI_SUBSYS_ID_REG);

	sc->hw.subsystem_vendor_id = PCI_VENDOR(reg);
	sc->hw.subsystem_id = PCI_PRODUCT(reg);

	/* Identify the MAC */
	if (em_set_mac_type(&sc->hw))
		printf("%s: Unknown MAC Type\n", sc->sc_dv.dv_xname);

d1244 3
a1246 3
	int		i, val, rid;
	pci_intr_handle_t	ih;
	const char		*intrstr = NULL;
d1248 1
a1248 1
	pci_chipset_tag_t	pc = pa->pa_pc;
d1254 3
a1256 3
	}
	if (pci_mapreg_map(pa, EM_MMBA, PCI_MAPREG_MEM_TYPE(val), 0,
	    &sc->osdep.mem_bus_space_tag, &sc->osdep.mem_bus_space_handle,
d1262 12
d1285 1
a1285 1
		if (pci_mapreg_map(pa, rid, PCI_MAPREG_TYPE_IO, 0,
d1290 3
a1292 3
			printf(": can't find io space");
			return (ENXIO);
		}
d1295 4
a1298 4
	if (pci_intr_map(pa, &ih)) {
		printf(": couldn't map interrupt\n");
		return (ENXIO);
	}
d1300 8
a1307 8
	intrstr = pci_intr_string(pc, ih);
	sc->sc_intrhand = pci_intr_establish(pc, ih, IPL_NET, em_intr, sc,
					      sc->sc_dv.dv_xname);
	if (sc->sc_intrhand == NULL) {
		printf(": couldn't establish interrupt");
		if (intrstr != NULL)
			printf(" at %s", intrstr);
		printf("\n");
d1309 2
a1310 2
	}
	printf(": %s", intrstr);
d1321 1
a1321 1
	pci_chipset_tag_t	pc = pa->pa_pc;
d1333 1
a1333 1
		bus_space_unmap(sc->osdep.mem_bus_space_tag, sc->osdep.mem_bus_space_handle,
a1352 3
	/* When hardware is reset, fifo_head is also reset */
	sc->tx_fifo_head = 0;

d1401 1
a1401 1
	ifp = &sc->interface_data.ac_if;
d1405 2
a1406 2
#ifdef __FreeBSD__
	ifp->if_init =	em_init;
d1416 1
a1416 1
	strlcpy(ifp->if_xname, sc->sc_dv.dv_xname, IFNAMSIZ);
d1418 2
a1419 1
#ifdef __FreeBSD__
d1424 1
a1424 10

	/*
	 * Tell the upper layer(s) we support long frames.
	 */
	ifp->if_data.ifi_hdrlen = sizeof(struct ehter_vlan_header);
#if __FreeBSD_version >= 500000
	ifp->if_capabilities |= IFCAP_VLAN_HWTAGGING | IFCAP_VLAN_MTU;
#endif
#endif /* __FreeBSD__ */

d1427 1
a1427 1
	 * Specify the media types supported by this adapter and register
a1460 169
 *  Workaround for SmartSpeed on 82541 and 82547 controllers
 *
 **********************************************************************/	
void
em_smartspeed(struct em_softc *sc)
{
	uint16_t phy_tmp;
 
	if(sc->link_active || (sc->hw.phy_type != em_phy_igp) || 
	   !sc->hw.autoneg || !(sc->hw.autoneg_advertised & ADVERTISE_1000_FULL))
		return;

	if(sc->smartspeed == 0) {
		/* If Master/Slave config fault is asserted twice,
		 * we assume back-to-back */
		em_read_phy_reg(&sc->hw, PHY_1000T_STATUS, &phy_tmp);
		if(!(phy_tmp & SR_1000T_MS_CONFIG_FAULT)) return;
		em_read_phy_reg(&sc->hw, PHY_1000T_STATUS, &phy_tmp);
		if(phy_tmp & SR_1000T_MS_CONFIG_FAULT) {
			em_read_phy_reg(&sc->hw, PHY_1000T_CTRL,
					&phy_tmp);
			if(phy_tmp & CR_1000T_MS_ENABLE) {
				phy_tmp &= ~CR_1000T_MS_ENABLE;
				em_write_phy_reg(&sc->hw,
						    PHY_1000T_CTRL, phy_tmp);
				sc->smartspeed++;
				if(sc->hw.autoneg &&
				   !em_phy_setup_autoneg(&sc->hw) &&
				   !em_read_phy_reg(&sc->hw, PHY_CTRL,
						       &phy_tmp)) {
					phy_tmp |= (MII_CR_AUTO_NEG_EN |  
						    MII_CR_RESTART_AUTO_NEG);
					em_write_phy_reg(&sc->hw,
							 PHY_CTRL, phy_tmp);
				}
			}
		}
		return;
	} else if(sc->smartspeed == EM_SMARTSPEED_DOWNSHIFT) {
		/* If still no link, perhaps using 2/3 pair cable */
		em_read_phy_reg(&sc->hw, PHY_1000T_CTRL, &phy_tmp);
		phy_tmp |= CR_1000T_MS_ENABLE;
		em_write_phy_reg(&sc->hw, PHY_1000T_CTRL, phy_tmp);
		if(sc->hw.autoneg &&
		   !em_phy_setup_autoneg(&sc->hw) &&
		   !em_read_phy_reg(&sc->hw, PHY_CTRL, &phy_tmp)) {
			phy_tmp |= (MII_CR_AUTO_NEG_EN |
				    MII_CR_RESTART_AUTO_NEG);
			em_write_phy_reg(&sc->hw, PHY_CTRL, phy_tmp);
		}
	}
	/* Restart process after EM_SMARTSPEED_MAX iterations */
	if(sc->smartspeed++ == EM_SMARTSPEED_MAX)
		sc->smartspeed = 0;

	return;
}


/*
 * Manage DMA'able memory.
 */

#ifdef __FreeBSD__
void
em_dmamap_cb(void *arg, bus_dma_segment_t *segs, int nseg, int error)
{ 
	if (error)
		return;
	*(bus_addr_t*) arg = segs->ds_addr;
	return;
}
#endif /* __FreeBSD__ */

int
em_dma_malloc(struct em_softc *sc, bus_size_t size,
	struct em_dma_alloc *dma, int mapflags)
{
	int r;

#ifdef __FreeBSD__
	r = bus_dma_tag_create(NULL,			/* parent */
			       PAGE_SIZE, 0,		/* alignment, bounds */
			       BUS_SPACE_MAXADDR,	/* lowaddr */
			       BUS_SPACE_MAXADDR,	/* highaddr */
			       NULL, NULL,		/* filter, filterarg */
			       size,			/* maxsize */
			       1,			/* nsegments */
			       size,			/* maxsegsize */
			       BUS_DMA_ALLOCNOW,	/* flags */
			       &dma->dma_tag);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dma_tag_create failed; "
			"error %u\n", sc->sc_dv.dv_xname, r);
		goto fail_0;
	}

	r = bus_dmamap_create(dma->dma_tag, BUS_DMA_NOWAIT, &dma->dma_map);
#endif /* __FreeBSD__ */
	dma->dma_tag = sc->osdep.em_pa.pa_dmat;
	r = bus_dmamap_create(dma->dma_tag, size, 1,
	    size, 0, BUS_DMA_NOWAIT, &dma->dma_map);

	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmamap_create failed; "
			"error %u\n", sc->sc_dv.dv_xname, r);
		goto fail_0;
	}

	r = bus_dmamem_alloc(dma->dma_tag, size, PAGE_SIZE, 0, &dma->dma_seg,
	    1, &dma->dma_nseg, BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmammem_alloc failed; "
			"size %ju, error %d\n", sc->sc_dv.dv_xname,
			size, r);
		goto fail_1;
	}

	r = bus_dmamem_map(dma->dma_tag, &dma->dma_seg, dma->dma_nseg, size,
	    &dma->dma_vaddr, BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmammem_map failed; "
			"size %ju, error %d\n", sc->sc_dv.dv_xname,
			size, r);
		goto fail_2;
	}

	r = bus_dmamap_load(sc->osdep.em_pa.pa_dmat, dma->dma_map,
			    dma->dma_vaddr,
			    size,
			    NULL,
			    mapflags | BUS_DMA_NOWAIT);
	if (r != 0) {
		printf("%s: em_dma_malloc: bus_dmamap_load failed; "
			"error %u\n", sc->sc_dv.dv_xname, r);
		goto fail_3;
	}

	dma->dma_size = size;
	return (0);

/* fail_4: */
	bus_dmamap_unload(dma->dma_tag, dma->dma_map);
fail_3:
	bus_dmamem_unmap(dma->dma_tag, dma->dma_vaddr, size);
fail_2:
	bus_dmamem_free(dma->dma_tag, &dma->dma_seg, dma->dma_nseg);
fail_1:
	bus_dmamap_destroy(dma->dma_tag, dma->dma_map);
	/* bus_dma_tag_destroy(dma->dma_tag); */
fail_0:
	dma->dma_map = NULL;
	/* dma->dma_tag = NULL; */
	return (r);
}

void
em_dma_free(struct em_softc *sc, struct em_dma_alloc *dma)
{
	bus_dmamap_unload(dma->dma_tag, dma->dma_map);
	bus_dmamem_unmap(dma->dma_tag, dma->dma_vaddr, dma->dma_size);
	bus_dmamem_free(dma->dma_tag, &dma->dma_seg, dma->dma_nseg);
	bus_dmamap_destroy(dma->dma_tag, dma->dma_map);
	/* bus_dma_tag_destroy(dma->dma_tag); */
}


/*********************************************************************
 *
d1469 1
a1469 1
	      (struct em_buffer *) malloc(sizeof(struct em_buffer) *
d1478 1
a1478 1
	      sizeof(struct em_buffer) * sc->num_tx_desc);
d1491 13
a1503 17
#ifdef __FreeBSD__
	/*
	 * Setup DMA descriptor areas.
	 */
	if (bus_dma_tag_create(NULL,	/* parent */
		    PAGE_SIZE, 0,	/* alignment, bounds */
		    BUS_SPACE_MAXADDR,       /* lowaddr */
		    BUS_SPACE_MAXADDR,       /* highaddr */
		    NULL, NULL,              /* filter, filterarg */
		    MCLBYTES * 8,            /* maxsize */
		    EM_MAX_SCATTER,          /* nsegments */
		    MCLBYTES * 8,            /* maxsegsize */
		    BUS_DMA_ALLOCNOW,        /* flags */
		    &sc->txtag)) {
		printf("%s: Unable to allocate TX DMA tag\n", sc->sc_dv.dv_xname);
		return (ENOMEM);
	}
d1505 1
a1505 2
#endif /* __FreeBSD__ */
	sc->txtag = sc->osdep.em_pa.pa_dmat;
d1507 10
a1516 2
	if (em_allocate_transmit_structures(sc))
		return (ENOMEM);
d1518 1
a1518 1
	bzero((void *) sc->tx_desc_base,
d1521 3
a1523 2
	sc->next_avail_tx_desc = 0;
	sc->oldest_used_tx_desc = 0;
d1531 1
a1531 1
	return (0);
d1542 2
a1543 3
	u_int32_t	reg_tctl;
	u_int32_t	reg_tipg = 0;
	u_int64_t	bus_addr;
d1546 3
a1548 3
	bus_addr = sc->txdma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, TDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, TDBAH, (u_int32_t)(bus_addr >> 32));
d1562 1
d1565 12
d1584 1
a1584 6
		if (sc->hw.media_type == em_media_type_fiber)
			reg_tipg = DEFAULT_82543_TIPG_IPGT_FIBER;
		else
			reg_tipg = DEFAULT_82543_TIPG_IPGT_COPPER;
			reg_tipg |= DEFAULT_82543_TIPG_IPGR1 << E1000_TIPG_IPGR1_SHIFT;
			reg_tipg |= DEFAULT_82543_TIPG_IPGR2 << E1000_TIPG_IPGR2_SHIFT;
a1585 1

a1587 2
	if(sc->hw.mac_type >= em_82540)
		E1000_WRITE_REG(&sc->hw, TADV, sc->tx_abs_int_delay);
d1600 1
a1600 1
	sc->txd_cmd = E1000_TXD_CMD_IFCS | E1000_TXD_CMD_RS;
d1605 5
d1621 2
a1622 2
	struct em_buffer   *tx_buffer;
	int		i;
d1629 1
a1629 3
			if (tx_buffer->m_head != NULL) {
				bus_dmamap_unload(sc->txtag, tx_buffer->map);
				bus_dmamap_destroy(sc->txtag, tx_buffer->map);
a1630 1
			}
d1632 5
a1642 6
	if (sc->txtag != NULL) {
#ifdef __FreeBSD__
		bus_dma_tag_destroy(sc->txtag);
#endif
		sc->txtag = NULL;
	}
d1653 1
a1653 1
#ifdef __FreeBSD__
d1657 1
d1662 1
a1662 3
	struct em_buffer *tx_buffer;
	int curr_txd;

d1694 2
a1695 3
	curr_txd = sc->next_avail_tx_desc;
	tx_buffer = &sc->tx_buffer_area[curr_txd];
	TXD = (struct em_context_desc *) &sc->tx_desc_base[curr_txd];
d1701 1
a1701 1
	    htole16(ETHER_HDR_LEN + sizeof(struct ip) - 1);
d1705 1
a1705 1
	TXD->upper_setup.tcp_fields.tucse = htole16(0);
d1717 2
a1718 2
	TXD->tcp_seg_setup.data = htole32(0);
	TXD->cmd_and_length = htole32(sc->txd_cmd | E1000_TXD_CMD_DEXT);
d1720 4
a1723 4
	tx_buffer->m_head = NULL;

	if (++curr_txd == sc->num_tx_desc)
		curr_txd = 0;
a1725 1
	sc->next_avail_tx_desc = curr_txd;
d1727 1
d1730 1
a1730 43
#endif /* __FreeBSD__ */

/**********************************************************************
 *
 *  Examine each tx_buffer in the used queue. If the hardware is done
 *  processing the packet then free associated resources. The
 *  tx_buffer is put back on the free queue. 
 *
 **********************************************************************/
void
em_clean_transmit_interrupts(struct em_softc* sc)
{
	int s;
	int i, num_avail;
	struct em_buffer *tx_buffer;
	struct em_tx_desc   *tx_desc;
	struct ifnet   *ifp = &sc->interface_data.ac_if;

	if (sc->num_tx_desc_avail == sc->num_tx_desc)
		return;

	s = splimp();
#ifdef DBG_STATS
	sc->clean_tx_interrupts++;
#endif
	num_avail = sc->num_tx_desc_avail;
	i = sc->oldest_used_tx_desc;

	tx_buffer = &sc->tx_buffer_area[i];
	tx_desc = &sc->tx_desc_base[i];

	while(tx_desc->upper.fields.status & E1000_TXD_STAT_DD) {

		tx_desc->upper.data = 0;
		num_avail++;

		if (tx_buffer->m_head) {
			ifp->if_opackets++;
			bus_dmamap_sync(sc->txtag, tx_buffer->map,
			    0, tx_buffer->map->dm_mapsize,
			    BUS_DMASYNC_POSTWRITE);
			bus_dmamap_unload(sc->txtag, tx_buffer->map);
			bus_dmamap_destroy(sc->txtag, tx_buffer->map);
a1731 30
			m_freem(tx_buffer->m_head);
			tx_buffer->m_head = NULL;
		}

		if (++i == sc->num_tx_desc)
			i = 0;

		tx_buffer = &sc->tx_buffer_area[i];
		tx_desc = &sc->tx_desc_base[i];
	}

	sc->oldest_used_tx_desc = i;

	/*
	 * If we have enough room, clear IFF_OACTIVE to tell the stack
	 * that it is OK to send packets.
	 * If there are no pending descriptors, clear the timeout. Otherwise,
	 * if some descriptors have been freed, restart the timeout.
	 */
	if (num_avail > EM_TX_CLEANUP_THRESHOLD) {
		ifp->if_flags &= ~IFF_OACTIVE;
		if (num_avail == sc->num_tx_desc)
			ifp->if_timer = 0;
		else if (num_avail == sc->num_tx_desc_avail)
			ifp->if_timer = EM_TX_TIMEOUT;
	}
	sc->num_tx_desc_avail = num_avail;
	splx(s);
	return;
}
d1739 2
a1740 2
em_get_buf(int i, struct em_softc *sc,
    struct mbuf *nmp)
d1742 1
a1742 2
	struct mbuf    *mp = nmp;
	struct em_buffer *rx_buffer;
a1743 1
	int error;
d1745 1
a1745 1
	ifp = &sc->interface_data.ac_if;
d1748 2
a1749 2
		MGETHDR(mp, M_DONTWAIT, MT_DATA);
		if (mp == NULL) {
d1753 3
a1755 3
		MCLGET(mp, M_DONTWAIT);
		if ((mp->m_flags & M_EXT) == 0) {
			m_freem(mp);
d1759 1
a1759 1
		mp->m_len = mp->m_pkthdr.len = MCLBYTES;
d1761 17
a1777 26
		mp->m_len = mp->m_pkthdr.len = MCLBYTES;
		mp->m_data = mp->m_ext.ext_buf;
		mp->m_next = NULL;
	}

	if (ifp->if_mtu <= ETHERMTU) {
		m_adj(mp, ETHER_ALIGN);
	}

	rx_buffer = &sc->rx_buffer_area[i];

	/*
	 * Using memory from the mbuf cluster pool, invoke the
	 * bus_dma machinery to arrange the memory mapping.
	 */
	error = bus_dmamap_load(sc->rxtag, rx_buffer->map,
	    mtod(mp, void *), mp->m_len, NULL,
	    0);
	if (error) {
		m_free(mp);
		return(error);
	}
	rx_buffer->m_head = mp;
	sc->rx_desc_base[i].buffer_addr = htole64(rx_buffer->map->dm_segs[0].ds_addr);
	bus_dmamap_sync(sc->rxtag, rx_buffer->map, 0,
	    rx_buffer->map->dm_mapsize, BUS_DMASYNC_PREREAD);
d1793 2
a1794 2
	int		i, error;
	struct em_buffer *rx_buffer;
d1797 1
a1797 1
	      (struct em_buffer *) malloc(sizeof(struct em_buffer) *
d1806 4
a1809 1
	      sizeof(struct em_buffer) * sc->num_rx_desc);
d1811 9
a1819 30
#ifdef __FreeBSD__
	error = bus_dma_tag_create(NULL,                /* parent */
				PAGE_SIZE, 0,            /* alignment, bounds */
				BUS_SPACE_MAXADDR,       /* lowaddr */
				BUS_SPACE_MAXADDR,       /* highaddr */
				NULL, NULL,              /* filter, filterarg */
				MCLBYTES,                /* maxsize */
				1,                       /* nsegments */
				MCLBYTES,                /* maxsegsize */
				BUS_DMA_ALLOCNOW,        /* flags */
				&sc->rxtag);
	if (error != 0) {
		printf("%s: em_allocate_receive_structures: "
			"bus_dma_tag_create failed; error %u\n",
			sc->sc_dv.dv_xname, error);
		goto fail_0;
	}
#endif /* __FreeBSD__ */
	sc->rxtag = sc->osdep.em_pa.pa_dmat;

	rx_buffer = sc->rx_buffer_area;
	for (i = 0; i < sc->num_rx_desc; i++, rx_buffer++) {
		error = bus_dmamap_create(sc->rxtag, MCLBYTES, 1,
					MCLBYTES, 0, BUS_DMA_NOWAIT,
					&rx_buffer->map);
		if (error != 0) {
			printf("%s: em_allocate_receive_structures: "
			    "bus_dmamap_create failed; error %u\n",
			    sc->sc_dv.dv_xname, error);
			goto fail_1;
d1823 1
a1823 18
	for (i = 0; i < sc->num_rx_desc; i++) {
		error = em_get_buf(i, sc, NULL);
		if (error != 0) {
			sc->rx_buffer_area[i].m_head = NULL;
			sc->rx_desc_base[i].buffer_addr = 0;
			return(error);
                }
        }

        return(0);

fail_1:
	/* bus_dma_tag_destroy(sc->rxtag); */
/* fail_0: */
	sc->rxtag = NULL;
	free(sc->rx_buffer_area, M_DEVBUF);
	sc->rx_buffer_area = NULL;
	return (error);
d1834 3
a1836 2
	bzero((void *) sc->rx_desc_base,
	    (sizeof(struct em_rx_desc)) * sc->num_rx_desc);
d1841 26
d1868 2
a1869 1
	sc->next_rx_desc_to_check = 0;
d1881 3
a1883 3
	u_int32_t	reg_rctl;
#ifdef __FreeBSD__
	u_int32_t	reg_rxcsum;
d1885 1
a1885 2
	struct ifnet	*ifp;
	u_int64_t	bus_addr;
d1887 1
a1887 1
	ifp = &sc->interface_data.ac_if;
d1889 4
a1892 1
	/* Make sure receives are disabled while setting up the descriptor ring */
a1898 10
	if(sc->hw.mac_type >= em_82540) {
		E1000_WRITE_REG(&sc->hw, RADV, sc->rx_abs_int_delay);

		/* Set the interrupt throttling rate.  Value is calculated
		 * as DEFAULT_ITR = 1/(MAX_INTS_PER_SEC * 256ns) */
#define MAX_INTS_PER_SEC	8000
#define DEFAULT_ITR		1000000000/(MAX_INTS_PER_SEC * 256)
		E1000_WRITE_REG(&sc->hw, ITR, DEFAULT_ITR);
	}

d1900 3
a1902 3
	bus_addr = sc->rxdma.dma_map->dm_segs[0].ds_addr;
	E1000_WRITE_REG(&sc->hw, RDBAL, (u_int32_t)bus_addr);
	E1000_WRITE_REG(&sc->hw, RDBAH, (u_int32_t)(bus_addr >> 32));
d1908 3
a1910 1
	E1000_WRITE_REG(&sc->hw, RDT, sc->num_rx_desc - 1);
d1928 1
a1928 1
		break;		  
d1940 1
a1940 1
#ifdef __FreeBSD__
d1948 1
a1948 1
#endif /* __FreeBSD__ */
d1964 2
a1965 2
	struct em_buffer   *rx_buffer;
	int		i;
a1971 4
			if (rx_buffer->map != NULL) {
				bus_dmamap_unload(sc->rxtag, rx_buffer->map);
				bus_dmamap_destroy(sc->rxtag, rx_buffer->map);
			}
d1975 5
a1985 4
	if (sc->rxtag != NULL) {
		/* bus_dma_tag_destroy(sc->rxtag); */
		sc->rxtag = NULL;
	}
a1994 3
 *  We loop at most count times if count is > 0, or until done if
 *  count < 0.
 *
d1997 1
a1997 1
em_process_receive_interrupts(struct em_softc* sc, int count)
d1999 2
a2000 2
	struct ifnet	    *ifp;
	struct mbuf	    *mp;
d2002 5
a2006 4
	u_int8_t	    accept_frame = 0;
	u_int8_t	    eop = 0;
	u_int16_t	    len, desc_len;
	int		    i;
d2010 2
d2013 2
a2014 3
	ifp = &sc->interface_data.ac_if;
	i = sc->next_rx_desc_to_check;
	current_desc = &sc->rx_desc_base[i];
d2023 1
a2023 1
	while ((current_desc->status & E1000_RXD_STAT_DD) && (count != 0)) {
d2025 8
a2032 5
		mp = sc->rx_buffer_area[i].m_head;
		bus_dmamap_sync(sc->rxtag, sc->rx_buffer_area[i].map,
		    0, sc->rx_buffer_area[i].map->dm_mapsize,
		    BUS_DMASYNC_POSTREAD);
		bus_dmamap_unload(sc->rxtag, sc->rx_buffer_area[i].map);
d2034 1
d2036 1
a2036 1
		desc_len = letoh16(current_desc->length);
a2037 1
			count--;
d2039 1
a2039 1
			len = desc_len - ETHER_CRC_LEN;
d2042 1
a2042 1
			len = desc_len;
a2045 2
			u_int8_t last_byte;
			u_int32_t pkt_len = desc_len;
d2047 3
a2049 1
			if (sc->fmp != NULL)
d2051 1
d2053 2
a2054 1
			last_byte = *(mtod(mp, caddr_t) + desc_len - 1);
d2056 2
a2057 2
			if (TBI_ACCEPT(&sc->hw, current_desc->status,
				       current_desc->errors,
d2064 1
a2064 2
			}
			else {
d2071 1
a2071 1
			if (em_get_buf(i, sc, NULL) == ENOBUFS) {
d2073 2
a2074 3
				em_get_buf(i, sc, mp);
				if (sc->fmp != NULL)
					m_freem(sc->fmp);
a2096 2
				ifp->if_ipackets++;

d2106 1
d2108 1
d2111 3
a2113 4
				em_receive_checksum(sc, current_desc,
						sc->fmp);

#ifdef __FreeBSD__
d2116 1
a2116 2
					    (letoh16(current_desc->special) &
					    E1000_RXD_SPC_VLAN_MASK));
d2118 1
a2118 1
#endif /* __FreeBSD__ */
d2126 2
a2127 3
			em_get_buf(i, sc, mp);
			if (sc->fmp != NULL)
				m_freem(sc->fmp);
d2135 11
a2145 2
		/* Advance the E1000's Receive Queue #0	 "Tail Pointer". */
		E1000_WRITE_REG(&sc->hw, RDT, i);
d2147 15
a2161 6
		/* Advance our pointers to the next descriptor */
		if (++i == sc->num_rx_desc) {
			i = 0;
			current_desc = sc->rx_desc_base;
		} else
			current_desc++;
a2162 1
	sc->next_rx_desc_to_check = i;
d2178 1
a2178 1
#ifdef __FreeBSD__
d2200 1
a2200 1
		/* Did it pass? */	  
d2209 1
a2209 1
#endif /* __FreeBSD__ */
d2217 1
a2217 1
	E1000_WRITE_REG(&sc->hw, VET, ETHERTYPE_8021Q);
d2241 1
a2241 14
int
em_is_valid_ether_addr(u_int8_t *addr)
{
	const char zero_addr[6] = { 0, 0, 0, 0, 0, 0 };

	if ((addr[0] & 1) || (!bcmp(addr, zero_addr, ETHER_ADDR_LEN))) {
		return (FALSE);
	}

	return(TRUE);
}

void
em_write_pci_cfg(struct em_hw *hw,
d2245 1
a2245 1
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
a2246 1
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
d2250 1
a2250 2
void
em_read_pci_cfg(struct em_hw *hw, uint32_t reg,
d2253 1
a2253 1
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
d2259 1
a2259 2
void
em_pci_set_mwi(struct em_hw *hw)
d2261 7
a2267 6
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pci_chipset_tag_t pc = pa->pa_pc;
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
	pci_conf_write(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
		(hw->pci_cmd_word | CMD_MEM_WRT_INVALIDATE));

d2270 1
a2270 2
void
em_pci_clear_mwi(struct em_hw *hw)
d2272 7
a2278 20
	struct pci_attach_args *pa = &((struct em_osdep *)hw->back)->em_pa;
	pci_chipset_tag_t pc = pa->pa_pc;
	/* Should we do read/mask/write...?  16 vs 32 bit!!! */
	pci_conf_write(pc, pa->pa_tag, PCI_COMMAND_STATUS_REG,
		(hw->pci_cmd_word & ~CMD_MEM_WRT_INVALIDATE));

}

uint32_t
em_io_read(struct em_hw *hw, uint32_t port)
{
	return bus_space_read_4(((struct em_osdep *)(hw)->back)->em_iobtag,
		((struct em_osdep *)(hw)->back)->em_iobhandle, port);
}

void
em_io_write(struct em_hw *hw, uint32_t port, uint32_t value)
{
	bus_space_write_4(((struct em_osdep *)(hw)->back)->em_iobtag,
			((struct em_osdep *)(hw)->back)->em_iobhandle, port,
d2281 1
a2281 1
}
a2297 1

d2364 1
a2364 1
	ifp = &sc->interface_data.ac_if;
d2367 2
d2397 1
a2397 1
em_print_debug_info(struct em_softc *sc)
a2398 2
	const char * const unit = sc->sc_dv.dv_xname;

d2400 1
a2400 1
	printf("%s: Packets not Avail = %ld\n", unit, 
d2402 1
a2402 1
	printf("%s: CleanTxInterrupts = %ld\n", unit,
a2404 21
	printf("%s: fifo workaround = %lld, fifo_reset = %lld\n", unit,
		(long long)sc->tx_fifo_wrk,
		(long long)sc->tx_fifo_reset);
	printf("%s: hw tdh = %d, hw tdt = %d\n", unit,
		E1000_READ_REG(&sc->hw, TDH),
		E1000_READ_REG(&sc->hw, TDT));
	printf("%s: Num Tx Descriptors avail = %ld\n", unit,
	       sc->num_tx_desc_avail);
	printf("%s: Tx Descriptors not avail1 = %ld\n", unit,
	       sc->no_tx_desc_avail1);
	printf("%s: Tx Descriptors not avail2 = %ld\n", unit,
	       sc->no_tx_desc_avail2);
	printf("%s: Std mbuf failed = %ld\n", unit,
		sc->mbuf_alloc_failed);
	printf("%s: Std mbuf cluster failed = %ld\n", unit,
		sc->mbuf_cluster_failed);
	printf("%s: Driver dropped packets = %ld\n", unit,
	       sc->dropped_pkts);

	return;
}
d2406 10
a2415 4
void
em_print_hw_stats(struct em_softc *sc)
{
	const char * const unit = sc->sc_dv.dv_xname;
d2417 1
a2417 3
	printf("%s: Excessive collisions = %lld\n", unit,
		(long long)sc->stats.ecol);
	printf("%s: Symbol errors = %lld\n", unit,
d2419 1
a2419 1
	printf("%s: Sequence errors = %lld\n", unit,
d2421 1
a2421 1
	printf("%s: Defer count = %lld\n", unit,
d2424 1
a2424 1
	printf("%s: Missed Packets = %lld\n", unit,
d2426 1
a2426 1
	printf("%s: Receive No Buffers = %lld\n", unit,
d2428 1
a2428 1
	printf("%s: Receive length errors = %lld\n", unit,
d2430 1
a2430 1
	printf("%s: Receive errors = %lld\n", unit,
d2432 1
a2432 1
	printf("%s: Crc errors = %lld\n", unit,
d2434 1
a2434 1
	printf("%s: Alignment errors = %lld\n", unit,
d2436 1
a2436 1
	printf("%s: Carrier extension errors = %lld\n", unit,
d2438 2
d2441 1
a2441 1
	printf("%s: XON Rcvd = %lld\n", unit,
d2443 1
a2443 1
	printf("%s: XON Xmtd = %lld\n", unit,
d2445 1
a2445 1
	printf("%s: XOFF Rcvd = %lld\n", unit,
d2447 1
a2447 1
	printf("%s: XOFF Xmtd = %lld\n", unit,
d2450 1
a2450 1
	printf("%s: Good Packets Rcvd = %lld\n", unit,
d2452 1
a2452 1
	printf("%s: Good Packets Xmtd = %lld\n", unit,
d2454 1
a2455 2
	return;
}
d2457 9
a2465 3
#ifdef __FreeBSD__
int
em_sysctl_debug_info(SYSCTL_HANDLER_ARGS)
d2467 9
a2475 3
	int error;
	int result;
	struct em_softc *sc;
d2477 62
a2538 2
	result = -1;
	error = sysctl_handle_int(oidp, &result, 0, req);
d2540 1
a2540 2
	if (error || !req->newptr)
		return (error);
d2542 4
a2545 3
	if (result == 1) {
		sc = (struct em_softc *)arg1;
		em_print_debug_info(sc);
d2547 2
a2548 2

	return error;
d2551 2
a2552 3

int
em_sysctl_stats(SYSCTL_HANDLER_ARGS)
d2554 1
a2554 3
	int error;
	int result;
	struct em_softc *sc;
d2556 1
a2556 2
	result = -1;
	error = sysctl_handle_int(oidp, &result, 0, req);
d2558 18
a2575 2
	if (error || !req->newptr)
		return (error);
d2577 16
a2592 6
	if (result == 1) {
		sc = (struct em_softc *)arg1;
		em_print_hw_stats(sc);
	}

	return error;
a2593 2
#endif /* __FreeBSD__ */

@


1.1.1.3
log
@more fixes from -current
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.10 2003/06/29 21:42:53 avsm Exp $ */
d1844 2
a1845 2
			"size %lu, error %d\n", sc->sc_dv.dv_xname,
			(unsigned long)size, r);
d1853 2
a1854 2
			"size %lu, error %d\n", sc->sc_dv.dv_xname,
			(unsigned long)size, r);
@


1.1.1.4
log
@Synchronize with OpenBSD 3.4-beta
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.11 2003/08/23 18:52:18 fgsch Exp $ */
a2534 1
#ifdef __FreeBSD__
a2535 1
#endif
a2636 1
#ifdef __FreeBSD__
a2639 1
#endif
d2649 1
a2650 3
#else /* __FreeBSD__ */
				ether_input_mbuf(ifp, sc->fmp);
#endif /* !__FreeBSD__ */
@


1.1.1.5
log
@Time to import OpenBSD once again. Expect breakage.
@
text
@d35 1
a35 1
/* $OpenBSD: if_em.c,v 1.16 2003/12/09 23:41:35 henning Exp $ */
d126 1
a126 11
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82540EP_LP },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546GB_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82545GM_SERDES },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541GI_MOBILE },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541ER }
d749 1
a749 1
	/* em_enable_vlans(sc); */
d1328 3
a1330 3
	struct arpcom *ac = &sc->interface_data;
	struct ether_multi *enm;
	struct ether_multistep step;
d1332 3
a1334 1
	struct ifnet *ifp = &sc->interface_data.ac_if;
d1348 13
a1360 10
	ETHER_FIRST_MULTI(step, ac, enm);
	while (enm != NULL) {
		if (bcmp(enm->enm_addrlo, enm->enm_addrhi, ETHER_ADDR_LEN)) {
			ifp->if_flags |= IFF_ALLMULTI;
			mcnt = MAX_NUM_MULTICAST_ADDRESSES;
		}
		if (mcnt == MAX_NUM_MULTICAST_ADDRESSES)
			break;
		bcopy(enm->enm_addrlo, &mta[mcnt*ETH_LENGTH_OF_ADDRESS],
		      ETH_LENGTH_OF_ADDRESS);
a1361 1
		ETHER_NEXT_MULTI(step, enm);
d1363 1
a1694 3
#ifdef __OpenBSD__
	ifp->if_capabilities |= IFCAP_VLAN_MTU;
#endif
a2729 15
#else /* __FreeBSD__ */
	/* 82543 or newer only */
	if ((sc->hw.mac_type < em_82543) ||
	    /* Ignore Checksum bit is set */
	    (rx_desc->status & E1000_RXD_STAT_IXSM))
		return;

	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE)) ==
	    E1000_RXD_STAT_IPCS)
		mp->m_pkthdr.csum |= M_IPV4_CSUM_IN_OK;

	if ((rx_desc->status & (E1000_RXD_STAT_IPCS|E1000_RXD_ERR_IPE|
	    E1000_RXD_STAT_TCPCS|E1000_RXD_ERR_TCPE)) ==
	    (E1000_RXD_STAT_TCPCS | E1000_RXD_STAT_IPCS))
		mp->m_pkthdr.csum |= M_TCP_CSUM_IN_OK | M_UDP_CSUM_IN_OK;
@


1.1.1.6
log
@large-scale import of OpenBSD 3.5-current source base including many fixes
note: from now, we will not be binary compatible with OpenBSD apps any
longer (due to syscall numbering differences); both an OpenBSD compat and
a conversion tool for old MirOS #7 apps will be delivered later.

The src/ tree is locked from now.
@
text
@d34 2
a35 2
/*$FreeBSD: if_em.c,v 1.38 2004/03/17 17:50:31 njl Exp $*/
/* $OpenBSD: if_em.c,v 1.21 2004/05/04 06:00:51 henric Exp $ */
d78 6
d100 1
a100 55
char em_driver_version[] = "1.7.25";

#ifdef __FreeBSD__
/*********************************************************************
 *  PCI Device ID Table
 *
 *  Used by probe to select devices to load on
 *  Last field stores an index into em_strings
 *  Last entry must be all 0s
 *
 *  { Vendor ID, Device ID, SubVendor ID, SubDevice ID, String Index }
 *********************************************************************/

em_vendor_info_t em_vendor_info_array[] =
{
        /* Intel(R) PRO/1000 Network Connection */
        { 0x8086, 0x1000, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1001, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1004, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1008, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1009, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100C, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100D, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100E, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x100F, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1010, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1011, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1012, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1013, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1014, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1015, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1016, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1017, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1018, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1019, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101A, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101D, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x101E, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1026, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1027, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1028, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1075, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1076, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1077, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1078, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x1079, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x107A, PCI_ANY_ID, PCI_ANY_ID, 0},
        { 0x8086, 0x107B, PCI_ANY_ID, PCI_ANY_ID, 0},
        /* required last entry */
        { 0, 0, 0, 0, 0}
};

/*********************************************************************
 *  Table of branding strings for all supported NICs.
 *********************************************************************/
a101 4
char *em_strings[] = {
        "Intel(R) PRO/1000 Network Connection"
};
#endif /* __FreeBSD__ */
a102 1
#ifdef __OpenBSD__
a119 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_NC },
a124 1
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_MOB },
d127 3
d133 4
a136 7
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82547EI_CT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MT },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MOB },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82541EI_MT2 },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_COPPER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_FIBER },
	{ PCI_VENDOR_INTEL, PCI_PRODUCT_INTEL_82546EB_SERDES }
a137 1
#endif /* __OpenBSD__ */
a141 8
#ifdef __FreeBSD__
int  em_probe(device_t);
int  em_attach(device_t);
int  em_detach(device_t);
int  em_shutdown(device_t);
void em_intr(void *);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
d144 5
a149 1
#endif /* __OpenBSD__ */
a150 1
void em_start_locked(struct ifnet *);
a153 1
void em_init_locked(struct em_softc *);
a161 4
#ifdef __FreeBSD__
void em_setup_interface(device_t, struct em_softc *);
#endif
#ifdef __OpenBSD__
a162 1
#endif
a187 1
void em_update_link_status(struct em_softc *);
d196 1
a196 2
void em_82547_move_tail(void *arg);
void em_82547_move_tail_locked(struct em_softc *);
a201 13
#ifdef __FreeBSD__
int  em_sysctl_stats(SYSCTL_HANDLER_ARGS);
int  em_sysctl_debug_info(SYSCTL_HANDLER_ARGS);
#endif /* __FreeBSD__ */
u_int32_t em_fill_descriptors (u_int64_t address,
                                      u_int32_t length,
                                      PDESC_ARRAY desc_array);
#ifdef __FreeBSD__
int  em_sysctl_int_delay(SYSCTL_HANDLER_ARGS);
void em_add_int_delay_sysctl(struct em_softc *, const char *,
                                    const char *, struct em_int_delay_info *,
                                    int, int);
#endif /* __FreeBSD__ */
a206 21
#ifdef __FreeBSD__
device_method_t em_methods[] = {
        /* Device interface */
        DEVMETHOD(device_probe, em_probe),
        DEVMETHOD(device_attach, em_attach),
        DEVMETHOD(device_detach, em_detach),
        DEVMETHOD(device_shutdown, em_shutdown),
        {0, 0}
};

driver_t em_driver = {
        "em", em_methods, sizeof(struct em_softc ),
};

devclass_t em_devclass;
DRIVER_MODULE(em, pci, em_driver, em_devclass, 0, 0);
MODULE_DEPEND(em, pci, 1, 1, 1);
MODULE_DEPEND(em, ether, 1, 1, 1);
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a213 20
#endif /* __OpenBSD__ */

/*********************************************************************
 *  Tunable default values.
 *********************************************************************/

#define E1000_TICKS_TO_USECS(ticks)     ((1024 * (ticks) + 500) / 1000)
#define E1000_USECS_TO_TICKS(usecs)     ((1000 * (usecs) + 512) / 1024)

int em_tx_int_delay_dflt = E1000_TICKS_TO_USECS(EM_TIDV);
int em_rx_int_delay_dflt = E1000_TICKS_TO_USECS(EM_RDTR);
int em_tx_abs_int_delay_dflt = E1000_TICKS_TO_USECS(EM_TADV);
int em_rx_abs_int_delay_dflt = E1000_TICKS_TO_USECS(EM_RADV);

#ifdef __FreeBSD__
TUNABLE_INT("hw.em.tx_int_delay", &em_tx_int_delay_dflt);
TUNABLE_INT("hw.em.rx_int_delay", &em_rx_int_delay_dflt);
TUNABLE_INT("hw.em.tx_abs_int_delay", &em_tx_abs_int_delay_dflt);
TUNABLE_INT("hw.em.rx_abs_int_delay", &em_rx_abs_int_delay_dflt);
#endif /* __FreeBSD__ */
a223 46
#ifdef __FreeBSD__
int
em_probe(device_t dev)
{
        em_vendor_info_t *ent;

        u_int16_t       pci_vendor_id = 0;
        u_int16_t       pci_device_id = 0;
        u_int16_t       pci_subvendor_id = 0;
        u_int16_t       pci_subdevice_id = 0;
        char            adapter_name[60];

        INIT_DEBUGOUT("em_probe: begin");

        pci_vendor_id = pci_get_vendor(dev);
        if (pci_vendor_id != EM_VENDOR_ID)
                return(ENXIO);

        pci_device_id = pci_get_device(dev);
        pci_subvendor_id = pci_get_subvendor(dev);
        pci_subdevice_id = pci_get_subdevice(dev);

        ent = em_vendor_info_array;
        while (ent->vendor_id != 0) {
                if ((pci_vendor_id == ent->vendor_id) &&
                    (pci_device_id == ent->device_id) &&

                    ((pci_subvendor_id == ent->subvendor_id) ||
                     (ent->subvendor_id == PCI_ANY_ID)) &&

                    ((pci_subdevice_id == ent->subdevice_id) ||
                     (ent->subdevice_id == PCI_ANY_ID))) {
                        sprintf(adapter_name, "%s, Version - %s",
                                em_strings[ent->index],
                                em_driver_version);
                        device_set_desc_copy(dev, adapter_name);
                        return(0);
                }
                ent++;
        }

        return(ENXIO);
}
#endif /* __FreeBSD__ */

#ifdef __OpenBSD__
a231 1
#endif /* __OpenBSD__ */
a242 7
#ifdef __FreeBSD__
int
em_attach(device_t dev)
{
	pci_chipset_tag_t pc = pa->pa_pc;
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
d247 5
a251 2
#endif /* __OpenBSD__ */
	struct em_softc *sc;
d256 1
d262 1
a268 1
	EM_LOCK_INIT(sc, device_get_nameunit(dev));
a270 3

#ifdef __OpenBSD__
	sc = (struct em_softc *)self;
a271 1
#endif
d304 2
a305 2
	callout_init(&sc->timer, CALLOUT_MPSAFE);
	callout_init(&sc->tx_fifo_timer, CALLOUT_MPSAFE);
a307 1
#ifdef __OpenBSD__
a309 1
#endif /* __OpenBSD__ */
a313 22
#ifdef __FreeBSD__
        /* Set up some sysctls for the tunable interrupt delays */
        em_add_int_delay_sysctl(sc, "rx_int_delay",
            "receive interrupt delay in usecs", &sc->rx_int_delay,
            E1000_REG_OFFSET(&sc->hw, RDTR), em_rx_int_delay_dflt);
        em_add_int_delay_sysctl(sc, "tx_int_delay",
            "transmit interrupt delay in usecs", &sc->tx_int_delay,
            E1000_REG_OFFSET(&sc->hw, TIDV), em_tx_int_delay_dflt);
        if (sc->hw.mac_type >= em_82540) {
                em_add_int_delay_sysctl(sc, "rx_abs_int_delay",
                    "receive interrupt delay limit in usecs",
                    &sc->rx_abs_int_delay,
                    E1000_REG_OFFSET(&sc->hw, RADV),
                    em_rx_abs_int_delay_dflt);
                em_add_int_delay_sysctl(sc, "tx_abs_int_delay",
                    "transmit interrupt delay limit in usecs",
                    &sc->tx_abs_int_delay,
                    E1000_REG_OFFSET(&sc->hw, TADV),
                    em_tx_abs_int_delay_dflt);
        }
#endif /* __FreeBSD__ */

d315 6
a320 2
	sc->num_tx_desc = EM_MIN_TXD;
	sc->num_rx_desc = EM_MIN_RXD;
a337 1
        sc->hw.phy_reset_disable = FALSE;
a338 5
#ifndef EM_MASTER_SLAVE
        sc->hw.master_slave = em_ms_hw_default;
#else
        sc->hw.master_slave = EM_MASTER_SLAVE;
#endif
d416 2
d428 3
a430 12
        if (sc->link_active == 1) {
                em_get_speed_and_duplex(&sc->hw, &sc->link_speed,
                                        &sc->link_duplex);
#ifdef __FreeBSD__
                printf("%s:  Speed:%d Mbps  Duplex:%s\n",
                       sc->sc_dv.dv_xname,
                       sc->link_speed,
                       sc->link_duplex == FULL_DUPLEX ? "Full" : "Half");
        } else
                printf("%s:  Speed:N/A  Duplex:N/A\n", sc->sc_dv.dv_xname);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a432 12
	printf(", address: %s\n", ether_sprintf(sc->interface_data.ac_enaddr));
#endif /* __OpenBSD__ */

        /* Identify 82544 on PCIX */
        em_get_bus_info(&sc->hw);
        if(sc->hw.bus_type == em_bus_type_pcix &&
           sc->hw.mac_type == em_82544) {
                sc->pcix_82544 = TRUE;
        }
        else {
                sc->pcix_82544 = FALSE;
        }
d434 1
a434 4
#ifdef __FreeBSD__
	return(0);
#endif
#ifdef __OpenBSD__
a435 1
#endif
a446 2
err_sysctl:
	return(error);
d448 3
a462 1

d465 1
a465 1
em_detach(device_t dev)
d467 11
a477 13
        struct em_softc * sc = device_get_softc(dev);
        struct ifnet   *ifp = &sc->interface_data.ac_if;
	EM_LOCK_STATE();

        INIT_DEBUGOUT("em_detach: begin");

        EM_LOCK(sc);
        sc->in_detach = 1;
        em_stop(sc);
        em_phy_hw_reset(&sc->hw);
        EM_UNLOCK(sc);
#if  __FreeBSD_version < 500000
        ether_ifdetach(&sc->interface_data.ac_if, ETHER_BPF_SUPPORTED);
d479 1
a479 1
        ether_ifdetach(&sc->interface_data.ac_if);
d481 1
a481 2
        em_free_pci_resources(sc);
        bus_generic_detach(dev);
d483 19
a501 5
        /* Free Transmit Descriptor ring */
        if (sc->tx_desc_base) {
                em_dma_free(sc, &sc->txdma);
                sc->tx_desc_base = NULL;
        }
d503 2
a504 5
        /* Free Receive Descriptor ring */
        if (sc->rx_desc_base) {
                em_dma_free(sc, &sc->rxdma);
                sc->rx_desc_base = NULL;
        }
d506 2
a507 17
        /* Free the sysctl tree */
        sysctl_ctx_free(&sc->sysctl_ctx);

        /* Remove from the sc list */
        if (em_adapter_list == sc)
                em_adapter_list = sc->next;
        if (sc->next != NULL)
                sc->next->prev = sc->prev;
        if (sc->prev != NULL)
                sc->prev->next = sc->next;

        EM_LOCK_DESTROY(sc);

        ifp->if_flags &= ~(IFF_RUNNING | IFF_OACTIVE);
        ifp->if_timer = 0;

        return(0);
a508 1
#endif /* __FreeBSD__ */
a515 1
#ifdef __FreeBSD__
d517 1
a517 1
em_shutdown(device_t dev)
d519 4
a522 2
        struct em_softc *sc = device_get_softc(dev);
	EM_LOCK_STATE();
a523 5
        EM_LOCK(sc);
        em_stop(sc);
        EM_UNLOCK(sc);
        return(0);
}
a525 1

d537 1
a537 1
em_start_locked(struct ifnet *ifp)
d539 1
a542 2
	mtx_assert(&sc->mtx, MA_OWNED);
	
d546 2
d570 1
a570 12
	return;
}

void
em_start(struct ifnet *ifp)
{
	struct em_softc *sc = ifp->if_softc;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_start_locked(ifp);
        EM_UNLOCK(sc);
d586 1
a586 1
	int		error = 0;
d588 1
a589 1
	EM_LOCK_STATE();
d591 1
a591 5
#ifdef __OpenBSD__
	struct ifaddr  *ifa = (struct ifaddr *)data;
	EM_LOCK(sc);
	error = ether_ioctl(ifp, &sc->interface_data, command, data);
	EM_UNLOCK(sc);
d593 2
a594 1
	if (error > 0)
d596 1
a596 2
#endif /* __OpenBSD__ */
        if (sc->in_detach) return(error);
a605 1
#ifdef __OpenBSD__
a619 1
#endif /* __OpenBSD__ */
a624 1
                        EM_LOCK(sc);
d628 1
a628 2
			em_init_locked(sc);
                        EM_UNLOCK(sc);
a632 1
                EM_LOCK(sc);
d634 2
a635 3
			if (!(ifp->if_flags & IFF_RUNNING)) {
				em_init_locked(sc);
                        }
a643 1
                EM_UNLOCK(sc);
a647 1
#ifdef __OpenBSD__
a652 1
#endif /* __OpenBSD__ */
a653 1
                                EM_LOCK(sc);
d660 1
a660 1
				if (!(ifp->if_flags & IFF_POLLING))
a662 1
                                EM_UNLOCK(sc);
a663 1
#ifdef __OpenBSD__
a665 1
#endif /* __OpenBSD__ */
d687 1
a687 1
		IOCTL_DEBUGOUT1("ioctl received: UNKNOWN (0x%x)\n", (int)command);
d691 1
d716 1
a716 2
	if (em_check_for_link(&sc->hw))
	        printf("%s: watchdog timeout -- resetting\n", sc->sc_dv.dv_xname);
d720 1
d739 1
a739 1
em_init_locked(struct em_softc *sc)
d741 3
a743 1
	struct ifnet   *ifp = &sc->interface_data.ac_if;
d747 1
a747 1
        mtx_assert(&sc->mtx, MA_OWNED);
a750 15
	if (ifp->if_flags & IFF_UP) {
		sc->num_tx_desc = EM_MAX_TXD;
		sc->num_rx_desc = EM_MAX_RXD;
	} else {
		sc->num_tx_desc = EM_MIN_TXD;
		sc->num_rx_desc = EM_MIN_RXD;
	}


#ifdef __FreeBSD__
        /* Get the latest mac address, User can use a LAA */
        bcopy(sc->interface_data.ac_enaddr, sc->hw.mac_addr,
              ETHER_ADDR_LEN);
#endif /* __FreeBSD__ */

d755 1
d766 1
d779 1
d784 1
a784 3
        /* Don't loose promiscuous settings */
        em_set_promisc(sc);

d795 1
a796 3
	callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a797 1
#endif
d804 1
a804 1
        if (ifp->if_flags & IFF_POLLING)
d810 1
a810 3
        /* Don't reset the phy next time init gets called */
        sc->hw.phy_reset_disable = TRUE;

a813 12
void
em_init(void *arg)
{
        struct em_softc * sc = arg;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_init_locked(sc);
        EM_UNLOCK(sc);
        return;
}

d816 1
a816 1
poll_handler_t em_poll;
d818 2
a819 2
void
em_poll_locked(struct ifnet *ifp, enum poll_cmd cmd, int count)
d821 2
a822 2
        struct em_softc *sc = ifp->if_softc;
        u_int32_t reg_icr;
d824 18
a841 1
        mtx_assert(&sc->mtx, MA_OWNED);
d843 2
a844 32
        if (cmd == POLL_DEREGISTER) {       /* final call, enable interrupts */
                em_enable_intr(sc);
                return;
        }
        if (cmd == POLL_AND_CHECK_STATUS) {
                reg_icr = E1000_READ_REG(&sc->hw, ICR);
                if (reg_icr & (E1000_ICR_RXSEQ | E1000_ICR_LSC)) {
                        callout_stop(&sc->timer);
                        sc->hw.get_link_status = 1;
                        em_check_for_link(&sc->hw);
                        em_update_link_status(sc);
                        callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
                }
        }
        if (ifp->if_flags & IFF_RUNNING) {
                em_process_receive_interrupts(sc, count);
                em_clean_transmit_interrupts(sc);
        }

        if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
                em_start_locked(ifp);
}

void
em_poll(struct ifnet *ifp, enum poll_cmd cmd, int count)
{
        struct em_softc *sc = ifp->if_softc;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_poll_locked(ifp, cmd, count);
        EM_UNLOCK(sc);
a852 4
#ifdef __FreeBSD__
void
#endif
#ifdef __OpenBSD__
a853 1
#endif
d859 1
a859 4
	struct em_softc  *sc = arg;
	EM_LOCK_STATE();

        EM_LOCK(sc);
d864 2
a865 4
        if (ifp->if_flags & IFF_POLLING) {
                EM_UNLOCK(sc);
                return;
        }
d867 5
a871 6
        if (ether_poll_register(em_poll, ifp)) {
                em_disable_intr(sc);
                em_poll_locked(ifp, 0, 1);
                EM_UNLOCK(sc);
                return;
        }
a872 1

a874 5
                EM_UNLOCK(sc);
#ifdef __FreeBSD__
		return;
#endif
#ifdef __OpenBSD__
a875 1
#endif
a879 4
#ifdef __FreeBSD__
                callout_stop(&sc->timer);
#endif
#ifdef __OpenBSD__
a880 1
#endif
d883 1
a883 5
		em_update_link_status(sc);
#ifdef __FreeBSD__
                callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif
#ifdef __OpenBSD__
a884 1
#endif
a894 4
#ifdef __FreeBSD__
        if (ifp->if_flags & IFF_RUNNING && ifp->if_snd.ifq_head != NULL)
#endif
#ifdef __OpenBSD__
d896 1
a896 2
#endif
                em_start_locked(ifp);
a897 5
        EM_UNLOCK(sc);
#ifdef __FreeBSD__
	return;
#endif
#ifdef __OpenBSD__
a898 1
#endif
a952 3
#if defined(__FreeBSD__) && __FreeBSD_version < 500000
			ifmr->ifm_active |= IFM_1000_TX;
#else
a953 1
#endif
d989 1
a989 5
#if defined(__FreeBSD__) && __FreeBSD_version < 500000
        case IFM_1000_TX:
#else
        case IFM_1000_T:
#endif
a1012 5
        /* As the speed/duplex settings my have changed we need to
         * reset the PHY.
         */
        sc->hw.phy_reset_disable = FALSE;

d1026 1
a1026 1
	KASSERT(nsegs <= EM_MAX_SCATTER,
d1047 1
a1047 1
	u_int32_t	txd_lower, txd_used = 0, txd_saved = 0;
a1048 6
	u_int64_t       address;

        /* For 82544 Workaround */
        DESC_ARRAY              desc_array;
        u_int32_t               array_elements;
        u_int32_t               counter;
d1074 1
a1074 1
            &q.map)) {
a1111 4
        if (sc->pcix_82544) {
                txd_saved = i;
                txd_used = 0;
        }
d1113 7
a1119 40
                /* If sc is 82544 and on PCIX bus */
                if(sc->pcix_82544) {
                        array_elements = 0;
                        address = htole64(q.map->dm_segs[j].ds_addr);
                        /*
                         * Check the Address and Length combination and
                         * split the data accordingly
                         */
                        array_elements = em_fill_descriptors(address,
                                                             htole32(q.map->dm_segs[j].ds_len),
                                                             &desc_array);
                        for (counter = 0; counter < array_elements; counter++) {
                                if (txd_used == sc->num_tx_desc_avail) {
                                          sc->next_avail_tx_desc = txd_saved;
                                          sc->no_tx_desc_avail2++;
                                          bus_dmamap_destroy(sc->txtag, q.map);
                                          return (ENOBUFS);
                                }
                                tx_buffer = &sc->tx_buffer_area[i];
                                current_tx_desc = &sc->tx_desc_base[i];
                                current_tx_desc->buffer_addr = htole64(
                                        desc_array.descriptor[counter].address);
                                current_tx_desc->lower.data = htole32(
                                        (sc->txd_cmd | txd_lower |
                                         (u_int16_t)desc_array.descriptor[counter].length));
                                current_tx_desc->upper.data = htole32((txd_upper));
                                if (++i == sc->num_tx_desc)
                                         i = 0;

                                tx_buffer->m_head = NULL;
                                txd_used++;
                        }
                } else {
		        tx_buffer = &sc->tx_buffer_area[i];
		        current_tx_desc = &sc->tx_desc_base[i];

		        current_tx_desc->buffer_addr = htole64(q.map->dm_segs[j].ds_addr);
		        current_tx_desc->lower.data = htole32(
		            sc->txd_cmd | txd_lower | q.map->dm_segs[j].ds_len);
		        current_tx_desc->upper.data = htole32(txd_upper);
d1121 2
a1122 2
		        if (++i == sc->num_tx_desc)
	        		i = 0;
d1124 1
a1124 2
		        tx_buffer->m_head = NULL;
                }
d1127 1
a1128 6
        if (sc->pcix_82544) {
                sc->num_tx_desc_avail -= txd_used;
        }
        else {
                sc->num_tx_desc_avail -= q.map->dm_nsegs;
        }
d1156 1
a1156 1
		em_82547_move_tail_locked(sc);
d1172 1
a1172 1
 * in this case. We do that only when FIFO is quiescent.
d1176 1
a1176 1
em_82547_move_tail_locked(struct em_softc *sc)
d1178 2
d1186 1
a1186 2
        EM_LOCK_ASSERT(sc);

a1199 5
#ifdef __FreeBSD__
                                callout_reset(&sc->tx_fifo_timer, 1,
                                        em_82547_move_tail, sc);
#endif
#ifdef __OpenBSD__
d1201 7
a1207 2
#endif
				break;
a1208 3
			E1000_WRITE_REG(&sc->hw, TDT, hw_tdt);
			em_82547_update_fifo_head(sc, length);
			length = 0;
d1211 1
a1214 11
void
em_82547_move_tail(void *arg)
{
        struct em_softc *sc = arg;
	EM_LOCK_STATE();

        EM_LOCK(sc);
        em_82547_move_tail_locked(sc);
        EM_UNLOCK(sc);
}

a1337 6
#ifdef __FreeBSD__
	struct ifmultiaddr  *ifma;
#endif
	int mcnt = 0;
	struct ifnet *ifp = &sc->interface_data.ac_if;
#ifdef __OpenBSD__
d1341 2
a1342 1
#endif /* __OpenBSD__ */
a1355 17
#ifdef __FreeBSD__
#if __FreeBSD_version < 500000
        LIST_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#else
        TAILQ_FOREACH(ifma, &ifp->if_multiaddrs, ifma_link) {
#endif
                if (ifma->ifma_addr->sa_family != AF_LINK)
                        continue;

                if (mcnt == MAX_NUM_MULTICAST_ADDRESSES) break;

                bcopy(LLADDR((struct sockaddr_dl *)ifma->ifma_addr),
                      &mta[mcnt*ETH_LENGTH_OF_ADDRESS], ETH_LENGTH_OF_ADDRESS);
                mcnt++;
        }
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1368 1
#endif /* __OpenBSD__ */
d1375 1
a1375 1
		em_mc_addr_list_update(&sc->hw, mta, mcnt, 0, 1);
d1401 1
a1403 2
	EM_LOCK_STATE();

d1406 1
a1406 1
	EM_LOCK(sc);
d1409 1
a1409 1
	em_update_link_status(sc);
a1415 4
#ifdef __FreeBSD__
        callout_reset(&sc->timer, 2*hz, em_local_timer, sc);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1416 1
#endif /* __OpenBSD__ */
d1418 1
a1418 1
        EM_UNLOCK(sc);
d1425 15
a1439 45
        if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
                if (sc->link_active == 0) {
                        em_get_speed_and_duplex(&sc->hw,
                                                &sc->link_speed,
                                                &sc->link_duplex);
                        printf("%s: Link is up %d Mbps %s\n",
                               sc->sc_dv.dv_xname,
                               sc->link_speed,
                               ((sc->link_duplex == FULL_DUPLEX) ?
                                "Full Duplex" : "Half Duplex"));
                        sc->link_active = 1;
                        sc->smartspeed = 0;
                }
        } else {
                if (sc->link_active == 1) {
                        sc->link_speed = 0;
                        sc->link_duplex = 0;
                        printf("%s: Link is Down\n", sc->sc_dv.dv_xname);
                        sc->link_active = 0;
                }
        }

        return;
}

void
em_update_link_status(struct em_softc * sc)
{
        if (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU) {
                if (sc->link_active == 0) {
                        em_get_speed_and_duplex(&sc->hw,
                                                &sc->link_speed,
                                                &sc->link_duplex);
                        sc->link_active = 1;
                        sc->smartspeed = 0;
                }
        } else {
                if (sc->link_active == 1) {
                        sc->link_speed = 0;
                        sc->link_duplex = 0;
                        sc->link_active = 0;
                }
        }

        return;
d1441 1
d1458 1
a1458 3
	mtx_assert(&sc->mtx, MA_OWNED);

	INIT_DEBUGOUT("em_stop: begin");
a1460 5
#ifdef __FreeBSD__
        callout_stop(&sc->timer);
        callout_stop(&sc->tx_fifo_timer);
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
a1462 1
#endif /* __OpenBSD__ */
a1513 6
	if(sc->hw.mac_type == em_82541 ||
	   sc->hw.mac_type == em_82541_rev_2 ||
	   sc->hw.mac_type == em_82547 ||
	   sc->hw.mac_type == em_82547_rev_2)
		sc->hw.phy_init_script = TRUE;

d1534 1
a1534 1
		printf(": can't find mem space\n");
d1554 1
a1554 1
			printf(": can't find io space\n");
a1556 8

#ifdef __FreeBSD__
                sc->hw.io_base =
                rman_get_start(sc->res_ioport);
#endif
#ifdef __OpenBSD__
		sc->hw.io_base = 0;
#endif
a1613 1
	INIT_DEBUGOUT("em_hardware_init: begin");
a1662 4
#ifdef __FreeBSD__
em_setup_interface(device_t dev, struct em_softc * sc)
#endif
#ifdef __OpenBSD__
a1663 1
#endif
a1668 7
#ifdef __FreeBSD__
        if_initname(ifp, device_get_name(dev), device_get_unit(dev));
#endif
#ifdef __OpenBSD__
	strlcpy(ifp->if_xname, sc->sc_dv.dv_xname, IFNAMSIZ);
#endif

a1679 4
#ifdef __FreeBSD__
	ifp->if_snd.ifq_maxlen = sc->num_tx_desc - 1;
#endif
#ifdef __OpenBSD__
a1681 1
#endif
d1683 2
d1694 1
a1694 1
	ifp->if_data.ifi_hdrlen = sizeof(struct ether_vlan_header);
a1729 1
#ifdef __OpenBSD__
d1732 1
a1732 1
#endif
d1801 1
a1828 2
			       NULL,			/* lockfunc */
			       NULL,			/* lockarg */
a1837 1
#ifdef __OpenBSD__
d1841 1
a1841 1
#endif /* __OpenBSD__ */
d1888 1
a1888 1
	bus_dma_tag_destroy(dma->dma_tag);
d1902 1
a1902 1
	bus_dma_tag_destroy(dma->dma_tag);
a1950 2
		    NULL,                    /* lockfunc */
		    NULL,                    /* lockarg */
a1956 1
#ifdef __OpenBSD__
a1957 1
#endif
a1988 1
	INIT_DEBUGOUT("em_initialize_transmit_unit: begin");
d2024 1
a2024 1
	E1000_WRITE_REG(&sc->hw, TIDV, sc->tx_int_delay.value);
d2026 1
a2026 2
		E1000_WRITE_REG(&sc->hw, TADV,
		    sc->tx_abs_int_delay.value);
d2041 1
a2041 1
	if (sc->tx_int_delay.value > 0)
d2076 1
d2078 1
d2182 1
a2187 2
	mtx_assert(&sc->mtx, MA_OWNED);

d2191 1
d2241 1
a2348 1
#ifdef __OpenBSD__
a2349 1
#endif
d2376 1
a2376 1
	bus_dma_tag_destroy(sc->rxtag);
a2417 1
	INIT_DEBUGOUT("em_initialize_receive_unit: begin");
d2425 1
a2425 1
			sc->rx_int_delay.value | E1000_RDT_FPDB);
d2428 1
a2428 2
		E1000_WRITE_REG(&sc->hw, RADV,
		    sc->rx_abs_int_delay.value);
a2437 4
#ifdef __FreeBSD__
	bus_addr = sc->rxdma.dma_paddr;
#endif
#ifdef __OpenBSD__
a2438 1
#endif
d2522 1
a2522 1
		bus_dma_tag_destroy(sc->rxtag);
a2543 1
#if __FreeBSD_version < 500000
a2545 1
#endif /* __FreeBSD__ */
d2548 1
a2548 1
	u_int16_t	    len, desc_len, prev_len_adj;
a2553 2
	mtx_assert(&sc->mtx, MA_OWNED);

a2573 1
		prev_len_adj = 0;
d2578 1
a2578 7
			if (desc_len < ETHER_CRC_LEN) {
				len = 0;
				prev_len_adj = ETHER_CRC_LEN - desc_len;
			}
			else {
				len = desc_len - ETHER_CRC_LEN;
			}
d2600 1
a2600 1
				if (len > 0) len--;
d2629 3
a2631 11
                                /*
                                 * Adjust length of previous mbuf in chain if we
                                 * received less than 4 bytes in the last descriptor.
                                 */
                                if (prev_len_adj > 0) {
                                        sc->lmp->m_len -= prev_len_adj;
                                        sc->fmp->m_pkthdr.len -= prev_len_adj;
                                }
                                sc->lmp->m_next = mp;
                                sc->lmp = sc->lmp->m_next;
                                sc->fmp->m_pkthdr.len += len;
a2637 1
#ifdef __OpenBSD__
d2646 1
a2646 4
				em_receive_checksum(sc, current_desc,
					    sc->fmp);
				ether_input_mbuf(ifp, sc->fmp);
#endif /* __OpenBSD__ */
a2647 1
#if __FreeBSD_version < 500000
d2651 14
a2664 9
                                em_receive_checksum(sc, current_desc,
                                                    sc->fmp);
                                if (current_desc->status & E1000_RXD_STAT_VP)
                                        VLAN_INPUT_TAG(eh, sc->fmp,
                                                       (current_desc->special &
                                                        E1000_RXD_SPC_VLAN_MASK));
                                else
                                        ether_input(ifp, eh, sc->fmp);
#else
a2665 15
                                em_receive_checksum(sc, current_desc,
                                                    sc->fmp);
                                if (current_desc->status & E1000_RXD_STAT_VP)
                                        VLAN_INPUT_TAG(ifp, sc->fmp,
                                                       (current_desc->special &
                                                        E1000_RXD_SPC_VLAN_MASK),
                                                       sc->fmp = NULL);

                                if (sc->fmp != NULL) {
                                        EM_UNLOCK(sc);
                                        (*ifp->if_input)(ifp, sc->fmp);
                                        EM_LOCK(sc);
                                }
#endif
#endif /* __FreeBSD__ */
d2738 1
a2738 2
#endif /* __FreeBSD__ */
#ifdef __OpenBSD__
d2753 1
a2753 1
#endif /* __OpenBSD__ */
d2757 1
a2757 2
void
em_enable_vlans(struct em_softc * sc)
d2840 2
a2841 3
#ifdef __FreeBSD__
int32_t
em_io_read(struct em_hw *hw, unsigned long port)
d2843 2
a2844 1
        return(inl(port));
d2848 1
a2848 1
em_io_write(struct em_hw *hw, unsigned long port, uint32_t value)
d2850 4
a2853 56
        outl(port, value);
        return;
}
#endif /* __FreeBSD__ */

/*********************************************************************
* 82544 Coexistence issue workaround.
*    There are 2 issues.
*       1. Transmit Hang issue.
*    To detect this issue, following equation can be used...
*          SIZE[3:0] + ADDR[2:0] = SUM[3:0].
*          If SUM[3:0] is in between 1 to 4, we will have this issue.
*
*       2. DAC issue.
*    To detect this issue, following equation can be used...
*          SIZE[3:0] + ADDR[2:0] = SUM[3:0].
*          If SUM[3:0] is in between 9 to c, we will have this issue.
*
*
*    WORKAROUND:
*          Make sure we do not have ending address as 1,2,3,4(Hang) or 9,a,b,c (DAC)
*
*** *********************************************************************/
u_int32_t
em_fill_descriptors (u_int64_t address,
                              u_int32_t length,
                              PDESC_ARRAY desc_array)
{
        /* Since issue is sensitive to length and address.*/
        /* Let us first check the address...*/
        u_int32_t safe_terminator;
        if (length <= 4) {
                desc_array->descriptor[0].address = address;
                desc_array->descriptor[0].length = length;
                desc_array->elements = 1;
                return desc_array->elements;
        }
        safe_terminator = (u_int32_t)((((u_int32_t)address & 0x7) + (length & 0xF)) & 0xF);
        /* if it does not fall between 0x1 to 0x4 and 0x9 to 0xC then return */
        if (safe_terminator == 0   ||
        (safe_terminator > 4   &&
        safe_terminator < 9)   ||
        (safe_terminator > 0xC &&
        safe_terminator <= 0xF)) {
                desc_array->descriptor[0].address = address;
                desc_array->descriptor[0].length = length;
                desc_array->elements = 1;
                return desc_array->elements;
        }

        desc_array->descriptor[0].address = address;
        desc_array->descriptor[0].length = length - 4;
        desc_array->descriptor[1].address = address + (length - 4);
        desc_array->descriptor[1].length = 4;
        desc_array->elements = 2;
        return desc_array->elements;
a2865 5
	if(sc->hw.media_type == em_media_type_copper ||
	    (E1000_READ_REG(&sc->hw, STATUS) & E1000_STATUS_LU)) {
		sc->stats.symerrs += E1000_READ_REG(&sc->hw, SYMERRS);
 		sc->stats.sec += E1000_READ_REG(&sc->hw, SEC);
	}
d2867 1
d2876 1
a2971 9
	uint8_t *hw_addr = sc->hw.hw_addr;

        printf("%s: Adapter hardware address = %p \n", unit, hw_addr);
        printf("%s:tx_int_delay = %d, tx_abs_int_delay = %d\n", unit,
              E1000_READ_REG(&sc->hw, TIDV),
              E1000_READ_REG(&sc->hw, TADV));
        printf("%s:rx_int_delay = %d, rx_abs_int_delay = %d\n", unit,
              E1000_READ_REG(&sc->hw, RDTR),
              E1000_READ_REG(&sc->hw, RADV));
d2985 1
a2985 1
	printf("%s: Num Tx descriptors avail = %d\n", unit,
a3088 60
}

int
em_sysctl_int_delay(SYSCTL_HANDLER_ARGS)
{
	struct em_int_delay_info *info;
	struct em_softc *sc;
	u_int32_t regval;
	int error;
	int usecs;
	int ticks;
	int s;

	info = (struct em_int_delay_info *)arg1;
	sc = info->sc;
	usecs = info->value;
	error = sysctl_handle_int(oidp, &usecs, 0, req);
	if (error != 0 || req->newptr == NULL)
		return error;
	if (usecs < 0 || usecs > E1000_TICKS_TO_USECS(65535))
		return EINVAL;
	info->value = usecs;
	ticks = E1000_USECS_TO_TICKS(usecs);

	s = splimp();
	regval = E1000_READ_OFFSET(&sc->hw, info->offset);
	regval = (regval & ~0xffff) | (ticks & 0xffff);
	/* Handle a few special cases. */
	switch (info->offset) {
	case E1000_RDTR:
	case E1000_82542_RDTR:
		regval |= E1000_RDT_FPDB;
		break;
	case E1000_TIDV:
	case E1000_82542_TIDV:
		if (ticks == 0) {
			sc->txd_cmd &= ~E1000_TXD_CMD_IDE;
			/* Don't write 0 into the TIDV register. */
			regval++;
		} else
			sc->txd_cmd |= E1000_TXD_CMD_IDE;
		break;
	}
	E1000_WRITE_OFFSET(&sc->hw, info->offset, regval);
	splx(s);
	return 0;
}

void
em_add_int_delay_sysctl(struct em_softc *sc, const char *name,
    const char *description, struct em_int_delay_info *info,
    int offset, int value)
{
	info->sc = sc;
	info->offset = offset;
	info->value = value;
	SYSCTL_ADD_PROC(&sc->sysctl_ctx,
	    SYSCTL_CHILDREN(sc->sysctl_tree),
	    OID_AUTO, name, CTLTYPE_INT|CTLFLAG_RW,
	    info, 0, em_sysctl_int_delay, "I", description);
@


